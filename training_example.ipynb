{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f77023ce7c8>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import argparse\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torchsummary import summary\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from preprocessing import *\n",
    "from discharge_model import Predictor\n",
    "from utils import loss_profile, model_evaluation, adjust_learning_rate\n",
    "torch.manual_seed(2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_args_parser():\n",
    "    \"\"\"hyperparameter & model setting\"\"\" \n",
    "    parser = argparse.ArgumentParser('Discharge model(QV-curve) training', add_help=False)\n",
    "    parser.add_argument('--batch_size', default=32, type=int)\n",
    "    parser.add_argument('--epochs', default=1000, type=int)\n",
    "    parser.add_argument('--split_seed', default=0, type=int)\n",
    "    parser.add_argument('--gpu_id', default=0, type=int)\n",
    "    parser.add_argument('--detail_epoch', default=1, type=int)\n",
    "\n",
    "    # Model parameters\n",
    "    parser.add_argument('--model', default='Predictor_1', type=str, metavar='MODEL')\n",
    "    parser.add_argument('--checkpoint', default='checkpoint/pretrain_predictor.pth', type=str)\n",
    "    parser.add_argument('--drop', default=0.20, type=float)\n",
    "    parser.add_argument('--qv_ch', default=64, type=int)\n",
    "    parser.add_argument('--savepath', default='checkpoint/best_predictor.pth', type=str)\n",
    "    parser.add_argument('--finetune', default=False, type=bool)\n",
    "    parser.add_argument('--pretrained_model', default='checkpoint/best_38p55.pth', type=str)\n",
    "\n",
    "    # Optimizer parameters\n",
    "    parser.add_argument('--weight_decay', type=float, default=1e-2, metavar='LR')\n",
    "    parser.add_argument('--lr', type=float, default=1e-4, metavar='LR')\n",
    "    parser.add_argument('--lr_schedule', type=bool, default=True, metavar='LR')\n",
    "    parser.add_argument('--min_lr', type=float, default=1e-6, metavar='LR')\n",
    "    parser.add_argument('--lr_period', type=int, default=10, metavar='LR')\n",
    "\n",
    "    return parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -- GPU is available -- \n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv1d-1               [-1, 64, 50]          45,120\n",
      "              Mish-2               [-1, 64, 50]               0\n",
      "            Conv1d-3              [-1, 128, 50]          57,472\n",
      "              Mish-4              [-1, 128, 50]               0\n",
      "            Conv1d-5              [-1, 256, 50]         164,096\n",
      "              Mish-6              [-1, 256, 50]               0\n",
      "    SpatialDropout-7              [-1, 256, 50]               0\n",
      "         AvgPool1d-8              [-1, 256, 25]               0\n",
      "            Conv1d-9               [-1, 64, 25]         180,288\n",
      "             Mish-10               [-1, 64, 25]               0\n",
      "           Conv1d-11               [-1, 64, 25]         114,752\n",
      "             Mish-12               [-1, 64, 25]               0\n",
      "        AvgPool1d-13                [-1, 64, 1]               0\n",
      "        AvgPool1d-14                [-1, 25, 1]               0\n",
      "           Conv1d-15               [-1, 64, 89]             640\n",
      "             Mish-16               [-1, 64, 89]               0\n",
      "           Conv1d-17               [-1, 32, 89]          14,368\n",
      "             Mish-18               [-1, 32, 89]               0\n",
      "           Conv1d-19              [-1, 128, 89]          28,800\n",
      "             Mish-20              [-1, 128, 89]               0\n",
      "        MaxPool1d-21               [-1, 128, 1]               0\n",
      "        AvgPool1d-22               [-1, 128, 1]               0\n",
      "           Linear-23                    [-1, 1]             129\n",
      "================================================================\n",
      "Total params: 605,665\n",
      "Trainable params: 605,665\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 0.84\n",
      "Params size (MB): 2.31\n",
      "Estimated Total Size (MB): 3.17\n",
      "----------------------------------------------------------------\n",
      "epoch:[1 / 1000] batch:[30 / 134] loss= 0.204\n",
      "epoch:[1 / 1000] batch:[60 / 134] loss= 0.468\n",
      "epoch:[1 / 1000] batch:[90 / 134] loss= 0.298\n",
      "epoch:[1 / 1000] batch:[120 / 134] loss= 0.531\n",
      "100 cycles trn_loss: 0.358, val_loss: 0.430, lr=9.757730e-05\n",
      "training set RMSE 1 cycle: 93.847, 10 cycle: 93.844, 100 cycle: 93.842\n",
      "testing set RMSE 1 cycle: 100.373, 10 cycle: 100.372, 100 cycle: 100.370\n",
      "epoch:[2 / 1000] batch:[30 / 134] loss= 0.507\n",
      "epoch:[2 / 1000] batch:[60 / 134] loss= 0.240\n",
      "epoch:[2 / 1000] batch:[90 / 134] loss= 0.282\n",
      "epoch:[2 / 1000] batch:[120 / 134] loss= 0.313\n",
      "100 cycles trn_loss: 0.345, val_loss: 0.419, lr=9.054634e-05\n",
      "training set RMSE 1 cycle: 93.109, 10 cycle: 92.976, 100 cycle: 92.917\n",
      "testing set RMSE 1 cycle: 99.568, 10 cycle: 99.501, 100 cycle: 99.441\n",
      "epoch:[3 / 1000] batch:[30 / 134] loss= 0.284\n",
      "epoch:[3 / 1000] batch:[60 / 134] loss= 0.458\n",
      "epoch:[3 / 1000] batch:[90 / 134] loss= 0.248\n",
      "epoch:[3 / 1000] batch:[120 / 134] loss= 0.201\n",
      "100 cycles trn_loss: 0.360, val_loss: 0.447, lr=7.959537e-05\n",
      "training set RMSE 1 cycle: 95.696, 10 cycle: 95.160, 100 cycle: 95.726\n",
      "testing set RMSE 1 cycle: 102.291, 10 cycle: 102.210, 100 cycle: 102.619\n",
      "epoch:[4 / 1000] batch:[30 / 134] loss= 0.337\n",
      "epoch:[4 / 1000] batch:[60 / 134] loss= 0.272\n",
      "epoch:[4 / 1000] batch:[90 / 134] loss= 0.102\n",
      "epoch:[4 / 1000] batch:[120 / 134] loss= 0.516\n",
      "100 cycles trn_loss: 0.209, val_loss: 0.278, lr=6.579634e-05\n",
      "training set RMSE 1 cycle: 86.516, 10 cycle: 68.185, 100 cycle: 67.403\n",
      "testing set RMSE 1 cycle: 75.625, 10 cycle: 74.846, 100 cycle: 73.786\n",
      "epoch:[5 / 1000] batch:[30 / 134] loss= 0.173\n",
      "epoch:[5 / 1000] batch:[60 / 134] loss= 0.267\n",
      "epoch:[5 / 1000] batch:[90 / 134] loss= 0.147\n",
      "epoch:[5 / 1000] batch:[120 / 134] loss= 0.188\n",
      "100 cycles trn_loss: 0.251, val_loss: 0.323, lr=5.050000e-05\n",
      "training set RMSE 1 cycle: 86.062, 10 cycle: 75.664, 100 cycle: 76.019\n",
      "testing set RMSE 1 cycle: 82.879, 10 cycle: 82.321, 100 cycle: 82.305\n",
      "epoch:[6 / 1000] batch:[30 / 134] loss= 0.184\n",
      "epoch:[6 / 1000] batch:[60 / 134] loss= 0.208\n",
      "epoch:[6 / 1000] batch:[90 / 134] loss= 0.279\n",
      "epoch:[6 / 1000] batch:[120 / 134] loss= 0.211\n",
      "100 cycles trn_loss: 0.218, val_loss: 0.291, lr=3.520366e-05\n",
      "training set RMSE 1 cycle: 90.029, 10 cycle: 69.197, 100 cycle: 68.983\n",
      "testing set RMSE 1 cycle: 76.926, 10 cycle: 76.091, 100 cycle: 75.450\n",
      "epoch:[7 / 1000] batch:[30 / 134] loss= 0.201\n",
      "epoch:[7 / 1000] batch:[60 / 134] loss= 0.186\n",
      "epoch:[7 / 1000] batch:[90 / 134] loss= 0.246\n",
      "epoch:[7 / 1000] batch:[120 / 134] loss= 0.163\n",
      "100 cycles trn_loss: 0.185, val_loss: 0.247, lr=2.140463e-05\n",
      "training set RMSE 1 cycle: 91.446, 10 cycle: 64.347, 100 cycle: 61.533\n",
      "testing set RMSE 1 cycle: 70.997, 10 cycle: 70.097, 100 cycle: 67.128\n",
      "epoch:[8 / 1000] batch:[30 / 134] loss= 0.118\n",
      "epoch:[8 / 1000] batch:[60 / 134] loss= 0.287\n",
      "epoch:[8 / 1000] batch:[90 / 134] loss= 0.221\n",
      "epoch:[8 / 1000] batch:[120 / 134] loss= 0.189\n",
      "100 cycles trn_loss: 0.183, val_loss: 0.245, lr=1.045366e-05\n",
      "training set RMSE 1 cycle: 92.689, 10 cycle: 64.042, 100 cycle: 61.007\n",
      "testing set RMSE 1 cycle: 70.816, 10 cycle: 69.858, 100 cycle: 66.696\n",
      "epoch:[9 / 1000] batch:[30 / 134] loss= 0.139\n",
      "epoch:[9 / 1000] batch:[60 / 134] loss= 0.169\n",
      "epoch:[9 / 1000] batch:[90 / 134] loss= 0.160\n",
      "epoch:[9 / 1000] batch:[120 / 134] loss= 0.118\n",
      "100 cycles trn_loss: 0.185, val_loss: 0.253, lr=3.422702e-06\n",
      "training set RMSE 1 cycle: 93.486, 10 cycle: 64.134, 100 cycle: 61.788\n",
      "testing set RMSE 1 cycle: 71.720, 10 cycle: 70.643, 100 cycle: 68.092\n",
      "epoch:[10 / 1000] batch:[30 / 134] loss= 0.179\n",
      "epoch:[10 / 1000] batch:[60 / 134] loss= 0.246\n",
      "epoch:[10 / 1000] batch:[90 / 134] loss= 0.157\n",
      "epoch:[10 / 1000] batch:[120 / 134] loss= 0.215\n",
      "100 cycles trn_loss: 0.183, val_loss: 0.251, lr=1.000000e-06\n",
      "training set RMSE 1 cycle: 94.456, 10 cycle: 63.894, 100 cycle: 61.221\n",
      "testing set RMSE 1 cycle: 71.425, 10 cycle: 70.337, 100 cycle: 67.503\n",
      "epoch:[11 / 1000] batch:[30 / 134] loss= 0.166\n",
      "epoch:[11 / 1000] batch:[60 / 134] loss= 0.142\n",
      "epoch:[11 / 1000] batch:[90 / 134] loss= 0.211\n",
      "epoch:[11 / 1000] batch:[120 / 134] loss= 0.230\n",
      "100 cycles trn_loss: 0.185, val_loss: 0.254, lr=3.422702e-06\n",
      "training set RMSE 1 cycle: 93.955, 10 cycle: 64.088, 100 cycle: 61.757\n",
      "testing set RMSE 1 cycle: 71.781, 10 cycle: 70.671, 100 cycle: 68.131\n",
      "epoch:[12 / 1000] batch:[30 / 134] loss= 0.222\n",
      "epoch:[12 / 1000] batch:[60 / 134] loss= 0.300\n",
      "epoch:[12 / 1000] batch:[90 / 134] loss= 0.273\n",
      "epoch:[12 / 1000] batch:[120 / 134] loss= 0.291\n",
      "100 cycles trn_loss: 0.183, val_loss: 0.252, lr=1.045366e-05\n",
      "training set RMSE 1 cycle: 94.576, 10 cycle: 63.934, 100 cycle: 61.443\n",
      "testing set RMSE 1 cycle: 71.624, 10 cycle: 70.494, 100 cycle: 67.815\n",
      "epoch:[13 / 1000] batch:[30 / 134] loss= 0.155\n",
      "epoch:[13 / 1000] batch:[60 / 134] loss= 0.161\n",
      "epoch:[13 / 1000] batch:[90 / 134] loss= 0.173\n",
      "epoch:[13 / 1000] batch:[120 / 134] loss= 0.114\n",
      "100 cycles trn_loss: 0.178, val_loss: 0.237, lr=2.140463e-05\n",
      "training set RMSE 1 cycle: 96.966, 10 cycle: 63.970, 100 cycle: 59.475\n",
      "testing set RMSE 1 cycle: 70.280, 10 cycle: 69.292, 100 cycle: 64.849\n",
      "epoch:[14 / 1000] batch:[30 / 134] loss= 0.124\n",
      "epoch:[14 / 1000] batch:[60 / 134] loss= 0.196\n",
      "epoch:[14 / 1000] batch:[90 / 134] loss= 0.172\n",
      "epoch:[14 / 1000] batch:[120 / 134] loss= 0.108\n",
      "100 cycles trn_loss: 0.206, val_loss: 0.281, lr=3.520366e-05\n",
      "training set RMSE 1 cycle: 92.220, 10 cycle: 67.023, 100 cycle: 66.544\n",
      "testing set RMSE 1 cycle: 75.302, 10 cycle: 74.032, 100 cycle: 73.120\n",
      "epoch:[15 / 1000] batch:[30 / 134] loss= 0.215\n",
      "epoch:[15 / 1000] batch:[60 / 134] loss= 0.151\n",
      "epoch:[15 / 1000] batch:[90 / 134] loss= 0.316\n",
      "epoch:[15 / 1000] batch:[120 / 134] loss= 0.168\n",
      "100 cycles trn_loss: 0.180, val_loss: 0.243, lr=5.050000e-05\n",
      "training set RMSE 1 cycle: 92.887, 10 cycle: 63.437, 100 cycle: 60.452\n",
      "testing set RMSE 1 cycle: 70.607, 10 cycle: 69.357, 100 cycle: 66.261\n",
      "epoch:[16 / 1000] batch:[30 / 134] loss= 0.239\n",
      "epoch:[16 / 1000] batch:[60 / 134] loss= 0.166\n",
      "epoch:[16 / 1000] batch:[90 / 134] loss= 0.242\n",
      "epoch:[16 / 1000] batch:[120 / 134] loss= 0.305\n",
      "100 cycles trn_loss: 0.178, val_loss: 0.230, lr=6.579634e-05\n",
      "training set RMSE 1 cycle: 97.850, 10 cycle: 64.478, 100 cycle: 58.905\n",
      "testing set RMSE 1 cycle: 70.038, 10 cycle: 68.804, 100 cycle: 63.470\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:[17 / 1000] batch:[30 / 134] loss= 0.273\n",
      "epoch:[17 / 1000] batch:[60 / 134] loss= 0.151\n",
      "epoch:[17 / 1000] batch:[90 / 134] loss= 0.243\n",
      "epoch:[17 / 1000] batch:[120 / 134] loss= 0.246\n",
      "100 cycles trn_loss: 0.191, val_loss: 0.230, lr=7.959537e-05\n",
      "training set RMSE 1 cycle: 101.818, 10 cycle: 67.378, 100 cycle: 60.078\n",
      "testing set RMSE 1 cycle: 71.323, 10 cycle: 70.225, 100 cycle: 63.358\n",
      "epoch:[18 / 1000] batch:[30 / 134] loss= 0.115\n",
      "epoch:[18 / 1000] batch:[60 / 134] loss= 0.170\n",
      "epoch:[18 / 1000] batch:[90 / 134] loss= 0.192\n",
      "epoch:[18 / 1000] batch:[120 / 134] loss= 0.218\n",
      "100 cycles trn_loss: 0.191, val_loss: 0.270, lr=9.054634e-05\n",
      "training set RMSE 1 cycle: 97.121, 10 cycle: 64.298, 100 cycle: 63.673\n",
      "testing set RMSE 1 cycle: 73.910, 10 cycle: 71.836, 100 cycle: 70.630\n",
      "epoch:[19 / 1000] batch:[30 / 134] loss= 0.174\n",
      "epoch:[19 / 1000] batch:[60 / 134] loss= 0.129\n",
      "epoch:[19 / 1000] batch:[90 / 134] loss= 0.345\n",
      "epoch:[19 / 1000] batch:[120 / 134] loss= 0.233\n",
      "100 cycles trn_loss: 0.258, val_loss: 0.339, lr=9.757730e-05\n",
      "training set RMSE 1 cycle: 89.372, 10 cycle: 75.909, 100 cycle: 76.792\n",
      "testing set RMSE 1 cycle: 85.014, 10 cycle: 83.534, 100 cycle: 83.886\n",
      "epoch:[20 / 1000] batch:[30 / 134] loss= 0.259\n",
      "epoch:[20 / 1000] batch:[60 / 134] loss= 0.273\n",
      "epoch:[20 / 1000] batch:[90 / 134] loss= 0.130\n",
      "epoch:[20 / 1000] batch:[120 / 134] loss= 0.121\n",
      "100 cycles trn_loss: 0.225, val_loss: 0.293, lr=1.000000e-04\n",
      "training set RMSE 1 cycle: 84.535, 10 cycle: 70.978, 100 cycle: 70.970\n",
      "testing set RMSE 1 cycle: 78.635, 10 cycle: 77.230, 100 cycle: 76.997\n",
      "epoch:[21 / 1000] batch:[30 / 134] loss= 0.202\n",
      "epoch:[21 / 1000] batch:[60 / 134] loss= 0.170\n",
      "epoch:[21 / 1000] batch:[90 / 134] loss= 0.097\n",
      "epoch:[21 / 1000] batch:[120 / 134] loss= 0.254\n",
      "100 cycles trn_loss: 0.188, val_loss: 0.268, lr=9.757730e-05\n",
      "training set RMSE 1 cycle: 93.057, 10 cycle: 63.597, 100 cycle: 63.345\n",
      "testing set RMSE 1 cycle: 73.325, 10 cycle: 71.225, 100 cycle: 70.330\n",
      "epoch:[22 / 1000] batch:[30 / 134] loss= 0.150\n",
      "epoch:[22 / 1000] batch:[60 / 134] loss= 0.100\n",
      "epoch:[22 / 1000] batch:[90 / 134] loss= 0.086\n",
      "epoch:[22 / 1000] batch:[120 / 134] loss= 0.195\n",
      "100 cycles trn_loss: 0.168, val_loss: 0.238, lr=9.054634e-05\n",
      "training set RMSE 1 cycle: 100.389, 10 cycle: 63.616, 100 cycle: 57.661\n",
      "testing set RMSE 1 cycle: 72.676, 10 cycle: 69.724, 100 cycle: 64.875\n",
      "epoch:[23 / 1000] batch:[30 / 134] loss= 0.143\n",
      "epoch:[23 / 1000] batch:[60 / 134] loss= 0.078\n",
      "epoch:[23 / 1000] batch:[90 / 134] loss= 0.298\n",
      "epoch:[23 / 1000] batch:[120 / 134] loss= 0.237\n",
      "100 cycles trn_loss: 0.168, val_loss: 0.236, lr=7.959537e-05\n",
      "training set RMSE 1 cycle: 89.242, 10 cycle: 61.266, 100 cycle: 58.329\n",
      "testing set RMSE 1 cycle: 69.871, 10 cycle: 67.330, 100 cycle: 64.606\n",
      "epoch:[24 / 1000] batch:[30 / 134] loss= 0.269\n",
      "epoch:[24 / 1000] batch:[60 / 134] loss= 0.208\n",
      "epoch:[24 / 1000] batch:[90 / 134] loss= 0.300\n",
      "epoch:[24 / 1000] batch:[120 / 134] loss= 0.264\n",
      "100 cycles trn_loss: 0.279, val_loss: 0.357, lr=6.579634e-05\n",
      "training set RMSE 1 cycle: 87.758, 10 cycle: 81.314, 100 cycle: 81.946\n",
      "testing set RMSE 1 cycle: 89.821, 10 cycle: 89.009, 100 cycle: 89.093\n",
      "epoch:[25 / 1000] batch:[30 / 134] loss= 0.250\n",
      "epoch:[25 / 1000] batch:[60 / 134] loss= 0.098\n",
      "epoch:[25 / 1000] batch:[90 / 134] loss= 0.216\n",
      "epoch:[25 / 1000] batch:[120 / 134] loss= 0.218\n",
      "100 cycles trn_loss: 0.189, val_loss: 0.269, lr=5.050000e-05\n",
      "training set RMSE 1 cycle: 88.566, 10 cycle: 63.681, 100 cycle: 63.754\n",
      "testing set RMSE 1 cycle: 72.710, 10 cycle: 70.985, 100 cycle: 70.554\n",
      "epoch:[26 / 1000] batch:[30 / 134] loss= 0.120\n",
      "epoch:[26 / 1000] batch:[60 / 134] loss= 0.191\n",
      "epoch:[26 / 1000] batch:[90 / 134] loss= 0.348\n",
      "epoch:[26 / 1000] batch:[120 / 134] loss= 0.120\n",
      "100 cycles trn_loss: 0.198, val_loss: 0.280, lr=3.520366e-05\n",
      "training set RMSE 1 cycle: 89.605, 10 cycle: 64.982, 100 cycle: 65.519\n",
      "testing set RMSE 1 cycle: 73.315, 10 cycle: 72.377, 100 cycle: 72.313\n",
      "epoch:[27 / 1000] batch:[30 / 134] loss= 0.092\n",
      "epoch:[27 / 1000] batch:[60 / 134] loss= 0.251\n",
      "epoch:[27 / 1000] batch:[90 / 134] loss= 0.211\n",
      "epoch:[27 / 1000] batch:[120 / 134] loss= 0.101\n",
      "100 cycles trn_loss: 0.161, val_loss: 0.235, lr=2.140463e-05\n",
      "training set RMSE 1 cycle: 90.638, 10 cycle: 61.721, 100 cycle: 56.903\n",
      "testing set RMSE 1 cycle: 71.005, 10 cycle: 68.222, 100 cycle: 64.363\n",
      "epoch:[28 / 1000] batch:[30 / 134] loss= 0.215\n",
      "epoch:[28 / 1000] batch:[60 / 134] loss= 0.112\n",
      "epoch:[28 / 1000] batch:[90 / 134] loss= 0.151\n",
      "epoch:[28 / 1000] batch:[120 / 134] loss= 0.149\n",
      "100 cycles trn_loss: 0.166, val_loss: 0.245, lr=1.045366e-05\n",
      "training set RMSE 1 cycle: 88.789, 10 cycle: 60.491, 100 cycle: 58.968\n",
      "testing set RMSE 1 cycle: 69.682, 10 cycle: 67.828, 100 cycle: 66.157\n",
      "epoch:[29 / 1000] batch:[30 / 134] loss= 0.073\n",
      "epoch:[29 / 1000] batch:[60 / 134] loss= 0.189\n",
      "epoch:[29 / 1000] batch:[90 / 134] loss= 0.073\n",
      "epoch:[29 / 1000] batch:[120 / 134] loss= 0.243\n",
      "100 cycles trn_loss: 0.174, val_loss: 0.255, lr=3.422702e-06\n",
      "training set RMSE 1 cycle: 89.637, 10 cycle: 61.399, 100 cycle: 60.784\n",
      "testing set RMSE 1 cycle: 70.021, 10 cycle: 68.815, 100 cycle: 67.904\n",
      "epoch:[30 / 1000] batch:[30 / 134] loss= 0.132\n",
      "epoch:[30 / 1000] batch:[60 / 134] loss= 0.135\n",
      "epoch:[30 / 1000] batch:[90 / 134] loss= 0.089\n",
      "epoch:[30 / 1000] batch:[120 / 134] loss= 0.088\n",
      "100 cycles trn_loss: 0.160, val_loss: 0.240, lr=1.000000e-06\n",
      "training set RMSE 1 cycle: 90.535, 10 cycle: 60.099, 100 cycle: 57.782\n",
      "testing set RMSE 1 cycle: 69.582, 10 cycle: 67.668, 100 cycle: 65.412\n",
      "epoch:[31 / 1000] batch:[30 / 134] loss= 0.154\n",
      "epoch:[31 / 1000] batch:[60 / 134] loss= 0.134\n",
      "epoch:[31 / 1000] batch:[90 / 134] loss= 0.122\n",
      "epoch:[31 / 1000] batch:[120 / 134] loss= 0.177\n",
      "100 cycles trn_loss: 0.163, val_loss: 0.243, lr=3.422702e-06\n",
      "training set RMSE 1 cycle: 90.044, 10 cycle: 60.211, 100 cycle: 58.434\n",
      "testing set RMSE 1 cycle: 69.471, 10 cycle: 67.740, 100 cycle: 65.889\n",
      "epoch:[32 / 1000] batch:[30 / 134] loss= 0.088\n",
      "epoch:[32 / 1000] batch:[60 / 134] loss= 0.292\n",
      "epoch:[32 / 1000] batch:[90 / 134] loss= 0.223\n",
      "epoch:[32 / 1000] batch:[120 / 134] loss= 0.088\n",
      "100 cycles trn_loss: 0.164, val_loss: 0.245, lr=1.045366e-05\n",
      "training set RMSE 1 cycle: 89.627, 10 cycle: 60.262, 100 cycle: 58.622\n",
      "testing set RMSE 1 cycle: 69.517, 10 cycle: 67.818, 100 cycle: 66.081\n",
      "epoch:[33 / 1000] batch:[30 / 134] loss= 0.177\n",
      "epoch:[33 / 1000] batch:[60 / 134] loss= 0.187\n",
      "epoch:[33 / 1000] batch:[90 / 134] loss= 0.196\n",
      "epoch:[33 / 1000] batch:[120 / 134] loss= 0.085\n",
      "100 cycles trn_loss: 0.157, val_loss: 0.237, lr=2.140463e-05\n",
      "training set RMSE 1 cycle: 91.943, 10 cycle: 60.330, 100 cycle: 56.838\n",
      "testing set RMSE 1 cycle: 69.969, 10 cycle: 67.939, 100 cycle: 64.841\n",
      "epoch:[34 / 1000] batch:[30 / 134] loss= 0.224\n",
      "epoch:[34 / 1000] batch:[60 / 134] loss= 0.092\n",
      "epoch:[34 / 1000] batch:[90 / 134] loss= 0.150\n",
      "epoch:[34 / 1000] batch:[120 / 134] loss= 0.229\n",
      "100 cycles trn_loss: 0.165, val_loss: 0.243, lr=3.520366e-05\n",
      "training set RMSE 1 cycle: 89.001, 10 cycle: 60.184, 100 cycle: 58.669\n",
      "testing set RMSE 1 cycle: 68.881, 10 cycle: 67.443, 100 cycle: 65.793\n",
      "epoch:[35 / 1000] batch:[30 / 134] loss= 0.198\n",
      "epoch:[35 / 1000] batch:[60 / 134] loss= 0.210\n",
      "epoch:[35 / 1000] batch:[90 / 134] loss= 0.118\n",
      "epoch:[35 / 1000] batch:[120 / 134] loss= 0.162\n",
      "100 cycles trn_loss: 0.163, val_loss: 0.241, lr=5.050000e-05\n",
      "training set RMSE 1 cycle: 90.155, 10 cycle: 60.063, 100 cycle: 58.423\n",
      "testing set RMSE 1 cycle: 68.461, 10 cycle: 67.202, 100 cycle: 65.449\n",
      "epoch:[36 / 1000] batch:[30 / 134] loss= 0.215\n",
      "epoch:[36 / 1000] batch:[60 / 134] loss= 0.134\n",
      "epoch:[36 / 1000] batch:[90 / 134] loss= 0.108\n",
      "epoch:[36 / 1000] batch:[120 / 134] loss= 0.215\n",
      "100 cycles trn_loss: 0.180, val_loss: 0.263, lr=6.579634e-05\n",
      "training set RMSE 1 cycle: 87.916, 10 cycle: 62.380, 100 cycle: 62.070\n",
      "testing set RMSE 1 cycle: 70.430, 10 cycle: 69.846, 100 cycle: 69.377\n",
      "epoch:[37 / 1000] batch:[30 / 134] loss= 0.145\n",
      "epoch:[37 / 1000] batch:[60 / 134] loss= 0.202\n",
      "epoch:[37 / 1000] batch:[90 / 134] loss= 0.154\n",
      "epoch:[37 / 1000] batch:[120 / 134] loss= 0.127\n",
      "100 cycles trn_loss: 0.202, val_loss: 0.279, lr=7.959537e-05\n",
      "training set RMSE 1 cycle: 88.509, 10 cycle: 66.065, 100 cycle: 66.435\n",
      "testing set RMSE 1 cycle: 72.872, 10 cycle: 72.870, 100 cycle: 72.865\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:[38 / 1000] batch:[30 / 134] loss= 0.137\n",
      "epoch:[38 / 1000] batch:[60 / 134] loss= 0.364\n",
      "epoch:[38 / 1000] batch:[90 / 134] loss= 0.162\n",
      "epoch:[38 / 1000] batch:[120 / 134] loss= 0.165\n",
      "100 cycles trn_loss: 0.155, val_loss: 0.233, lr=9.054634e-05\n",
      "training set RMSE 1 cycle: 86.293, 10 cycle: 60.082, 100 cycle: 56.089\n",
      "testing set RMSE 1 cycle: 68.543, 10 cycle: 66.874, 100 cycle: 64.027\n",
      "epoch:[39 / 1000] batch:[30 / 134] loss= 0.212\n",
      "epoch:[39 / 1000] batch:[60 / 134] loss= 0.125\n",
      "epoch:[39 / 1000] batch:[90 / 134] loss= 0.257\n",
      "epoch:[39 / 1000] batch:[120 / 134] loss= 0.210\n",
      "100 cycles trn_loss: 0.227, val_loss: 0.307, lr=9.757730e-05\n",
      "training set RMSE 1 cycle: 87.690, 10 cycle: 70.581, 100 cycle: 71.325\n",
      "testing set RMSE 1 cycle: 77.022, 10 cycle: 77.339, 100 cycle: 77.906\n",
      "epoch:[40 / 1000] batch:[30 / 134] loss= 0.200\n",
      "epoch:[40 / 1000] batch:[60 / 134] loss= 0.080\n",
      "epoch:[40 / 1000] batch:[90 / 134] loss= 0.129\n",
      "epoch:[40 / 1000] batch:[120 / 134] loss= 0.257\n",
      "100 cycles trn_loss: 0.159, val_loss: 0.256, lr=1.000000e-04\n",
      "training set RMSE 1 cycle: 84.454, 10 cycle: 59.732, 100 cycle: 57.489\n",
      "testing set RMSE 1 cycle: 70.716, 10 cycle: 69.203, 100 cycle: 67.675\n",
      "epoch:[41 / 1000] batch:[30 / 134] loss= 0.135\n",
      "epoch:[41 / 1000] batch:[60 / 134] loss= 0.169\n",
      "epoch:[41 / 1000] batch:[90 / 134] loss= 0.185\n",
      "epoch:[41 / 1000] batch:[120 / 134] loss= 0.155\n",
      "100 cycles trn_loss: 0.152, val_loss: 0.225, lr=9.757730e-05\n",
      "training set RMSE 1 cycle: 88.414, 10 cycle: 62.657, 100 cycle: 54.651\n",
      "testing set RMSE 1 cycle: 70.251, 10 cycle: 68.037, 100 cycle: 62.908\n",
      "epoch:[42 / 1000] batch:[30 / 134] loss= 0.192\n",
      "epoch:[42 / 1000] batch:[60 / 134] loss= 0.226\n",
      "epoch:[42 / 1000] batch:[90 / 134] loss= 0.192\n",
      "epoch:[42 / 1000] batch:[120 / 134] loss= 0.111\n",
      "100 cycles trn_loss: 0.158, val_loss: 0.244, lr=9.054634e-05\n",
      "training set RMSE 1 cycle: 84.203, 10 cycle: 59.793, 100 cycle: 57.702\n",
      "testing set RMSE 1 cycle: 68.720, 10 cycle: 67.156, 100 cycle: 65.980\n",
      "epoch:[43 / 1000] batch:[30 / 134] loss= 0.187\n",
      "epoch:[43 / 1000] batch:[60 / 134] loss= 0.249\n",
      "epoch:[43 / 1000] batch:[90 / 134] loss= 0.119\n",
      "epoch:[43 / 1000] batch:[120 / 134] loss= 0.126\n",
      "100 cycles trn_loss: 0.147, val_loss: 0.225, lr=7.959537e-05\n",
      "training set RMSE 1 cycle: 84.286, 10 cycle: 59.067, 100 cycle: 55.302\n",
      "testing set RMSE 1 cycle: 67.788, 10 cycle: 65.434, 100 cycle: 63.074\n",
      "epoch:[44 / 1000] batch:[30 / 134] loss= 0.128\n",
      "epoch:[44 / 1000] batch:[60 / 134] loss= 0.111\n",
      "epoch:[44 / 1000] batch:[90 / 134] loss= 0.202\n",
      "epoch:[44 / 1000] batch:[120 / 134] loss= 0.179\n",
      "100 cycles trn_loss: 0.140, val_loss: 0.224, lr=6.579634e-05\n",
      "training set RMSE 1 cycle: 84.974, 10 cycle: 59.388, 100 cycle: 53.728\n",
      "testing set RMSE 1 cycle: 69.615, 10 cycle: 66.414, 100 cycle: 62.978\n",
      "epoch:[45 / 1000] batch:[30 / 134] loss= 0.150\n",
      "epoch:[45 / 1000] batch:[60 / 134] loss= 0.276\n",
      "epoch:[45 / 1000] batch:[90 / 134] loss= 0.202\n",
      "epoch:[45 / 1000] batch:[120 / 134] loss= 0.143\n",
      "100 cycles trn_loss: 0.191, val_loss: 0.269, lr=5.050000e-05\n",
      "training set RMSE 1 cycle: 83.606, 10 cycle: 65.059, 100 cycle: 64.773\n",
      "testing set RMSE 1 cycle: 72.102, 10 cycle: 70.488, 100 cycle: 71.183\n",
      "epoch:[46 / 1000] batch:[30 / 134] loss= 0.238\n",
      "epoch:[46 / 1000] batch:[60 / 134] loss= 0.173\n",
      "epoch:[46 / 1000] batch:[90 / 134] loss= 0.140\n",
      "epoch:[46 / 1000] batch:[120 / 134] loss= 0.168\n",
      "100 cycles trn_loss: 0.137, val_loss: 0.216, lr=3.520366e-05\n",
      "training set RMSE 1 cycle: 83.554, 10 cycle: 59.196, 100 cycle: 52.725\n",
      "testing set RMSE 1 cycle: 69.089, 10 cycle: 65.754, 100 cycle: 61.613\n",
      "epoch:[47 / 1000] batch:[30 / 134] loss= 0.222\n",
      "epoch:[47 / 1000] batch:[60 / 134] loss= 0.105\n",
      "epoch:[47 / 1000] batch:[90 / 134] loss= 0.225\n",
      "epoch:[47 / 1000] batch:[120 / 134] loss= 0.131\n",
      "100 cycles trn_loss: 0.138, val_loss: 0.217, lr=2.140463e-05\n",
      "training set RMSE 1 cycle: 83.147, 10 cycle: 60.236, 100 cycle: 52.516\n",
      "testing set RMSE 1 cycle: 70.279, 10 cycle: 66.691, 100 cycle: 61.779\n",
      "epoch:[48 / 1000] batch:[30 / 134] loss= 0.147\n",
      "epoch:[48 / 1000] batch:[60 / 134] loss= 0.071\n",
      "epoch:[48 / 1000] batch:[90 / 134] loss= 0.106\n",
      "epoch:[48 / 1000] batch:[120 / 134] loss= 0.197\n",
      "100 cycles trn_loss: 0.149, val_loss: 0.228, lr=1.045366e-05\n",
      "training set RMSE 1 cycle: 78.812, 10 cycle: 58.690, 100 cycle: 55.994\n",
      "testing set RMSE 1 cycle: 68.719, 10 cycle: 64.871, 100 cycle: 63.799\n",
      "epoch:[49 / 1000] batch:[30 / 134] loss= 0.179\n",
      "epoch:[49 / 1000] batch:[60 / 134] loss= 0.087\n",
      "epoch:[49 / 1000] batch:[90 / 134] loss= 0.130\n",
      "epoch:[49 / 1000] batch:[120 / 134] loss= 0.057\n",
      "100 cycles trn_loss: 0.155, val_loss: 0.244, lr=3.422702e-06\n",
      "training set RMSE 1 cycle: 81.295, 10 cycle: 59.698, 100 cycle: 57.747\n",
      "testing set RMSE 1 cycle: 71.041, 10 cycle: 66.473, 100 cycle: 66.393\n",
      "epoch:[50 / 1000] batch:[30 / 134] loss= 0.212\n",
      "epoch:[50 / 1000] batch:[60 / 134] loss= 0.096\n",
      "epoch:[50 / 1000] batch:[90 / 134] loss= 0.096\n",
      "epoch:[50 / 1000] batch:[120 / 134] loss= 0.079\n",
      "100 cycles trn_loss: 0.144, val_loss: 0.226, lr=1.000000e-06\n",
      "training set RMSE 1 cycle: 79.927, 10 cycle: 58.116, 100 cycle: 55.230\n",
      "testing set RMSE 1 cycle: 69.480, 10 cycle: 64.517, 100 cycle: 63.457\n",
      "epoch:[51 / 1000] batch:[30 / 134] loss= 0.097\n",
      "epoch:[51 / 1000] batch:[60 / 134] loss= 0.134\n",
      "epoch:[51 / 1000] batch:[90 / 134] loss= 0.191\n",
      "epoch:[51 / 1000] batch:[120 / 134] loss= 0.112\n",
      "100 cycles trn_loss: 0.134, val_loss: 0.218, lr=3.422702e-06\n",
      "training set RMSE 1 cycle: 80.162, 10 cycle: 57.403, 100 cycle: 53.019\n",
      "testing set RMSE 1 cycle: 69.485, 10 cycle: 64.495, 100 cycle: 62.162\n",
      "epoch:[52 / 1000] batch:[30 / 134] loss= 0.112\n",
      "epoch:[52 / 1000] batch:[60 / 134] loss= 0.221\n",
      "epoch:[52 / 1000] batch:[90 / 134] loss= 0.143\n",
      "epoch:[52 / 1000] batch:[120 / 134] loss= 0.208\n",
      "100 cycles trn_loss: 0.136, val_loss: 0.221, lr=1.045366e-05\n",
      "training set RMSE 1 cycle: 79.991, 10 cycle: 57.436, 100 cycle: 53.571\n",
      "testing set RMSE 1 cycle: 69.914, 10 cycle: 64.545, 100 cycle: 62.693\n",
      "epoch:[53 / 1000] batch:[30 / 134] loss= 0.115\n",
      "epoch:[53 / 1000] batch:[60 / 134] loss= 0.122\n",
      "epoch:[53 / 1000] batch:[90 / 134] loss= 0.157\n",
      "epoch:[53 / 1000] batch:[120 / 134] loss= 0.198\n",
      "100 cycles trn_loss: 0.132, val_loss: 0.219, lr=2.140463e-05\n",
      "training set RMSE 1 cycle: 80.148, 10 cycle: 57.076, 100 cycle: 52.663\n",
      "testing set RMSE 1 cycle: 70.354, 10 cycle: 64.591, 100 cycle: 62.332\n",
      "epoch:[54 / 1000] batch:[30 / 134] loss= 0.072\n",
      "epoch:[54 / 1000] batch:[60 / 134] loss= 0.187\n",
      "epoch:[54 / 1000] batch:[90 / 134] loss= 0.185\n",
      "epoch:[54 / 1000] batch:[120 / 134] loss= 0.071\n",
      "100 cycles trn_loss: 0.137, val_loss: 0.217, lr=3.520366e-05\n",
      "training set RMSE 1 cycle: 77.454, 10 cycle: 57.213, 100 cycle: 53.437\n",
      "testing set RMSE 1 cycle: 68.384, 10 cycle: 63.890, 100 cycle: 61.879\n",
      "epoch:[55 / 1000] batch:[30 / 134] loss= 0.216\n",
      "epoch:[55 / 1000] batch:[60 / 134] loss= 0.159\n",
      "epoch:[55 / 1000] batch:[90 / 134] loss= 0.146\n",
      "epoch:[55 / 1000] batch:[120 / 134] loss= 0.146\n",
      "100 cycles trn_loss: 0.137, val_loss: 0.202, lr=5.050000e-05\n",
      "training set RMSE 1 cycle: 78.410, 10 cycle: 59.111, 100 cycle: 52.334\n",
      "testing set RMSE 1 cycle: 68.055, 10 cycle: 63.650, 100 cycle: 59.222\n",
      "epoch:[56 / 1000] batch:[30 / 134] loss= 0.186\n",
      "epoch:[56 / 1000] batch:[60 / 134] loss= 0.094\n",
      "epoch:[56 / 1000] batch:[90 / 134] loss= 0.192\n",
      "epoch:[56 / 1000] batch:[120 / 134] loss= 0.158\n",
      "100 cycles trn_loss: 0.130, val_loss: 0.215, lr=6.579634e-05\n",
      "training set RMSE 1 cycle: 77.082, 10 cycle: 56.647, 100 cycle: 51.916\n",
      "testing set RMSE 1 cycle: 69.724, 10 cycle: 64.356, 100 cycle: 61.756\n",
      "epoch:[57 / 1000] batch:[30 / 134] loss= 0.200\n",
      "epoch:[57 / 1000] batch:[60 / 134] loss= 0.139\n",
      "epoch:[57 / 1000] batch:[90 / 134] loss= 0.292\n",
      "epoch:[57 / 1000] batch:[120 / 134] loss= 0.195\n",
      "100 cycles trn_loss: 0.157, val_loss: 0.235, lr=7.959537e-05\n",
      "training set RMSE 1 cycle: 80.474, 10 cycle: 59.655, 100 cycle: 57.963\n",
      "testing set RMSE 1 cycle: 68.222, 10 cycle: 65.209, 100 cycle: 65.092\n",
      "epoch:[58 / 1000] batch:[30 / 134] loss= 0.116\n",
      "epoch:[58 / 1000] batch:[60 / 134] loss= 0.091\n",
      "epoch:[58 / 1000] batch:[90 / 134] loss= 0.200\n",
      "epoch:[58 / 1000] batch:[120 / 134] loss= 0.091\n",
      "100 cycles trn_loss: 0.135, val_loss: 0.207, lr=9.054634e-05\n",
      "training set RMSE 1 cycle: 77.225, 10 cycle: 59.755, 100 cycle: 51.675\n",
      "testing set RMSE 1 cycle: 68.597, 10 cycle: 64.921, 100 cycle: 59.974\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:[59 / 1000] batch:[30 / 134] loss= 0.182\n",
      "epoch:[59 / 1000] batch:[60 / 134] loss= 0.226\n",
      "epoch:[59 / 1000] batch:[90 / 134] loss= 0.112\n",
      "epoch:[59 / 1000] batch:[120 / 134] loss= 0.101\n",
      "100 cycles trn_loss: 0.128, val_loss: 0.204, lr=9.757730e-05\n",
      "training set RMSE 1 cycle: 81.028, 10 cycle: 57.338, 100 cycle: 51.460\n",
      "testing set RMSE 1 cycle: 67.953, 10 cycle: 63.242, 100 cycle: 59.845\n",
      "epoch:[60 / 1000] batch:[30 / 134] loss= 0.220\n",
      "epoch:[60 / 1000] batch:[60 / 134] loss= 0.118\n",
      "epoch:[60 / 1000] batch:[90 / 134] loss= 0.190\n",
      "epoch:[60 / 1000] batch:[120 / 134] loss= 0.218\n",
      "100 cycles trn_loss: 0.162, val_loss: 0.251, lr=1.000000e-04\n",
      "training set RMSE 1 cycle: 79.146, 10 cycle: 60.612, 100 cycle: 59.033\n",
      "testing set RMSE 1 cycle: 70.484, 10 cycle: 67.254, 100 cycle: 67.742\n",
      "epoch:[61 / 1000] batch:[30 / 134] loss= 0.194\n",
      "epoch:[61 / 1000] batch:[60 / 134] loss= 0.226\n",
      "epoch:[61 / 1000] batch:[90 / 134] loss= 0.186\n",
      "epoch:[61 / 1000] batch:[120 / 134] loss= 0.047\n",
      "100 cycles trn_loss: 0.129, val_loss: 0.209, lr=9.757730e-05\n",
      "training set RMSE 1 cycle: 77.663, 10 cycle: 58.549, 100 cycle: 50.746\n",
      "testing set RMSE 1 cycle: 68.974, 10 cycle: 65.346, 100 cycle: 60.515\n",
      "epoch:[62 / 1000] batch:[30 / 134] loss= 0.062\n",
      "epoch:[62 / 1000] batch:[60 / 134] loss= 0.149\n",
      "epoch:[62 / 1000] batch:[90 / 134] loss= 0.117\n",
      "epoch:[62 / 1000] batch:[120 / 134] loss= 0.144\n",
      "100 cycles trn_loss: 0.182, val_loss: 0.274, lr=9.054634e-05\n",
      "training set RMSE 1 cycle: 79.329, 10 cycle: 63.955, 100 cycle: 63.457\n",
      "testing set RMSE 1 cycle: 72.427, 10 cycle: 70.418, 100 cycle: 71.675\n",
      "epoch:[63 / 1000] batch:[30 / 134] loss= 0.201\n",
      "epoch:[63 / 1000] batch:[60 / 134] loss= 0.175\n",
      "epoch:[63 / 1000] batch:[90 / 134] loss= 0.184\n",
      "epoch:[63 / 1000] batch:[120 / 134] loss= 0.288\n",
      "100 cycles trn_loss: 0.199, val_loss: 0.314, lr=7.959537e-05\n",
      "training set RMSE 1 cycle: 79.619, 10 cycle: 67.318, 100 cycle: 66.645\n",
      "testing set RMSE 1 cycle: 76.590, 10 cycle: 76.504, 100 cycle: 77.785\n",
      "epoch:[64 / 1000] batch:[30 / 134] loss= 0.258\n",
      "epoch:[64 / 1000] batch:[60 / 134] loss= 0.270\n",
      "epoch:[64 / 1000] batch:[90 / 134] loss= 0.161\n",
      "epoch:[64 / 1000] batch:[120 / 134] loss= 0.194\n",
      "100 cycles trn_loss: 0.170, val_loss: 0.250, lr=6.579634e-05\n",
      "training set RMSE 1 cycle: 73.858, 10 cycle: 62.166, 100 cycle: 60.863\n",
      "testing set RMSE 1 cycle: 70.512, 10 cycle: 68.084, 100 cycle: 68.498\n",
      "epoch:[65 / 1000] batch:[30 / 134] loss= 0.121\n",
      "epoch:[65 / 1000] batch:[60 / 134] loss= 0.052\n",
      "epoch:[65 / 1000] batch:[90 / 134] loss= 0.330\n",
      "epoch:[65 / 1000] batch:[120 / 134] loss= 0.122\n",
      "100 cycles trn_loss: 0.120, val_loss: 0.195, lr=5.050000e-05\n",
      "training set RMSE 1 cycle: 75.965, 10 cycle: 55.513, 100 cycle: 49.787\n",
      "testing set RMSE 1 cycle: 65.022, 10 cycle: 61.806, 100 cycle: 58.410\n",
      "epoch:[66 / 1000] batch:[30 / 134] loss= 0.103\n",
      "epoch:[66 / 1000] batch:[60 / 134] loss= 0.049\n",
      "epoch:[66 / 1000] batch:[90 / 134] loss= 0.176\n",
      "epoch:[66 / 1000] batch:[120 / 134] loss= 0.126\n",
      "100 cycles trn_loss: 0.131, val_loss: 0.220, lr=3.520366e-05\n",
      "training set RMSE 1 cycle: 75.943, 10 cycle: 55.760, 100 cycle: 52.780\n",
      "testing set RMSE 1 cycle: 65.560, 10 cycle: 63.115, 100 cycle: 62.319\n",
      "epoch:[67 / 1000] batch:[30 / 134] loss= 0.209\n",
      "epoch:[67 / 1000] batch:[60 / 134] loss= 0.234\n",
      "epoch:[67 / 1000] batch:[90 / 134] loss= 0.111\n",
      "epoch:[67 / 1000] batch:[120 / 134] loss= 0.090\n",
      "100 cycles trn_loss: 0.130, val_loss: 0.221, lr=2.140463e-05\n",
      "training set RMSE 1 cycle: 75.045, 10 cycle: 55.745, 100 cycle: 52.474\n",
      "testing set RMSE 1 cycle: 65.895, 10 cycle: 63.501, 100 cycle: 62.515\n",
      "epoch:[68 / 1000] batch:[30 / 134] loss= 0.132\n",
      "epoch:[68 / 1000] batch:[60 / 134] loss= 0.079\n",
      "epoch:[68 / 1000] batch:[90 / 134] loss= 0.123\n",
      "epoch:[68 / 1000] batch:[120 / 134] loss= 0.111\n",
      "100 cycles trn_loss: 0.117, val_loss: 0.198, lr=1.045366e-05\n",
      "training set RMSE 1 cycle: 73.196, 10 cycle: 54.188, 100 cycle: 49.330\n",
      "testing set RMSE 1 cycle: 64.847, 10 cycle: 61.735, 100 cycle: 58.868\n",
      "epoch:[69 / 1000] batch:[30 / 134] loss= 0.090\n",
      "epoch:[69 / 1000] batch:[60 / 134] loss= 0.203\n",
      "epoch:[69 / 1000] batch:[90 / 134] loss= 0.134\n",
      "epoch:[69 / 1000] batch:[120 / 134] loss= 0.175\n",
      "100 cycles trn_loss: 0.126, val_loss: 0.202, lr=3.422702e-06\n",
      "training set RMSE 1 cycle: 72.322, 10 cycle: 54.408, 100 cycle: 51.717\n",
      "testing set RMSE 1 cycle: 64.407, 10 cycle: 60.485, 100 cycle: 59.505\n",
      "epoch:[70 / 1000] batch:[30 / 134] loss= 0.183\n",
      "epoch:[70 / 1000] batch:[60 / 134] loss= 0.149\n",
      "epoch:[70 / 1000] batch:[90 / 134] loss= 0.101\n",
      "epoch:[70 / 1000] batch:[120 / 134] loss= 0.125\n",
      "100 cycles trn_loss: 0.122, val_loss: 0.195, lr=1.000000e-06\n",
      "training set RMSE 1 cycle: 71.711, 10 cycle: 53.834, 100 cycle: 50.724\n",
      "testing set RMSE 1 cycle: 63.533, 10 cycle: 59.802, 100 cycle: 58.302\n",
      "epoch:[71 / 1000] batch:[30 / 134] loss= 0.121\n",
      "epoch:[71 / 1000] batch:[60 / 134] loss= 0.167\n",
      "epoch:[71 / 1000] batch:[90 / 134] loss= 0.196\n",
      "epoch:[71 / 1000] batch:[120 / 134] loss= 0.138\n",
      "100 cycles trn_loss: 0.113, val_loss: 0.181, lr=3.422702e-06\n",
      "training set RMSE 1 cycle: 72.056, 10 cycle: 53.365, 100 cycle: 48.515\n",
      "testing set RMSE 1 cycle: 62.689, 10 cycle: 59.110, 100 cycle: 56.072\n",
      "epoch:[72 / 1000] batch:[30 / 134] loss= 0.087\n",
      "epoch:[72 / 1000] batch:[60 / 134] loss= 0.218\n",
      "epoch:[72 / 1000] batch:[90 / 134] loss= 0.168\n",
      "epoch:[72 / 1000] batch:[120 / 134] loss= 0.226\n",
      "100 cycles trn_loss: 0.113, val_loss: 0.186, lr=1.045366e-05\n",
      "training set RMSE 1 cycle: 71.440, 10 cycle: 53.177, 100 cycle: 48.397\n",
      "testing set RMSE 1 cycle: 63.196, 10 cycle: 60.073, 100 cycle: 56.984\n",
      "epoch:[73 / 1000] batch:[30 / 134] loss= 0.155\n",
      "epoch:[73 / 1000] batch:[60 / 134] loss= 0.056\n",
      "epoch:[73 / 1000] batch:[90 / 134] loss= 0.130\n",
      "epoch:[73 / 1000] batch:[120 / 134] loss= 0.104\n",
      "100 cycles trn_loss: 0.109, val_loss: 0.191, lr=2.140463e-05\n",
      "training set RMSE 1 cycle: 71.889, 10 cycle: 54.368, 100 cycle: 46.671\n",
      "testing set RMSE 1 cycle: 63.875, 10 cycle: 62.484, 100 cycle: 57.741\n",
      "epoch:[74 / 1000] batch:[30 / 134] loss= 0.110\n",
      "epoch:[74 / 1000] batch:[60 / 134] loss= 0.153\n",
      "epoch:[74 / 1000] batch:[90 / 134] loss= 0.074\n",
      "epoch:[74 / 1000] batch:[120 / 134] loss= 0.127\n",
      "100 cycles trn_loss: 0.110, val_loss: 0.176, lr=3.520366e-05\n",
      "training set RMSE 1 cycle: 70.068, 10 cycle: 52.261, 100 cycle: 47.839\n",
      "testing set RMSE 1 cycle: 60.675, 10 cycle: 57.824, 100 cycle: 55.268\n",
      "epoch:[75 / 1000] batch:[30 / 134] loss= 0.141\n",
      "epoch:[75 / 1000] batch:[60 / 134] loss= 0.103\n",
      "epoch:[75 / 1000] batch:[90 / 134] loss= 0.317\n",
      "epoch:[75 / 1000] batch:[120 / 134] loss= 0.105\n",
      "100 cycles trn_loss: 0.114, val_loss: 0.177, lr=5.050000e-05\n",
      "training set RMSE 1 cycle: 77.825, 10 cycle: 56.550, 100 cycle: 47.396\n",
      "testing set RMSE 1 cycle: 63.774, 10 cycle: 61.386, 100 cycle: 55.419\n",
      "epoch:[76 / 1000] batch:[30 / 134] loss= 0.136\n",
      "epoch:[76 / 1000] batch:[60 / 134] loss= 0.151\n",
      "epoch:[76 / 1000] batch:[90 / 134] loss= 0.152\n",
      "epoch:[76 / 1000] batch:[120 / 134] loss= 0.115\n",
      "100 cycles trn_loss: 0.196, val_loss: 0.294, lr=6.579634e-05\n",
      "training set RMSE 1 cycle: 79.476, 10 cycle: 66.217, 100 cycle: 66.236\n",
      "testing set RMSE 1 cycle: 74.695, 10 cycle: 73.474, 100 cycle: 75.105\n",
      "epoch:[77 / 1000] batch:[30 / 134] loss= 0.048\n",
      "epoch:[77 / 1000] batch:[60 / 134] loss= 0.176\n",
      "epoch:[77 / 1000] batch:[90 / 134] loss= 0.142\n",
      "epoch:[77 / 1000] batch:[120 / 134] loss= 0.212\n",
      "100 cycles trn_loss: 0.138, val_loss: 0.242, lr=7.959537e-05\n",
      "training set RMSE 1 cycle: 70.249, 10 cycle: 56.053, 100 cycle: 53.924\n",
      "testing set RMSE 1 cycle: 65.773, 10 cycle: 64.896, 100 cycle: 65.569\n",
      "epoch:[78 / 1000] batch:[30 / 134] loss= 0.097\n",
      "epoch:[78 / 1000] batch:[60 / 134] loss= 0.253\n",
      "epoch:[78 / 1000] batch:[90 / 134] loss= 0.083\n",
      "epoch:[78 / 1000] batch:[120 / 134] loss= 0.211\n",
      "100 cycles trn_loss: 0.161, val_loss: 0.213, lr=9.054634e-05\n",
      "training set RMSE 1 cycle: 85.332, 10 cycle: 69.066, 100 cycle: 54.159\n",
      "testing set RMSE 1 cycle: 71.785, 10 cycle: 70.878, 100 cycle: 61.622\n",
      "epoch:[79 / 1000] batch:[30 / 134] loss= 0.083\n",
      "epoch:[79 / 1000] batch:[60 / 134] loss= 0.130\n",
      "epoch:[79 / 1000] batch:[90 / 134] loss= 0.189\n",
      "epoch:[79 / 1000] batch:[120 / 134] loss= 0.171\n",
      "100 cycles trn_loss: 0.133, val_loss: 0.211, lr=9.757730e-05\n",
      "training set RMSE 1 cycle: 69.718, 10 cycle: 55.639, 100 cycle: 52.998\n",
      "testing set RMSE 1 cycle: 64.275, 10 cycle: 61.919, 100 cycle: 61.072\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:[80 / 1000] batch:[30 / 134] loss= 0.160\n",
      "epoch:[80 / 1000] batch:[60 / 134] loss= 0.105\n",
      "epoch:[80 / 1000] batch:[90 / 134] loss= 0.203\n",
      "epoch:[80 / 1000] batch:[120 / 134] loss= 0.150\n",
      "100 cycles trn_loss: 0.140, val_loss: 0.197, lr=1.000000e-04\n",
      "training set RMSE 1 cycle: 81.816, 10 cycle: 64.357, 100 cycle: 51.128\n",
      "testing set RMSE 1 cycle: 68.527, 10 cycle: 66.571, 100 cycle: 58.779\n",
      "epoch:[81 / 1000] batch:[30 / 134] loss= 0.091\n",
      "epoch:[81 / 1000] batch:[60 / 134] loss= 0.145\n",
      "epoch:[81 / 1000] batch:[90 / 134] loss= 0.101\n",
      "epoch:[81 / 1000] batch:[120 / 134] loss= 0.207\n",
      "100 cycles trn_loss: 0.113, val_loss: 0.187, lr=9.757730e-05\n",
      "training set RMSE 1 cycle: 75.421, 10 cycle: 56.883, 100 cycle: 47.253\n",
      "testing set RMSE 1 cycle: 65.290, 10 cycle: 63.389, 100 cycle: 57.157\n",
      "epoch:[82 / 1000] batch:[30 / 134] loss= 0.157\n",
      "epoch:[82 / 1000] batch:[60 / 134] loss= 0.227\n",
      "epoch:[82 / 1000] batch:[90 / 134] loss= 0.083\n",
      "epoch:[82 / 1000] batch:[120 / 134] loss= 0.309\n",
      "100 cycles trn_loss: 0.189, val_loss: 0.296, lr=9.054634e-05\n",
      "training set RMSE 1 cycle: 77.776, 10 cycle: 65.618, 100 cycle: 65.038\n",
      "testing set RMSE 1 cycle: 74.220, 10 cycle: 73.661, 100 cycle: 75.276\n",
      "epoch:[83 / 1000] batch:[30 / 134] loss= 0.047\n",
      "epoch:[83 / 1000] batch:[60 / 134] loss= 0.101\n",
      "epoch:[83 / 1000] batch:[90 / 134] loss= 0.077\n",
      "epoch:[83 / 1000] batch:[120 / 134] loss= 0.116\n",
      "100 cycles trn_loss: 0.135, val_loss: 0.191, lr=7.959537e-05\n",
      "training set RMSE 1 cycle: 69.868, 10 cycle: 55.498, 100 cycle: 53.152\n",
      "testing set RMSE 1 cycle: 61.654, 10 cycle: 58.849, 100 cycle: 57.945\n",
      "epoch:[84 / 1000] batch:[30 / 134] loss= 0.155\n",
      "epoch:[84 / 1000] batch:[60 / 134] loss= 0.252\n",
      "epoch:[84 / 1000] batch:[90 / 134] loss= 0.137\n",
      "epoch:[84 / 1000] batch:[120 / 134] loss= 0.221\n",
      "100 cycles trn_loss: 0.197, val_loss: 0.291, lr=6.579634e-05\n",
      "training set RMSE 1 cycle: 82.852, 10 cycle: 66.337, 100 cycle: 66.307\n",
      "testing set RMSE 1 cycle: 83.991, 10 cycle: 74.294, 100 cycle: 75.456\n",
      "epoch:[85 / 1000] batch:[30 / 134] loss= 0.247\n",
      "epoch:[85 / 1000] batch:[60 / 134] loss= 0.067\n",
      "epoch:[85 / 1000] batch:[90 / 134] loss= 0.092\n",
      "epoch:[85 / 1000] batch:[120 / 134] loss= 0.173\n",
      "100 cycles trn_loss: 0.106, val_loss: 0.192, lr=5.050000e-05\n",
      "training set RMSE 1 cycle: 70.526, 10 cycle: 54.109, 100 cycle: 46.198\n",
      "testing set RMSE 1 cycle: 63.740, 10 cycle: 62.383, 100 cycle: 58.048\n",
      "epoch:[86 / 1000] batch:[30 / 134] loss= 0.071\n",
      "epoch:[86 / 1000] batch:[60 / 134] loss= 0.105\n",
      "epoch:[86 / 1000] batch:[90 / 134] loss= 0.153\n",
      "epoch:[86 / 1000] batch:[120 / 134] loss= 0.106\n",
      "100 cycles trn_loss: 0.109, val_loss: 0.180, lr=3.520366e-05\n",
      "training set RMSE 1 cycle: 65.270, 10 cycle: 51.624, 100 cycle: 47.562\n",
      "testing set RMSE 1 cycle: 58.944, 10 cycle: 57.233, 100 cycle: 55.881\n",
      "epoch:[87 / 1000] batch:[30 / 134] loss= 0.035\n",
      "epoch:[87 / 1000] batch:[60 / 134] loss= 0.073\n",
      "epoch:[87 / 1000] batch:[90 / 134] loss= 0.160\n",
      "epoch:[87 / 1000] batch:[120 / 134] loss= 0.235\n",
      "100 cycles trn_loss: 0.101, val_loss: 0.168, lr=2.140463e-05\n",
      "training set RMSE 1 cycle: 66.357, 10 cycle: 51.420, 100 cycle: 45.574\n",
      "testing set RMSE 1 cycle: 58.761, 10 cycle: 56.647, 100 cycle: 54.100\n",
      "epoch:[88 / 1000] batch:[30 / 134] loss= 0.341\n",
      "epoch:[88 / 1000] batch:[60 / 134] loss= 0.113\n",
      "epoch:[88 / 1000] batch:[90 / 134] loss= 0.153\n",
      "epoch:[88 / 1000] batch:[120 / 134] loss= 0.183\n",
      "100 cycles trn_loss: 0.101, val_loss: 0.165, lr=1.045366e-05\n",
      "training set RMSE 1 cycle: 63.375, 10 cycle: 50.696, 100 cycle: 45.449\n",
      "testing set RMSE 1 cycle: 57.783, 10 cycle: 55.989, 100 cycle: 53.552\n",
      "epoch:[89 / 1000] batch:[30 / 134] loss= 0.199\n",
      "epoch:[89 / 1000] batch:[60 / 134] loss= 0.146\n",
      "epoch:[89 / 1000] batch:[90 / 134] loss= 0.172\n",
      "epoch:[89 / 1000] batch:[120 / 134] loss= 0.164\n",
      "100 cycles trn_loss: 0.102, val_loss: 0.163, lr=3.422702e-06\n",
      "training set RMSE 1 cycle: 61.096, 10 cycle: 50.389, 100 cycle: 45.858\n",
      "testing set RMSE 1 cycle: 56.649, 10 cycle: 54.917, 100 cycle: 53.132\n",
      "epoch:[90 / 1000] batch:[30 / 134] loss= 0.145\n",
      "epoch:[90 / 1000] batch:[60 / 134] loss= 0.110\n",
      "epoch:[90 / 1000] batch:[90 / 134] loss= 0.140\n",
      "epoch:[90 / 1000] batch:[120 / 134] loss= 0.092\n",
      "100 cycles trn_loss: 0.102, val_loss: 0.167, lr=1.000000e-06\n",
      "training set RMSE 1 cycle: 60.328, 10 cycle: 50.098, 100 cycle: 45.971\n",
      "testing set RMSE 1 cycle: 56.829, 10 cycle: 55.342, 100 cycle: 53.860\n",
      "epoch:[91 / 1000] batch:[30 / 134] loss= 0.069\n",
      "epoch:[91 / 1000] batch:[60 / 134] loss= 0.169\n",
      "epoch:[91 / 1000] batch:[90 / 134] loss= 0.067\n",
      "epoch:[91 / 1000] batch:[120 / 134] loss= 0.220\n",
      "100 cycles trn_loss: 0.100, val_loss: 0.164, lr=3.422702e-06\n",
      "training set RMSE 1 cycle: 60.797, 10 cycle: 50.063, 100 cycle: 45.339\n",
      "testing set RMSE 1 cycle: 56.730, 10 cycle: 55.313, 100 cycle: 53.343\n",
      "epoch:[92 / 1000] batch:[30 / 134] loss= 0.130\n",
      "epoch:[92 / 1000] batch:[60 / 134] loss= 0.090\n",
      "epoch:[92 / 1000] batch:[90 / 134] loss= 0.208\n",
      "epoch:[92 / 1000] batch:[120 / 134] loss= 0.042\n",
      "100 cycles trn_loss: 0.105, val_loss: 0.172, lr=1.045366e-05\n",
      "training set RMSE 1 cycle: 60.278, 10 cycle: 49.993, 100 cycle: 46.714\n",
      "testing set RMSE 1 cycle: 56.823, 10 cycle: 55.285, 100 cycle: 54.641\n",
      "epoch:[93 / 1000] batch:[30 / 134] loss= 0.092\n",
      "epoch:[93 / 1000] batch:[60 / 134] loss= 0.039\n",
      "epoch:[93 / 1000] batch:[90 / 134] loss= 0.106\n",
      "epoch:[93 / 1000] batch:[120 / 134] loss= 0.059\n",
      "100 cycles trn_loss: 0.107, val_loss: 0.169, lr=2.140463e-05\n",
      "training set RMSE 1 cycle: 61.599, 10 cycle: 50.195, 100 cycle: 47.276\n",
      "testing set RMSE 1 cycle: 56.004, 10 cycle: 54.169, 100 cycle: 54.142\n",
      "epoch:[94 / 1000] batch:[30 / 134] loss= 0.094\n",
      "epoch:[94 / 1000] batch:[60 / 134] loss= 0.060\n",
      "epoch:[94 / 1000] batch:[90 / 134] loss= 0.136\n",
      "epoch:[94 / 1000] batch:[120 / 134] loss= 0.145\n",
      "100 cycles trn_loss: 0.106, val_loss: 0.164, lr=3.520366e-05\n",
      "training set RMSE 1 cycle: 61.328, 10 cycle: 50.011, 100 cycle: 47.231\n",
      "testing set RMSE 1 cycle: 55.055, 10 cycle: 53.126, 100 cycle: 53.298\n",
      "epoch:[95 / 1000] batch:[30 / 134] loss= 0.074\n",
      "epoch:[95 / 1000] batch:[60 / 134] loss= 0.165\n",
      "epoch:[95 / 1000] batch:[90 / 134] loss= 0.110\n",
      "epoch:[95 / 1000] batch:[120 / 134] loss= 0.113\n",
      "100 cycles trn_loss: 0.107, val_loss: 0.179, lr=5.050000e-05\n",
      "training set RMSE 1 cycle: 60.572, 10 cycle: 50.209, 100 cycle: 47.093\n",
      "testing set RMSE 1 cycle: 57.877, 10 cycle: 56.049, 100 cycle: 55.919\n",
      "epoch:[96 / 1000] batch:[30 / 134] loss= 0.078\n",
      "epoch:[96 / 1000] batch:[60 / 134] loss= 0.126\n",
      "epoch:[96 / 1000] batch:[90 / 134] loss= 0.111\n",
      "epoch:[96 / 1000] batch:[120 / 134] loss= 0.230\n",
      "100 cycles trn_loss: 0.112, val_loss: 0.177, lr=6.579634e-05\n",
      "training set RMSE 1 cycle: 66.062, 10 cycle: 51.300, 100 cycle: 48.425\n",
      "testing set RMSE 1 cycle: 56.826, 10 cycle: 54.860, 100 cycle: 55.420\n",
      "epoch:[97 / 1000] batch:[30 / 134] loss= 0.291\n",
      "epoch:[97 / 1000] batch:[60 / 134] loss= 0.060\n",
      "epoch:[97 / 1000] batch:[90 / 134] loss= 0.287\n",
      "epoch:[97 / 1000] batch:[120 / 134] loss= 0.111\n",
      "100 cycles trn_loss: 0.201, val_loss: 0.301, lr=7.959537e-05\n",
      "training set RMSE 1 cycle: 79.063, 10 cycle: 65.853, 100 cycle: 66.822\n",
      "testing set RMSE 1 cycle: 74.932, 10 cycle: 74.983, 100 cycle: 76.562\n",
      "epoch:[98 / 1000] batch:[30 / 134] loss= 0.041\n",
      "epoch:[98 / 1000] batch:[60 / 134] loss= 0.098\n",
      "epoch:[98 / 1000] batch:[90 / 134] loss= 0.180\n",
      "epoch:[98 / 1000] batch:[120 / 134] loss= 0.045\n",
      "100 cycles trn_loss: 0.116, val_loss: 0.176, lr=9.054634e-05\n",
      "training set RMSE 1 cycle: 65.208, 10 cycle: 55.146, 100 cycle: 48.187\n",
      "testing set RMSE 1 cycle: 60.529, 10 cycle: 59.355, 100 cycle: 55.288\n",
      "epoch:[99 / 1000] batch:[30 / 134] loss= 0.189\n",
      "epoch:[99 / 1000] batch:[60 / 134] loss= 0.129\n",
      "epoch:[99 / 1000] batch:[90 / 134] loss= 0.178\n",
      "epoch:[99 / 1000] batch:[120 / 134] loss= 0.232\n",
      "100 cycles trn_loss: 0.110, val_loss: 0.146, lr=9.757730e-05\n",
      "training set RMSE 1 cycle: 68.480, 10 cycle: 53.669, 100 cycle: 46.722\n",
      "testing set RMSE 1 cycle: 57.947, 10 cycle: 54.600, 100 cycle: 50.219\n",
      "epoch:[100 / 1000] batch:[30 / 134] loss= 0.108\n",
      "epoch:[100 / 1000] batch:[60 / 134] loss= 0.199\n",
      "epoch:[100 / 1000] batch:[90 / 134] loss= 0.183\n",
      "epoch:[100 / 1000] batch:[120 / 134] loss= 0.043\n",
      "100 cycles trn_loss: 0.159, val_loss: 0.251, lr=1.000000e-04\n",
      "training set RMSE 1 cycle: 67.701, 10 cycle: 58.992, 100 cycle: 58.595\n",
      "testing set RMSE 1 cycle: 67.031, 10 cycle: 65.476, 100 cycle: 67.460\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:[101 / 1000] batch:[30 / 134] loss= 0.245\n",
      "epoch:[101 / 1000] batch:[60 / 134] loss= 0.220\n",
      "epoch:[101 / 1000] batch:[90 / 134] loss= 0.175\n",
      "epoch:[101 / 1000] batch:[120 / 134] loss= 0.181\n",
      "100 cycles trn_loss: 0.126, val_loss: 0.196, lr=9.757730e-05\n",
      "training set RMSE 1 cycle: 69.061, 10 cycle: 53.891, 100 cycle: 51.457\n",
      "testing set RMSE 1 cycle: 60.344, 10 cycle: 58.568, 100 cycle: 58.441\n",
      "epoch:[102 / 1000] batch:[30 / 134] loss= 0.079\n",
      "epoch:[102 / 1000] batch:[60 / 134] loss= 0.095\n",
      "epoch:[102 / 1000] batch:[90 / 134] loss= 0.126\n",
      "epoch:[102 / 1000] batch:[120 / 134] loss= 0.162\n",
      "100 cycles trn_loss: 0.104, val_loss: 0.151, lr=9.054634e-05\n",
      "training set RMSE 1 cycle: 68.147, 10 cycle: 56.006, 100 cycle: 44.838\n",
      "testing set RMSE 1 cycle: 60.976, 10 cycle: 58.832, 100 cycle: 51.121\n",
      "epoch:[103 / 1000] batch:[30 / 134] loss= 0.115\n",
      "epoch:[103 / 1000] batch:[60 / 134] loss= 0.120\n",
      "epoch:[103 / 1000] batch:[90 / 134] loss= 0.175\n",
      "epoch:[103 / 1000] batch:[120 / 134] loss= 0.114\n",
      "100 cycles trn_loss: 0.107, val_loss: 0.180, lr=7.959537e-05\n",
      "training set RMSE 1 cycle: 65.477, 10 cycle: 53.631, 100 cycle: 46.506\n",
      "testing set RMSE 1 cycle: 61.398, 10 cycle: 60.400, 100 cycle: 56.025\n",
      "epoch:[104 / 1000] batch:[30 / 134] loss= 0.211\n",
      "epoch:[104 / 1000] batch:[60 / 134] loss= 0.097\n",
      "epoch:[104 / 1000] batch:[90 / 134] loss= 0.166\n",
      "epoch:[104 / 1000] batch:[120 / 134] loss= 0.130\n",
      "100 cycles trn_loss: 0.118, val_loss: 0.177, lr=6.579634e-05\n",
      "training set RMSE 1 cycle: 63.086, 10 cycle: 51.946, 100 cycle: 49.386\n",
      "testing set RMSE 1 cycle: 58.184, 10 cycle: 55.457, 100 cycle: 55.367\n",
      "epoch:[105 / 1000] batch:[30 / 134] loss= 0.109\n",
      "epoch:[105 / 1000] batch:[60 / 134] loss= 0.152\n",
      "epoch:[105 / 1000] batch:[90 / 134] loss= 0.172\n",
      "epoch:[105 / 1000] batch:[120 / 134] loss= 0.080\n",
      "100 cycles trn_loss: 0.144, val_loss: 0.183, lr=5.050000e-05\n",
      "training set RMSE 1 cycle: 64.537, 10 cycle: 56.786, 100 cycle: 54.652\n",
      "testing set RMSE 1 cycle: 60.161, 10 cycle: 57.339, 100 cycle: 56.915\n",
      "epoch:[106 / 1000] batch:[30 / 134] loss= 0.116\n",
      "epoch:[106 / 1000] batch:[60 / 134] loss= 0.202\n",
      "epoch:[106 / 1000] batch:[90 / 134] loss= 0.061\n",
      "epoch:[106 / 1000] batch:[120 / 134] loss= 0.117\n",
      "100 cycles trn_loss: 0.180, val_loss: 0.276, lr=3.520366e-05\n",
      "training set RMSE 1 cycle: 72.258, 10 cycle: 62.649, 100 cycle: 63.112\n",
      "testing set RMSE 1 cycle: 69.594, 10 cycle: 68.699, 100 cycle: 71.595\n",
      "epoch:[107 / 1000] batch:[30 / 134] loss= 0.070\n",
      "epoch:[107 / 1000] batch:[60 / 134] loss= 0.067\n",
      "epoch:[107 / 1000] batch:[90 / 134] loss= 0.057\n",
      "epoch:[107 / 1000] batch:[120 / 134] loss= 0.134\n",
      "100 cycles trn_loss: 0.134, val_loss: 0.218, lr=2.140463e-05\n",
      "training set RMSE 1 cycle: 59.816, 10 cycle: 53.583, 100 cycle: 53.197\n",
      "testing set RMSE 1 cycle: 61.368, 10 cycle: 59.632, 100 cycle: 61.963\n",
      "epoch:[108 / 1000] batch:[30 / 134] loss= 0.151\n",
      "epoch:[108 / 1000] batch:[60 / 134] loss= 0.088\n",
      "epoch:[108 / 1000] batch:[90 / 134] loss= 0.119\n",
      "epoch:[108 / 1000] batch:[120 / 134] loss= 0.099\n",
      "100 cycles trn_loss: 0.101, val_loss: 0.159, lr=1.045366e-05\n",
      "training set RMSE 1 cycle: 57.533, 10 cycle: 49.109, 100 cycle: 45.760\n",
      "testing set RMSE 1 cycle: 54.900, 10 cycle: 53.157, 100 cycle: 52.465\n",
      "epoch:[109 / 1000] batch:[30 / 134] loss= 0.065\n",
      "epoch:[109 / 1000] batch:[60 / 134] loss= 0.173\n",
      "epoch:[109 / 1000] batch:[90 / 134] loss= 0.155\n",
      "epoch:[109 / 1000] batch:[120 / 134] loss= 0.107\n",
      "100 cycles trn_loss: 0.091, val_loss: 0.140, lr=3.422702e-06\n",
      "training set RMSE 1 cycle: 59.445, 10 cycle: 50.373, 100 cycle: 42.572\n",
      "testing set RMSE 1 cycle: 55.152, 10 cycle: 53.712, 100 cycle: 49.296\n",
      "epoch:[110 / 1000] batch:[30 / 134] loss= 0.102\n",
      "epoch:[110 / 1000] batch:[60 / 134] loss= 0.082\n",
      "epoch:[110 / 1000] batch:[90 / 134] loss= 0.067\n",
      "epoch:[110 / 1000] batch:[120 / 134] loss= 0.073\n",
      "100 cycles trn_loss: 0.094, val_loss: 0.147, lr=1.000000e-06\n",
      "training set RMSE 1 cycle: 57.049, 10 cycle: 48.690, 100 cycle: 44.078\n",
      "testing set RMSE 1 cycle: 53.920, 10 cycle: 52.114, 100 cycle: 50.366\n",
      "epoch:[111 / 1000] batch:[30 / 134] loss= 0.174\n",
      "epoch:[111 / 1000] batch:[60 / 134] loss= 0.096\n",
      "epoch:[111 / 1000] batch:[90 / 134] loss= 0.093\n",
      "epoch:[111 / 1000] batch:[120 / 134] loss= 0.115\n",
      "100 cycles trn_loss: 0.097, val_loss: 0.154, lr=3.422702e-06\n",
      "training set RMSE 1 cycle: 56.386, 10 cycle: 48.498, 100 cycle: 44.737\n",
      "testing set RMSE 1 cycle: 54.336, 10 cycle: 52.743, 100 cycle: 51.672\n",
      "epoch:[112 / 1000] batch:[30 / 134] loss= 0.048\n",
      "epoch:[112 / 1000] batch:[60 / 134] loss= 0.104\n",
      "epoch:[112 / 1000] batch:[90 / 134] loss= 0.073\n",
      "epoch:[112 / 1000] batch:[120 / 134] loss= 0.147\n",
      "100 cycles trn_loss: 0.097, val_loss: 0.146, lr=1.045366e-05\n",
      "training set RMSE 1 cycle: 56.083, 10 cycle: 48.671, 100 cycle: 44.652\n",
      "testing set RMSE 1 cycle: 53.403, 10 cycle: 51.701, 100 cycle: 50.353\n",
      "epoch:[113 / 1000] batch:[30 / 134] loss= 0.045\n",
      "epoch:[113 / 1000] batch:[60 / 134] loss= 0.151\n",
      "epoch:[113 / 1000] batch:[90 / 134] loss= 0.086\n",
      "epoch:[113 / 1000] batch:[120 / 134] loss= 0.120\n",
      "100 cycles trn_loss: 0.097, val_loss: 0.138, lr=2.140463e-05\n",
      "training set RMSE 1 cycle: 57.094, 10 cycle: 48.847, 100 cycle: 44.594\n",
      "testing set RMSE 1 cycle: 52.170, 10 cycle: 50.364, 100 cycle: 48.831\n",
      "epoch:[114 / 1000] batch:[30 / 134] loss= 0.162\n",
      "epoch:[114 / 1000] batch:[60 / 134] loss= 0.076\n",
      "epoch:[114 / 1000] batch:[90 / 134] loss= 0.144\n",
      "epoch:[114 / 1000] batch:[120 / 134] loss= 0.047\n",
      "100 cycles trn_loss: 0.103, val_loss: 0.168, lr=3.520366e-05\n",
      "training set RMSE 1 cycle: 54.545, 10 cycle: 48.435, 100 cycle: 46.277\n",
      "testing set RMSE 1 cycle: 54.436, 10 cycle: 53.668, 100 cycle: 54.050\n",
      "epoch:[115 / 1000] batch:[30 / 134] loss= 0.181\n",
      "epoch:[115 / 1000] batch:[60 / 134] loss= 0.056\n",
      "epoch:[115 / 1000] batch:[90 / 134] loss= 0.274\n",
      "epoch:[115 / 1000] batch:[120 / 134] loss= 0.093\n",
      "100 cycles trn_loss: 0.119, val_loss: 0.121, lr=5.050000e-05\n",
      "training set RMSE 1 cycle: 67.085, 10 cycle: 56.406, 100 cycle: 47.614\n",
      "testing set RMSE 1 cycle: 53.722, 10 cycle: 51.324, 100 cycle: 45.813\n",
      "epoch:[116 / 1000] batch:[30 / 134] loss= 0.162\n",
      "epoch:[116 / 1000] batch:[60 / 134] loss= 0.167\n",
      "epoch:[116 / 1000] batch:[90 / 134] loss= 0.176\n",
      "epoch:[116 / 1000] batch:[120 / 134] loss= 0.184\n",
      "100 cycles trn_loss: 0.093, val_loss: 0.153, lr=6.579634e-05\n",
      "training set RMSE 1 cycle: 61.889, 10 cycle: 50.853, 100 cycle: 42.925\n",
      "testing set RMSE 1 cycle: 56.350, 10 cycle: 55.703, 100 cycle: 51.602\n",
      "epoch:[117 / 1000] batch:[30 / 134] loss= 0.167\n",
      "epoch:[117 / 1000] batch:[60 / 134] loss= 0.054\n",
      "epoch:[117 / 1000] batch:[90 / 134] loss= 0.105\n",
      "epoch:[117 / 1000] batch:[120 / 134] loss= 0.119\n",
      "100 cycles trn_loss: 0.160, val_loss: 0.257, lr=7.959537e-05\n",
      "training set RMSE 1 cycle: 64.874, 10 cycle: 57.568, 100 cycle: 58.271\n",
      "testing set RMSE 1 cycle: 64.915, 10 cycle: 64.217, 100 cycle: 67.628\n",
      "epoch:[118 / 1000] batch:[30 / 134] loss= 0.228\n",
      "epoch:[118 / 1000] batch:[60 / 134] loss= 0.100\n",
      "epoch:[118 / 1000] batch:[90 / 134] loss= 0.241\n",
      "epoch:[118 / 1000] batch:[120 / 134] loss= 0.098\n",
      "100 cycles trn_loss: 0.126, val_loss: 0.194, lr=9.054634e-05\n",
      "training set RMSE 1 cycle: 61.781, 10 cycle: 52.642, 100 cycle: 51.729\n",
      "testing set RMSE 1 cycle: 58.236, 10 cycle: 57.153, 100 cycle: 58.259\n",
      "epoch:[119 / 1000] batch:[30 / 134] loss= 0.232\n",
      "epoch:[119 / 1000] batch:[60 / 134] loss= 0.038\n",
      "epoch:[119 / 1000] batch:[90 / 134] loss= 0.151\n",
      "epoch:[119 / 1000] batch:[120 / 134] loss= 0.093\n",
      "100 cycles trn_loss: 0.116, val_loss: 0.206, lr=9.757730e-05\n",
      "training set RMSE 1 cycle: 58.387, 10 cycle: 50.812, 100 cycle: 48.868\n",
      "testing set RMSE 1 cycle: 57.830, 10 cycle: 58.417, 100 cycle: 59.940\n",
      "epoch:[120 / 1000] batch:[30 / 134] loss= 0.149\n",
      "epoch:[120 / 1000] batch:[60 / 134] loss= 0.097\n",
      "epoch:[120 / 1000] batch:[90 / 134] loss= 0.135\n",
      "epoch:[120 / 1000] batch:[120 / 134] loss= 0.181\n",
      "100 cycles trn_loss: 0.095, val_loss: 0.144, lr=1.000000e-04\n",
      "training set RMSE 1 cycle: 56.630, 10 cycle: 51.739, 100 cycle: 43.810\n",
      "testing set RMSE 1 cycle: 56.788, 10 cycle: 55.531, 100 cycle: 49.975\n",
      "epoch:[121 / 1000] batch:[30 / 134] loss= 0.235\n",
      "epoch:[121 / 1000] batch:[60 / 134] loss= 0.157\n",
      "epoch:[121 / 1000] batch:[90 / 134] loss= 0.195\n",
      "epoch:[121 / 1000] batch:[120 / 134] loss= 0.208\n",
      "100 cycles trn_loss: 0.106, val_loss: 0.152, lr=9.757730e-05\n",
      "training set RMSE 1 cycle: 62.223, 10 cycle: 54.423, 100 cycle: 45.196\n",
      "testing set RMSE 1 cycle: 59.028, 10 cycle: 58.318, 100 cycle: 51.359\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:[122 / 1000] batch:[30 / 134] loss= 0.093\n",
      "epoch:[122 / 1000] batch:[60 / 134] loss= 0.089\n",
      "epoch:[122 / 1000] batch:[90 / 134] loss= 0.040\n",
      "epoch:[122 / 1000] batch:[120 / 134] loss= 0.095\n",
      "100 cycles trn_loss: 0.114, val_loss: 0.129, lr=9.054634e-05\n",
      "training set RMSE 1 cycle: 64.888, 10 cycle: 59.631, 100 cycle: 46.011\n",
      "testing set RMSE 1 cycle: 59.940, 10 cycle: 57.398, 100 cycle: 47.200\n",
      "epoch:[123 / 1000] batch:[30 / 134] loss= 0.308\n",
      "epoch:[123 / 1000] batch:[60 / 134] loss= 0.151\n",
      "epoch:[123 / 1000] batch:[90 / 134] loss= 0.144\n",
      "epoch:[123 / 1000] batch:[120 / 134] loss= 0.166\n",
      "100 cycles trn_loss: 0.158, val_loss: 0.254, lr=7.959537e-05\n",
      "training set RMSE 1 cycle: 63.823, 10 cycle: 57.745, 100 cycle: 58.202\n",
      "testing set RMSE 1 cycle: 65.133, 10 cycle: 63.449, 100 cycle: 67.172\n",
      "epoch:[124 / 1000] batch:[30 / 134] loss= 0.126\n",
      "epoch:[124 / 1000] batch:[60 / 134] loss= 0.059\n",
      "epoch:[124 / 1000] batch:[90 / 134] loss= 0.131\n",
      "epoch:[124 / 1000] batch:[120 / 134] loss= 0.140\n",
      "100 cycles trn_loss: 0.095, val_loss: 0.158, lr=6.579634e-05\n",
      "training set RMSE 1 cycle: 52.807, 10 cycle: 48.258, 100 cycle: 43.983\n",
      "testing set RMSE 1 cycle: 54.495, 10 cycle: 53.683, 100 cycle: 52.399\n",
      "epoch:[125 / 1000] batch:[30 / 134] loss= 0.091\n",
      "epoch:[125 / 1000] batch:[60 / 134] loss= 0.071\n",
      "epoch:[125 / 1000] batch:[90 / 134] loss= 0.150\n",
      "epoch:[125 / 1000] batch:[120 / 134] loss= 0.060\n",
      "100 cycles trn_loss: 0.093, val_loss: 0.146, lr=5.050000e-05\n",
      "training set RMSE 1 cycle: 53.735, 10 cycle: 48.487, 100 cycle: 43.586\n",
      "testing set RMSE 1 cycle: 53.402, 10 cycle: 52.183, 100 cycle: 50.367\n",
      "epoch:[126 / 1000] batch:[30 / 134] loss= 0.151\n",
      "epoch:[126 / 1000] batch:[60 / 134] loss= 0.105\n",
      "epoch:[126 / 1000] batch:[90 / 134] loss= 0.242\n",
      "epoch:[126 / 1000] batch:[120 / 134] loss= 0.166\n",
      "100 cycles trn_loss: 0.115, val_loss: 0.183, lr=3.520366e-05\n",
      "training set RMSE 1 cycle: 50.343, 10 cycle: 49.473, 100 cycle: 48.861\n",
      "testing set RMSE 1 cycle: 55.218, 10 cycle: 54.647, 100 cycle: 56.482\n",
      "epoch:[127 / 1000] batch:[30 / 134] loss= 0.071\n",
      "epoch:[127 / 1000] batch:[60 / 134] loss= 0.087\n",
      "epoch:[127 / 1000] batch:[90 / 134] loss= 0.186\n",
      "epoch:[127 / 1000] batch:[120 / 134] loss= 0.160\n",
      "100 cycles trn_loss: 0.093, val_loss: 0.126, lr=2.140463e-05\n",
      "training set RMSE 1 cycle: 51.180, 10 cycle: 48.359, 100 cycle: 43.221\n",
      "testing set RMSE 1 cycle: 50.773, 10 cycle: 48.860, 100 cycle: 46.641\n",
      "epoch:[128 / 1000] batch:[30 / 134] loss= 0.101\n",
      "epoch:[128 / 1000] batch:[60 / 134] loss= 0.087\n",
      "epoch:[128 / 1000] batch:[90 / 134] loss= 0.182\n",
      "epoch:[128 / 1000] batch:[120 / 134] loss= 0.079\n",
      "100 cycles trn_loss: 0.106, val_loss: 0.167, lr=1.045366e-05\n",
      "training set RMSE 1 cycle: 48.214, 10 cycle: 47.780, 100 cycle: 47.000\n",
      "testing set RMSE 1 cycle: 53.583, 10 cycle: 52.191, 100 cycle: 54.014\n",
      "epoch:[129 / 1000] batch:[30 / 134] loss= 0.052\n",
      "epoch:[129 / 1000] batch:[60 / 134] loss= 0.183\n",
      "epoch:[129 / 1000] batch:[90 / 134] loss= 0.126\n",
      "epoch:[129 / 1000] batch:[120 / 134] loss= 0.064\n",
      "100 cycles trn_loss: 0.085, val_loss: 0.132, lr=3.422702e-06\n",
      "training set RMSE 1 cycle: 49.218, 10 cycle: 47.899, 100 cycle: 41.384\n",
      "testing set RMSE 1 cycle: 51.315, 10 cycle: 50.324, 100 cycle: 47.725\n",
      "epoch:[130 / 1000] batch:[30 / 134] loss= 0.201\n",
      "epoch:[130 / 1000] batch:[60 / 134] loss= 0.103\n",
      "epoch:[130 / 1000] batch:[90 / 134] loss= 0.061\n",
      "epoch:[130 / 1000] batch:[120 / 134] loss= 0.074\n",
      "100 cycles trn_loss: 0.093, val_loss: 0.144, lr=1.000000e-06\n",
      "training set RMSE 1 cycle: 47.603, 10 cycle: 46.665, 100 cycle: 43.588\n",
      "testing set RMSE 1 cycle: 51.043, 10 cycle: 50.031, 100 cycle: 50.104\n",
      "epoch:[131 / 1000] batch:[30 / 134] loss= 0.122\n",
      "epoch:[131 / 1000] batch:[60 / 134] loss= 0.066\n",
      "epoch:[131 / 1000] batch:[90 / 134] loss= 0.255\n",
      "epoch:[131 / 1000] batch:[120 / 134] loss= 0.048\n",
      "100 cycles trn_loss: 0.088, val_loss: 0.137, lr=3.422702e-06\n",
      "training set RMSE 1 cycle: 48.185, 10 cycle: 46.942, 100 cycle: 42.289\n",
      "testing set RMSE 1 cycle: 50.842, 10 cycle: 49.783, 100 cycle: 48.720\n",
      "epoch:[132 / 1000] batch:[30 / 134] loss= 0.093\n",
      "epoch:[132 / 1000] batch:[60 / 134] loss= 0.170\n",
      "epoch:[132 / 1000] batch:[90 / 134] loss= 0.126\n",
      "epoch:[132 / 1000] batch:[120 / 134] loss= 0.071\n",
      "100 cycles trn_loss: 0.088, val_loss: 0.142, lr=1.045366e-05\n",
      "training set RMSE 1 cycle: 47.903, 10 cycle: 46.881, 100 cycle: 42.359\n",
      "testing set RMSE 1 cycle: 51.244, 10 cycle: 50.491, 100 cycle: 49.574\n",
      "epoch:[133 / 1000] batch:[30 / 134] loss= 0.072\n",
      "epoch:[133 / 1000] batch:[60 / 134] loss= 0.095\n",
      "epoch:[133 / 1000] batch:[90 / 134] loss= 0.178\n",
      "epoch:[133 / 1000] batch:[120 / 134] loss= 0.086\n",
      "100 cycles trn_loss: 0.098, val_loss: 0.146, lr=2.140463e-05\n",
      "training set RMSE 1 cycle: 48.071, 10 cycle: 47.012, 100 cycle: 44.925\n",
      "testing set RMSE 1 cycle: 50.886, 10 cycle: 49.695, 100 cycle: 50.382\n",
      "epoch:[134 / 1000] batch:[30 / 134] loss= 0.066\n",
      "epoch:[134 / 1000] batch:[60 / 134] loss= 0.028\n",
      "epoch:[134 / 1000] batch:[90 / 134] loss= 0.061\n",
      "epoch:[134 / 1000] batch:[120 / 134] loss= 0.102\n",
      "100 cycles trn_loss: 0.085, val_loss: 0.134, lr=3.520366e-05\n",
      "training set RMSE 1 cycle: 51.137, 10 cycle: 48.401, 100 cycle: 41.119\n",
      "testing set RMSE 1 cycle: 51.687, 10 cycle: 51.347, 100 cycle: 48.213\n",
      "epoch:[135 / 1000] batch:[30 / 134] loss= 0.205\n",
      "epoch:[135 / 1000] batch:[60 / 134] loss= 0.116\n",
      "epoch:[135 / 1000] batch:[90 / 134] loss= 0.088\n",
      "epoch:[135 / 1000] batch:[120 / 134] loss= 0.108\n",
      "100 cycles trn_loss: 0.093, val_loss: 0.143, lr=5.050000e-05\n",
      "training set RMSE 1 cycle: 48.103, 10 cycle: 46.682, 100 cycle: 43.779\n",
      "testing set RMSE 1 cycle: 50.549, 10 cycle: 49.692, 100 cycle: 49.857\n",
      "epoch:[136 / 1000] batch:[30 / 134] loss= 0.063\n",
      "epoch:[136 / 1000] batch:[60 / 134] loss= 0.119\n",
      "epoch:[136 / 1000] batch:[90 / 134] loss= 0.097\n",
      "epoch:[136 / 1000] batch:[120 / 134] loss= 0.036\n",
      "100 cycles trn_loss: 0.092, val_loss: 0.154, lr=6.579634e-05\n",
      "training set RMSE 1 cycle: 46.907, 10 cycle: 46.652, 100 cycle: 43.385\n",
      "testing set RMSE 1 cycle: 52.296, 10 cycle: 51.788, 100 cycle: 51.704\n",
      "epoch:[137 / 1000] batch:[30 / 134] loss= 0.103\n",
      "epoch:[137 / 1000] batch:[60 / 134] loss= 0.085\n",
      "epoch:[137 / 1000] batch:[90 / 134] loss= 0.095\n",
      "epoch:[137 / 1000] batch:[120 / 134] loss= 0.126\n",
      "100 cycles trn_loss: 0.101, val_loss: 0.139, lr=7.959537e-05\n",
      "training set RMSE 1 cycle: 50.888, 10 cycle: 48.501, 100 cycle: 45.560\n",
      "testing set RMSE 1 cycle: 51.785, 10 cycle: 50.219, 100 cycle: 49.031\n",
      "epoch:[138 / 1000] batch:[30 / 134] loss= 0.063\n",
      "epoch:[138 / 1000] batch:[60 / 134] loss= 0.073\n",
      "epoch:[138 / 1000] batch:[90 / 134] loss= 0.097\n",
      "epoch:[138 / 1000] batch:[120 / 134] loss= 0.035\n",
      "100 cycles trn_loss: 0.094, val_loss: 0.141, lr=9.054634e-05\n",
      "training set RMSE 1 cycle: 54.855, 10 cycle: 52.571, 100 cycle: 42.215\n",
      "testing set RMSE 1 cycle: 56.781, 10 cycle: 55.407, 100 cycle: 49.452\n",
      "epoch:[139 / 1000] batch:[30 / 134] loss= 0.187\n",
      "epoch:[139 / 1000] batch:[60 / 134] loss= 0.108\n",
      "epoch:[139 / 1000] batch:[90 / 134] loss= 0.118\n",
      "epoch:[139 / 1000] batch:[120 / 134] loss= 0.118\n",
      "100 cycles trn_loss: 0.097, val_loss: 0.120, lr=9.757730e-05\n",
      "training set RMSE 1 cycle: 53.359, 10 cycle: 49.852, 100 cycle: 43.437\n",
      "testing set RMSE 1 cycle: 51.610, 10 cycle: 50.175, 100 cycle: 45.563\n",
      "epoch:[140 / 1000] batch:[30 / 134] loss= 0.133\n",
      "epoch:[140 / 1000] batch:[60 / 134] loss= 0.128\n",
      "epoch:[140 / 1000] batch:[90 / 134] loss= 0.110\n",
      "epoch:[140 / 1000] batch:[120 / 134] loss= 0.146\n",
      "100 cycles trn_loss: 0.095, val_loss: 0.147, lr=1.000000e-04\n",
      "training set RMSE 1 cycle: 51.893, 10 cycle: 48.451, 100 cycle: 43.974\n",
      "testing set RMSE 1 cycle: 53.883, 10 cycle: 53.491, 100 cycle: 50.530\n",
      "epoch:[141 / 1000] batch:[30 / 134] loss= 0.111\n",
      "epoch:[141 / 1000] batch:[60 / 134] loss= 0.094\n",
      "epoch:[141 / 1000] batch:[90 / 134] loss= 0.137\n",
      "epoch:[141 / 1000] batch:[120 / 134] loss= 0.066\n",
      "100 cycles trn_loss: 0.091, val_loss: 0.162, lr=9.757730e-05\n",
      "training set RMSE 1 cycle: 50.584, 10 cycle: 50.354, 100 cycle: 42.302\n",
      "testing set RMSE 1 cycle: 57.167, 10 cycle: 56.839, 100 cycle: 53.131\n",
      "epoch:[142 / 1000] batch:[30 / 134] loss= 0.116\n",
      "epoch:[142 / 1000] batch:[60 / 134] loss= 0.194\n",
      "epoch:[142 / 1000] batch:[90 / 134] loss= 0.073\n",
      "epoch:[142 / 1000] batch:[120 / 134] loss= 0.080\n",
      "100 cycles trn_loss: 0.094, val_loss: 0.159, lr=9.054634e-05\n",
      "training set RMSE 1 cycle: 50.092, 10 cycle: 48.364, 100 cycle: 43.844\n",
      "testing set RMSE 1 cycle: 55.341, 10 cycle: 55.196, 100 cycle: 52.604\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:[143 / 1000] batch:[30 / 134] loss= 0.105\n",
      "epoch:[143 / 1000] batch:[60 / 134] loss= 0.102\n",
      "epoch:[143 / 1000] batch:[90 / 134] loss= 0.093\n",
      "epoch:[143 / 1000] batch:[120 / 134] loss= 0.070\n",
      "100 cycles trn_loss: 0.119, val_loss: 0.174, lr=7.959537e-05\n",
      "training set RMSE 1 cycle: 50.529, 10 cycle: 50.362, 100 cycle: 49.483\n",
      "testing set RMSE 1 cycle: 56.295, 10 cycle: 54.385, 100 cycle: 55.105\n",
      "epoch:[144 / 1000] batch:[30 / 134] loss= 0.210\n",
      "epoch:[144 / 1000] batch:[60 / 134] loss= 0.280\n",
      "epoch:[144 / 1000] batch:[90 / 134] loss= 0.173\n",
      "epoch:[144 / 1000] batch:[120 / 134] loss= 0.132\n",
      "100 cycles trn_loss: 0.121, val_loss: 0.192, lr=6.579634e-05\n",
      "training set RMSE 1 cycle: 53.303, 10 cycle: 51.514, 100 cycle: 50.637\n",
      "testing set RMSE 1 cycle: 57.915, 10 cycle: 55.147, 100 cycle: 57.778\n",
      "epoch:[145 / 1000] batch:[30 / 134] loss= 0.117\n",
      "epoch:[145 / 1000] batch:[60 / 134] loss= 0.105\n",
      "epoch:[145 / 1000] batch:[90 / 134] loss= 0.141\n",
      "epoch:[145 / 1000] batch:[120 / 134] loss= 0.049\n",
      "100 cycles trn_loss: 0.088, val_loss: 0.114, lr=5.050000e-05\n",
      "training set RMSE 1 cycle: 50.655, 10 cycle: 48.900, 100 cycle: 41.444\n",
      "testing set RMSE 1 cycle: 51.287, 10 cycle: 50.160, 100 cycle: 44.431\n",
      "epoch:[146 / 1000] batch:[30 / 134] loss= 0.095\n",
      "epoch:[146 / 1000] batch:[60 / 134] loss= 0.084\n",
      "epoch:[146 / 1000] batch:[90 / 134] loss= 0.029\n",
      "epoch:[146 / 1000] batch:[120 / 134] loss= 0.172\n",
      "100 cycles trn_loss: 0.088, val_loss: 0.136, lr=3.520366e-05\n",
      "training set RMSE 1 cycle: 46.418, 10 cycle: 45.255, 100 cycle: 42.012\n",
      "testing set RMSE 1 cycle: 50.686, 10 cycle: 49.846, 100 cycle: 48.679\n",
      "epoch:[147 / 1000] batch:[30 / 134] loss= 0.112\n",
      "epoch:[147 / 1000] batch:[60 / 134] loss= 0.067\n",
      "epoch:[147 / 1000] batch:[90 / 134] loss= 0.121\n",
      "epoch:[147 / 1000] batch:[120 / 134] loss= 0.132\n",
      "100 cycles trn_loss: 0.089, val_loss: 0.163, lr=2.140463e-05\n",
      "training set RMSE 1 cycle: 47.465, 10 cycle: 46.936, 100 cycle: 41.897\n",
      "testing set RMSE 1 cycle: 54.363, 10 cycle: 54.801, 100 cycle: 53.326\n",
      "epoch:[148 / 1000] batch:[30 / 134] loss= 0.134\n",
      "epoch:[148 / 1000] batch:[60 / 134] loss= 0.099\n",
      "epoch:[148 / 1000] batch:[90 / 134] loss= 0.100\n",
      "epoch:[148 / 1000] batch:[120 / 134] loss= 0.071\n",
      "100 cycles trn_loss: 0.093, val_loss: 0.122, lr=1.045366e-05\n",
      "training set RMSE 1 cycle: 47.393, 10 cycle: 45.779, 100 cycle: 43.359\n",
      "testing set RMSE 1 cycle: 49.519, 10 cycle: 46.990, 100 cycle: 46.164\n",
      "epoch:[149 / 1000] batch:[30 / 134] loss= 0.071\n",
      "epoch:[149 / 1000] batch:[60 / 134] loss= 0.125\n",
      "epoch:[149 / 1000] batch:[90 / 134] loss= 0.128\n",
      "epoch:[149 / 1000] batch:[120 / 134] loss= 0.106\n",
      "100 cycles trn_loss: 0.097, val_loss: 0.149, lr=3.422702e-06\n",
      "training set RMSE 1 cycle: 45.468, 10 cycle: 45.298, 100 cycle: 44.528\n",
      "testing set RMSE 1 cycle: 51.948, 10 cycle: 50.424, 100 cycle: 51.020\n",
      "epoch:[150 / 1000] batch:[30 / 134] loss= 0.056\n",
      "epoch:[150 / 1000] batch:[60 / 134] loss= 0.136\n",
      "epoch:[150 / 1000] batch:[90 / 134] loss= 0.171\n",
      "epoch:[150 / 1000] batch:[120 / 134] loss= 0.072\n",
      "100 cycles trn_loss: 0.083, val_loss: 0.122, lr=1.000000e-06\n",
      "training set RMSE 1 cycle: 47.969, 10 cycle: 45.386, 100 cycle: 40.820\n",
      "testing set RMSE 1 cycle: 49.195, 10 cycle: 48.260, 100 cycle: 46.073\n",
      "epoch:[151 / 1000] batch:[30 / 134] loss= 0.110\n",
      "epoch:[151 / 1000] batch:[60 / 134] loss= 0.118\n",
      "epoch:[151 / 1000] batch:[90 / 134] loss= 0.106\n",
      "epoch:[151 / 1000] batch:[120 / 134] loss= 0.095\n",
      "100 cycles trn_loss: 0.085, val_loss: 0.129, lr=3.422702e-06\n",
      "training set RMSE 1 cycle: 47.123, 10 cycle: 44.965, 100 cycle: 41.404\n",
      "testing set RMSE 1 cycle: 49.657, 10 cycle: 48.863, 100 cycle: 47.442\n",
      "epoch:[152 / 1000] batch:[30 / 134] loss= 0.121\n",
      "epoch:[152 / 1000] batch:[60 / 134] loss= 0.114\n",
      "epoch:[152 / 1000] batch:[90 / 134] loss= 0.124\n",
      "epoch:[152 / 1000] batch:[120 / 134] loss= 0.105\n",
      "100 cycles trn_loss: 0.083, val_loss: 0.128, lr=1.045366e-05\n",
      "training set RMSE 1 cycle: 47.704, 10 cycle: 45.539, 100 cycle: 40.543\n",
      "testing set RMSE 1 cycle: 50.058, 10 cycle: 49.349, 100 cycle: 47.180\n",
      "epoch:[153 / 1000] batch:[30 / 134] loss= 0.042\n",
      "epoch:[153 / 1000] batch:[60 / 134] loss= 0.078\n",
      "epoch:[153 / 1000] batch:[90 / 134] loss= 0.117\n",
      "epoch:[153 / 1000] batch:[120 / 134] loss= 0.082\n",
      "100 cycles trn_loss: 0.082, val_loss: 0.121, lr=2.140463e-05\n",
      "training set RMSE 1 cycle: 48.995, 10 cycle: 45.865, 100 cycle: 40.383\n",
      "testing set RMSE 1 cycle: 48.837, 10 cycle: 48.411, 100 cycle: 45.716\n",
      "epoch:[154 / 1000] batch:[30 / 134] loss= 0.090\n",
      "epoch:[154 / 1000] batch:[60 / 134] loss= 0.115\n",
      "epoch:[154 / 1000] batch:[90 / 134] loss= 0.046\n",
      "epoch:[154 / 1000] batch:[120 / 134] loss= 0.124\n",
      "100 cycles trn_loss: 0.094, val_loss: 0.132, lr=3.520366e-05\n",
      "training set RMSE 1 cycle: 45.456, 10 cycle: 44.944, 100 cycle: 43.732\n",
      "testing set RMSE 1 cycle: 49.946, 10 cycle: 48.167, 100 cycle: 47.963\n",
      "epoch:[155 / 1000] batch:[30 / 134] loss= 0.069\n",
      "epoch:[155 / 1000] batch:[60 / 134] loss= 0.087\n",
      "epoch:[155 / 1000] batch:[90 / 134] loss= 0.147\n",
      "epoch:[155 / 1000] batch:[120 / 134] loss= 0.158\n",
      "100 cycles trn_loss: 0.095, val_loss: 0.148, lr=5.050000e-05\n",
      "training set RMSE 1 cycle: 47.012, 10 cycle: 45.306, 100 cycle: 44.143\n",
      "testing set RMSE 1 cycle: 51.956, 10 cycle: 50.425, 100 cycle: 50.703\n",
      "epoch:[156 / 1000] batch:[30 / 134] loss= 0.092\n",
      "epoch:[156 / 1000] batch:[60 / 134] loss= 0.099\n",
      "epoch:[156 / 1000] batch:[90 / 134] loss= 0.147\n",
      "epoch:[156 / 1000] batch:[120 / 134] loss= 0.119\n",
      "100 cycles trn_loss: 0.106, val_loss: 0.154, lr=6.579634e-05\n",
      "training set RMSE 1 cycle: 46.979, 10 cycle: 47.508, 100 cycle: 46.829\n",
      "testing set RMSE 1 cycle: 54.327, 10 cycle: 51.069, 100 cycle: 51.843\n",
      "epoch:[157 / 1000] batch:[30 / 134] loss= 0.107\n",
      "epoch:[157 / 1000] batch:[60 / 134] loss= 0.116\n",
      "epoch:[157 / 1000] batch:[90 / 134] loss= 0.125\n",
      "epoch:[157 / 1000] batch:[120 / 134] loss= 0.059\n",
      "100 cycles trn_loss: 0.117, val_loss: 0.176, lr=7.959537e-05\n",
      "training set RMSE 1 cycle: 51.085, 10 cycle: 50.208, 100 cycle: 49.690\n",
      "testing set RMSE 1 cycle: 56.802, 10 cycle: 53.717, 100 cycle: 55.349\n",
      "epoch:[158 / 1000] batch:[30 / 134] loss= 0.089\n",
      "epoch:[158 / 1000] batch:[60 / 134] loss= 0.177\n",
      "epoch:[158 / 1000] batch:[90 / 134] loss= 0.076\n",
      "epoch:[158 / 1000] batch:[120 / 134] loss= 0.066\n",
      "100 cycles trn_loss: 0.086, val_loss: 0.114, lr=9.054634e-05\n",
      "training set RMSE 1 cycle: 47.909, 10 cycle: 46.470, 100 cycle: 41.376\n",
      "testing set RMSE 1 cycle: 49.892, 10 cycle: 48.858, 100 cycle: 44.449\n",
      "epoch:[159 / 1000] batch:[30 / 134] loss= 0.120\n",
      "epoch:[159 / 1000] batch:[60 / 134] loss= 0.133\n",
      "epoch:[159 / 1000] batch:[90 / 134] loss= 0.130\n",
      "epoch:[159 / 1000] batch:[120 / 134] loss= 0.045\n",
      "100 cycles trn_loss: 0.094, val_loss: 0.127, lr=9.757730e-05\n",
      "training set RMSE 1 cycle: 50.531, 10 cycle: 48.087, 100 cycle: 43.078\n",
      "testing set RMSE 1 cycle: 53.675, 10 cycle: 50.733, 100 cycle: 46.927\n",
      "epoch:[160 / 1000] batch:[30 / 134] loss= 0.230\n",
      "epoch:[160 / 1000] batch:[60 / 134] loss= 0.131\n",
      "epoch:[160 / 1000] batch:[90 / 134] loss= 0.126\n",
      "epoch:[160 / 1000] batch:[120 / 134] loss= 0.184\n",
      "100 cycles trn_loss: 0.128, val_loss: 0.189, lr=1.000000e-04\n",
      "training set RMSE 1 cycle: 50.232, 10 cycle: 51.387, 100 cycle: 51.332\n",
      "testing set RMSE 1 cycle: 59.232, 10 cycle: 55.279, 100 cycle: 57.584\n",
      "epoch:[161 / 1000] batch:[30 / 134] loss= 0.097\n",
      "epoch:[161 / 1000] batch:[60 / 134] loss= 0.146\n",
      "epoch:[161 / 1000] batch:[90 / 134] loss= 0.133\n",
      "epoch:[161 / 1000] batch:[120 / 134] loss= 0.052\n",
      "100 cycles trn_loss: 0.132, val_loss: 0.136, lr=9.757730e-05\n",
      "training set RMSE 1 cycle: 58.846, 10 cycle: 55.831, 100 cycle: 49.710\n",
      "testing set RMSE 1 cycle: 54.180, 10 cycle: 51.838, 100 cycle: 48.505\n",
      "epoch:[162 / 1000] batch:[30 / 134] loss= 0.045\n",
      "epoch:[162 / 1000] batch:[60 / 134] loss= 0.116\n",
      "epoch:[162 / 1000] batch:[90 / 134] loss= 0.107\n",
      "epoch:[162 / 1000] batch:[120 / 134] loss= 0.155\n",
      "100 cycles trn_loss: 0.106, val_loss: 0.192, lr=9.054634e-05\n",
      "training set RMSE 1 cycle: 47.580, 10 cycle: 47.985, 100 cycle: 45.972\n",
      "testing set RMSE 1 cycle: 57.541, 10 cycle: 57.191, 100 cycle: 58.009\n",
      "epoch:[163 / 1000] batch:[30 / 134] loss= 0.041\n",
      "epoch:[163 / 1000] batch:[60 / 134] loss= 0.095\n",
      "epoch:[163 / 1000] batch:[90 / 134] loss= 0.193\n",
      "epoch:[163 / 1000] batch:[120 / 134] loss= 0.124\n",
      "100 cycles trn_loss: 0.082, val_loss: 0.131, lr=7.959537e-05\n",
      "training set RMSE 1 cycle: 47.199, 10 cycle: 46.129, 100 cycle: 40.150\n",
      "testing set RMSE 1 cycle: 52.664, 10 cycle: 51.842, 100 cycle: 47.648\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:[164 / 1000] batch:[30 / 134] loss= 0.177\n",
      "epoch:[164 / 1000] batch:[60 / 134] loss= 0.145\n",
      "epoch:[164 / 1000] batch:[90 / 134] loss= 0.147\n",
      "epoch:[164 / 1000] batch:[120 / 134] loss= 0.125\n",
      "100 cycles trn_loss: 0.118, val_loss: 0.207, lr=6.579634e-05\n",
      "training set RMSE 1 cycle: 46.736, 10 cycle: 47.803, 100 cycle: 48.572\n",
      "testing set RMSE 1 cycle: 58.467, 10 cycle: 57.919, 100 cycle: 60.342\n",
      "epoch:[165 / 1000] batch:[30 / 134] loss= 0.116\n",
      "epoch:[165 / 1000] batch:[60 / 134] loss= 0.106\n",
      "epoch:[165 / 1000] batch:[90 / 134] loss= 0.089\n",
      "epoch:[165 / 1000] batch:[120 / 134] loss= 0.039\n",
      "100 cycles trn_loss: 0.082, val_loss: 0.119, lr=5.050000e-05\n",
      "training set RMSE 1 cycle: 49.059, 10 cycle: 46.184, 100 cycle: 40.013\n",
      "testing set RMSE 1 cycle: 50.866, 10 cycle: 50.075, 100 cycle: 45.347\n",
      "epoch:[166 / 1000] batch:[30 / 134] loss= 0.104\n",
      "epoch:[166 / 1000] batch:[60 / 134] loss= 0.070\n",
      "epoch:[166 / 1000] batch:[90 / 134] loss= 0.094\n",
      "epoch:[166 / 1000] batch:[120 / 134] loss= 0.094\n",
      "100 cycles trn_loss: 0.081, val_loss: 0.137, lr=3.520366e-05\n",
      "training set RMSE 1 cycle: 46.493, 10 cycle: 45.555, 100 cycle: 39.545\n",
      "testing set RMSE 1 cycle: 52.249, 10 cycle: 52.514, 100 cycle: 48.807\n",
      "epoch:[167 / 1000] batch:[30 / 134] loss= 0.111\n",
      "epoch:[167 / 1000] batch:[60 / 134] loss= 0.090\n",
      "epoch:[167 / 1000] batch:[90 / 134] loss= 0.064\n",
      "epoch:[167 / 1000] batch:[120 / 134] loss= 0.046\n",
      "100 cycles trn_loss: 0.088, val_loss: 0.116, lr=2.140463e-05\n",
      "training set RMSE 1 cycle: 46.719, 10 cycle: 44.724, 100 cycle: 41.886\n",
      "testing set RMSE 1 cycle: 49.389, 10 cycle: 47.517, 100 cycle: 44.776\n",
      "epoch:[168 / 1000] batch:[30 / 134] loss= 0.095\n",
      "epoch:[168 / 1000] batch:[60 / 134] loss= 0.061\n",
      "epoch:[168 / 1000] batch:[90 / 134] loss= 0.109\n",
      "epoch:[168 / 1000] batch:[120 / 134] loss= 0.167\n",
      "100 cycles trn_loss: 0.079, val_loss: 0.112, lr=1.045366e-05\n",
      "training set RMSE 1 cycle: 49.675, 10 cycle: 47.178, 100 cycle: 39.208\n",
      "testing set RMSE 1 cycle: 49.971, 10 cycle: 50.059, 100 cycle: 44.067\n",
      "epoch:[169 / 1000] batch:[30 / 134] loss= 0.052\n",
      "epoch:[169 / 1000] batch:[60 / 134] loss= 0.102\n",
      "epoch:[169 / 1000] batch:[90 / 134] loss= 0.072\n",
      "epoch:[169 / 1000] batch:[120 / 134] loss= 0.113\n",
      "100 cycles trn_loss: 0.086, val_loss: 0.142, lr=3.422702e-06\n",
      "training set RMSE 1 cycle: 44.217, 10 cycle: 43.559, 100 cycle: 41.032\n",
      "testing set RMSE 1 cycle: 51.402, 10 cycle: 51.390, 100 cycle: 49.764\n",
      "epoch:[170 / 1000] batch:[30 / 134] loss= 0.148\n",
      "epoch:[170 / 1000] batch:[60 / 134] loss= 0.099\n",
      "epoch:[170 / 1000] batch:[90 / 134] loss= 0.087\n",
      "epoch:[170 / 1000] batch:[120 / 134] loss= 0.066\n",
      "100 cycles trn_loss: 0.083, val_loss: 0.124, lr=1.000000e-06\n",
      "training set RMSE 1 cycle: 44.987, 10 cycle: 43.291, 100 cycle: 40.344\n",
      "testing set RMSE 1 cycle: 49.471, 10 cycle: 48.898, 100 cycle: 46.502\n",
      "epoch:[171 / 1000] batch:[30 / 134] loss= 0.059\n",
      "epoch:[171 / 1000] batch:[60 / 134] loss= 0.088\n",
      "epoch:[171 / 1000] batch:[90 / 134] loss= 0.050\n",
      "epoch:[171 / 1000] batch:[120 / 134] loss= 0.062\n",
      "100 cycles trn_loss: 0.081, val_loss: 0.121, lr=3.422702e-06\n",
      "training set RMSE 1 cycle: 45.444, 10 cycle: 43.578, 100 cycle: 39.920\n",
      "testing set RMSE 1 cycle: 49.065, 10 cycle: 49.024, 100 cycle: 45.928\n",
      "epoch:[172 / 1000] batch:[30 / 134] loss= 0.057\n",
      "epoch:[172 / 1000] batch:[60 / 134] loss= 0.088\n",
      "epoch:[172 / 1000] batch:[90 / 134] loss= 0.153\n",
      "epoch:[172 / 1000] batch:[120 / 134] loss= 0.141\n",
      "100 cycles trn_loss: 0.081, val_loss: 0.117, lr=1.045366e-05\n",
      "training set RMSE 1 cycle: 45.553, 10 cycle: 43.570, 100 cycle: 39.782\n",
      "testing set RMSE 1 cycle: 48.703, 10 cycle: 48.313, 100 cycle: 45.065\n",
      "epoch:[173 / 1000] batch:[30 / 134] loss= 0.068\n",
      "epoch:[173 / 1000] batch:[60 / 134] loss= 0.191\n",
      "epoch:[173 / 1000] batch:[90 / 134] loss= 0.106\n",
      "epoch:[173 / 1000] batch:[120 / 134] loss= 0.046\n",
      "100 cycles trn_loss: 0.077, val_loss: 0.114, lr=2.140463e-05\n",
      "training set RMSE 1 cycle: 47.096, 10 cycle: 44.662, 100 cycle: 38.758\n",
      "testing set RMSE 1 cycle: 48.631, 10 cycle: 49.025, 100 cycle: 44.454\n",
      "epoch:[174 / 1000] batch:[30 / 134] loss= 0.060\n",
      "epoch:[174 / 1000] batch:[60 / 134] loss= 0.039\n",
      "epoch:[174 / 1000] batch:[90 / 134] loss= 0.079\n",
      "epoch:[174 / 1000] batch:[120 / 134] loss= 0.076\n",
      "100 cycles trn_loss: 0.090, val_loss: 0.141, lr=3.520366e-05\n",
      "training set RMSE 1 cycle: 44.711, 10 cycle: 43.242, 100 cycle: 42.200\n",
      "testing set RMSE 1 cycle: 50.901, 10 cycle: 49.813, 100 cycle: 49.489\n",
      "epoch:[175 / 1000] batch:[30 / 134] loss= 0.079\n",
      "epoch:[175 / 1000] batch:[60 / 134] loss= 0.052\n",
      "epoch:[175 / 1000] batch:[90 / 134] loss= 0.097\n",
      "epoch:[175 / 1000] batch:[120 / 134] loss= 0.215\n",
      "100 cycles trn_loss: 0.081, val_loss: 0.127, lr=5.050000e-05\n",
      "training set RMSE 1 cycle: 45.660, 10 cycle: 44.030, 100 cycle: 40.051\n",
      "testing set RMSE 1 cycle: 50.111, 10 cycle: 50.531, 100 cycle: 46.963\n",
      "epoch:[176 / 1000] batch:[30 / 134] loss= 0.043\n",
      "epoch:[176 / 1000] batch:[60 / 134] loss= 0.094\n",
      "epoch:[176 / 1000] batch:[90 / 134] loss= 0.077\n",
      "epoch:[176 / 1000] batch:[120 / 134] loss= 0.143\n",
      "100 cycles trn_loss: 0.144, val_loss: 0.204, lr=6.579634e-05\n",
      "training set RMSE 1 cycle: 53.534, 10 cycle: 54.643, 100 cycle: 56.059\n",
      "testing set RMSE 1 cycle: 59.762, 10 cycle: 54.294, 100 cycle: 59.933\n",
      "epoch:[177 / 1000] batch:[30 / 134] loss= 0.036\n",
      "epoch:[177 / 1000] batch:[60 / 134] loss= 0.049\n",
      "epoch:[177 / 1000] batch:[90 / 134] loss= 0.051\n",
      "epoch:[177 / 1000] batch:[120 / 134] loss= 0.176\n",
      "100 cycles trn_loss: 0.099, val_loss: 0.115, lr=7.959537e-05\n",
      "training set RMSE 1 cycle: 49.649, 10 cycle: 47.816, 100 cycle: 43.908\n",
      "testing set RMSE 1 cycle: 51.319, 10 cycle: 48.484, 100 cycle: 44.514\n",
      "epoch:[178 / 1000] batch:[30 / 134] loss= 0.118\n",
      "epoch:[178 / 1000] batch:[60 / 134] loss= 0.140\n",
      "epoch:[178 / 1000] batch:[90 / 134] loss= 0.096\n",
      "epoch:[178 / 1000] batch:[120 / 134] loss= 0.056\n",
      "100 cycles trn_loss: 0.135, val_loss: 0.216, lr=9.054634e-05\n",
      "training set RMSE 1 cycle: 49.493, 10 cycle: 51.655, 100 cycle: 53.352\n",
      "testing set RMSE 1 cycle: 61.044, 10 cycle: 55.635, 100 cycle: 61.460\n",
      "epoch:[179 / 1000] batch:[30 / 134] loss= 0.135\n",
      "epoch:[179 / 1000] batch:[60 / 134] loss= 0.228\n",
      "epoch:[179 / 1000] batch:[90 / 134] loss= 0.145\n",
      "epoch:[179 / 1000] batch:[120 / 134] loss= 0.092\n",
      "100 cycles trn_loss: 0.097, val_loss: 0.157, lr=9.757730e-05\n",
      "training set RMSE 1 cycle: 47.036, 10 cycle: 45.932, 100 cycle: 44.082\n",
      "testing set RMSE 1 cycle: 56.064, 10 cycle: 50.385, 100 cycle: 52.258\n",
      "epoch:[180 / 1000] batch:[30 / 134] loss= 0.224\n",
      "epoch:[180 / 1000] batch:[60 / 134] loss= 0.091\n",
      "epoch:[180 / 1000] batch:[90 / 134] loss= 0.038\n",
      "epoch:[180 / 1000] batch:[120 / 134] loss= 0.185\n",
      "100 cycles trn_loss: 0.101, val_loss: 0.156, lr=1.000000e-04\n",
      "training set RMSE 1 cycle: 46.951, 10 cycle: 45.874, 100 cycle: 45.284\n",
      "testing set RMSE 1 cycle: 53.905, 10 cycle: 54.046, 100 cycle: 52.033\n",
      "epoch:[181 / 1000] batch:[30 / 134] loss= 0.112\n",
      "epoch:[181 / 1000] batch:[60 / 134] loss= 0.151\n",
      "epoch:[181 / 1000] batch:[90 / 134] loss= 0.044\n",
      "epoch:[181 / 1000] batch:[120 / 134] loss= 0.122\n",
      "100 cycles trn_loss: 0.089, val_loss: 0.177, lr=9.757730e-05\n",
      "training set RMSE 1 cycle: 50.454, 10 cycle: 50.698, 100 cycle: 40.581\n",
      "testing set RMSE 1 cycle: 59.001, 10 cycle: 61.093, 100 cycle: 56.026\n",
      "epoch:[182 / 1000] batch:[30 / 134] loss= 0.073\n",
      "epoch:[182 / 1000] batch:[60 / 134] loss= 0.118\n",
      "epoch:[182 / 1000] batch:[90 / 134] loss= 0.114\n",
      "epoch:[182 / 1000] batch:[120 / 134] loss= 0.144\n",
      "100 cycles trn_loss: 0.086, val_loss: 0.148, lr=9.054634e-05\n",
      "training set RMSE 1 cycle: 45.976, 10 cycle: 44.918, 100 cycle: 41.426\n",
      "testing set RMSE 1 cycle: 55.045, 10 cycle: 53.866, 100 cycle: 50.643\n",
      "epoch:[183 / 1000] batch:[30 / 134] loss= 0.224\n",
      "epoch:[183 / 1000] batch:[60 / 134] loss= 0.080\n",
      "epoch:[183 / 1000] batch:[90 / 134] loss= 0.273\n",
      "epoch:[183 / 1000] batch:[120 / 134] loss= 0.087\n",
      "100 cycles trn_loss: 0.104, val_loss: 0.155, lr=7.959537e-05\n",
      "training set RMSE 1 cycle: 46.823, 10 cycle: 47.311, 100 cycle: 46.073\n",
      "testing set RMSE 1 cycle: 55.270, 10 cycle: 49.211, 100 cycle: 51.792\n",
      "epoch:[184 / 1000] batch:[30 / 134] loss= 0.138\n",
      "epoch:[184 / 1000] batch:[60 / 134] loss= 0.057\n",
      "epoch:[184 / 1000] batch:[90 / 134] loss= 0.125\n",
      "epoch:[184 / 1000] batch:[120 / 134] loss= 0.057\n",
      "100 cycles trn_loss: 0.099, val_loss: 0.169, lr=6.579634e-05\n",
      "training set RMSE 1 cycle: 45.151, 10 cycle: 45.914, 100 cycle: 44.090\n",
      "testing set RMSE 1 cycle: 58.534, 10 cycle: 54.379, 100 cycle: 54.300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:[185 / 1000] batch:[30 / 134] loss= 0.060\n",
      "epoch:[185 / 1000] batch:[60 / 134] loss= 0.066\n",
      "epoch:[185 / 1000] batch:[90 / 134] loss= 0.044\n",
      "epoch:[185 / 1000] batch:[120 / 134] loss= 0.068\n",
      "100 cycles trn_loss: 0.082, val_loss: 0.149, lr=5.050000e-05\n",
      "training set RMSE 1 cycle: 50.389, 10 cycle: 49.370, 100 cycle: 39.584\n",
      "testing set RMSE 1 cycle: 56.783, 10 cycle: 57.571, 100 cycle: 50.929\n",
      "epoch:[186 / 1000] batch:[30 / 134] loss= 0.084\n",
      "epoch:[186 / 1000] batch:[60 / 134] loss= 0.116\n",
      "epoch:[186 / 1000] batch:[90 / 134] loss= 0.149\n",
      "epoch:[186 / 1000] batch:[120 / 134] loss= 0.078\n",
      "100 cycles trn_loss: 0.077, val_loss: 0.131, lr=3.520366e-05\n",
      "training set RMSE 1 cycle: 44.471, 10 cycle: 42.907, 100 cycle: 38.241\n",
      "testing set RMSE 1 cycle: 53.845, 10 cycle: 50.907, 100 cycle: 47.680\n",
      "epoch:[187 / 1000] batch:[30 / 134] loss= 0.099\n",
      "epoch:[187 / 1000] batch:[60 / 134] loss= 0.127\n",
      "epoch:[187 / 1000] batch:[90 / 134] loss= 0.127\n",
      "epoch:[187 / 1000] batch:[120 / 134] loss= 0.120\n",
      "100 cycles trn_loss: 0.078, val_loss: 0.131, lr=2.140463e-05\n",
      "training set RMSE 1 cycle: 45.740, 10 cycle: 43.593, 100 cycle: 38.608\n",
      "testing set RMSE 1 cycle: 52.077, 10 cycle: 52.876, 100 cycle: 47.668\n",
      "epoch:[188 / 1000] batch:[30 / 134] loss= 0.091\n",
      "epoch:[188 / 1000] batch:[60 / 134] loss= 0.067\n",
      "epoch:[188 / 1000] batch:[90 / 134] loss= 0.094\n",
      "epoch:[188 / 1000] batch:[120 / 134] loss= 0.140\n",
      "100 cycles trn_loss: 0.075, val_loss: 0.120, lr=1.045366e-05\n",
      "training set RMSE 1 cycle: 44.623, 10 cycle: 42.502, 100 cycle: 37.799\n",
      "testing set RMSE 1 cycle: 51.437, 10 cycle: 50.483, 100 cycle: 45.654\n",
      "epoch:[189 / 1000] batch:[30 / 134] loss= 0.070\n",
      "epoch:[189 / 1000] batch:[60 / 134] loss= 0.067\n",
      "epoch:[189 / 1000] batch:[90 / 134] loss= 0.078\n",
      "epoch:[189 / 1000] batch:[120 / 134] loss= 0.071\n",
      "100 cycles trn_loss: 0.081, val_loss: 0.113, lr=3.422702e-06\n",
      "training set RMSE 1 cycle: 43.449, 10 cycle: 41.567, 100 cycle: 39.633\n",
      "testing set RMSE 1 cycle: 50.844, 10 cycle: 46.499, 100 cycle: 44.247\n",
      "epoch:[190 / 1000] batch:[30 / 134] loss= 0.066\n",
      "epoch:[190 / 1000] batch:[60 / 134] loss= 0.078\n",
      "epoch:[190 / 1000] batch:[90 / 134] loss= 0.114\n",
      "epoch:[190 / 1000] batch:[120 / 134] loss= 0.091\n",
      "100 cycles trn_loss: 0.075, val_loss: 0.116, lr=1.000000e-06\n",
      "training set RMSE 1 cycle: 45.042, 10 cycle: 42.548, 100 cycle: 37.943\n",
      "testing set RMSE 1 cycle: 50.305, 10 cycle: 50.295, 100 cycle: 44.755\n",
      "epoch:[191 / 1000] batch:[30 / 134] loss= 0.122\n",
      "epoch:[191 / 1000] batch:[60 / 134] loss= 0.074\n",
      "epoch:[191 / 1000] batch:[90 / 134] loss= 0.085\n",
      "epoch:[191 / 1000] batch:[120 / 134] loss= 0.085\n",
      "100 cycles trn_loss: 0.078, val_loss: 0.114, lr=3.422702e-06\n",
      "training set RMSE 1 cycle: 43.890, 10 cycle: 41.669, 100 cycle: 38.747\n",
      "testing set RMSE 1 cycle: 50.511, 10 cycle: 48.461, 100 cycle: 44.568\n",
      "epoch:[192 / 1000] batch:[30 / 134] loss= 0.102\n",
      "epoch:[192 / 1000] batch:[60 / 134] loss= 0.092\n",
      "epoch:[192 / 1000] batch:[90 / 134] loss= 0.051\n",
      "epoch:[192 / 1000] batch:[120 / 134] loss= 0.047\n",
      "100 cycles trn_loss: 0.079, val_loss: 0.114, lr=1.045366e-05\n",
      "training set RMSE 1 cycle: 43.338, 10 cycle: 41.506, 100 cycle: 39.210\n",
      "testing set RMSE 1 cycle: 50.528, 10 cycle: 47.763, 100 cycle: 44.458\n",
      "epoch:[193 / 1000] batch:[30 / 134] loss= 0.081\n",
      "epoch:[193 / 1000] batch:[60 / 134] loss= 0.032\n",
      "epoch:[193 / 1000] batch:[90 / 134] loss= 0.033\n",
      "epoch:[193 / 1000] batch:[120 / 134] loss= 0.052\n",
      "100 cycles trn_loss: 0.074, val_loss: 0.108, lr=2.140463e-05\n",
      "training set RMSE 1 cycle: 45.972, 10 cycle: 43.202, 100 cycle: 37.682\n",
      "testing set RMSE 1 cycle: 49.622, 10 cycle: 50.017, 100 cycle: 43.202\n",
      "epoch:[194 / 1000] batch:[30 / 134] loss= 0.092\n",
      "epoch:[194 / 1000] batch:[60 / 134] loss= 0.143\n",
      "epoch:[194 / 1000] batch:[90 / 134] loss= 0.058\n",
      "epoch:[194 / 1000] batch:[120 / 134] loss= 0.176\n",
      "100 cycles trn_loss: 0.073, val_loss: 0.118, lr=3.520366e-05\n",
      "training set RMSE 1 cycle: 48.177, 10 cycle: 45.386, 100 cycle: 36.721\n",
      "testing set RMSE 1 cycle: 51.982, 10 cycle: 52.986, 100 cycle: 45.263\n",
      "epoch:[195 / 1000] batch:[30 / 134] loss= 0.122\n",
      "epoch:[195 / 1000] batch:[60 / 134] loss= 0.100\n",
      "epoch:[195 / 1000] batch:[90 / 134] loss= 0.060\n",
      "epoch:[195 / 1000] batch:[120 / 134] loss= 0.082\n",
      "100 cycles trn_loss: 0.073, val_loss: 0.112, lr=5.050000e-05\n",
      "training set RMSE 1 cycle: 50.488, 10 cycle: 46.366, 100 cycle: 36.686\n",
      "testing set RMSE 1 cycle: 52.504, 10 cycle: 53.036, 100 cycle: 44.095\n",
      "epoch:[196 / 1000] batch:[30 / 134] loss= 0.075\n",
      "epoch:[196 / 1000] batch:[60 / 134] loss= 0.050\n",
      "epoch:[196 / 1000] batch:[90 / 134] loss= 0.029\n",
      "epoch:[196 / 1000] batch:[120 / 134] loss= 0.116\n",
      "100 cycles trn_loss: 0.075, val_loss: 0.118, lr=6.579634e-05\n",
      "training set RMSE 1 cycle: 49.356, 10 cycle: 44.514, 100 cycle: 37.017\n",
      "testing set RMSE 1 cycle: 49.727, 10 cycle: 51.987, 100 cycle: 45.231\n",
      "epoch:[197 / 1000] batch:[30 / 134] loss= 0.109\n",
      "epoch:[197 / 1000] batch:[60 / 134] loss= 0.158\n",
      "epoch:[197 / 1000] batch:[90 / 134] loss= 0.204\n",
      "epoch:[197 / 1000] batch:[120 / 134] loss= 0.122\n",
      "100 cycles trn_loss: 0.074, val_loss: 0.119, lr=7.959537e-05\n",
      "training set RMSE 1 cycle: 51.083, 10 cycle: 46.146, 100 cycle: 37.201\n",
      "testing set RMSE 1 cycle: 52.664, 10 cycle: 54.018, 100 cycle: 45.346\n",
      "epoch:[198 / 1000] batch:[30 / 134] loss= 0.115\n",
      "epoch:[198 / 1000] batch:[60 / 134] loss= 0.115\n",
      "epoch:[198 / 1000] batch:[90 / 134] loss= 0.114\n",
      "epoch:[198 / 1000] batch:[120 / 134] loss= 0.072\n",
      "100 cycles trn_loss: 0.084, val_loss: 0.154, lr=9.054634e-05\n",
      "training set RMSE 1 cycle: 43.660, 10 cycle: 43.623, 100 cycle: 39.973\n",
      "testing set RMSE 1 cycle: 55.227, 10 cycle: 56.256, 100 cycle: 51.870\n",
      "epoch:[199 / 1000] batch:[30 / 134] loss= 0.027\n",
      "epoch:[199 / 1000] batch:[60 / 134] loss= 0.165\n",
      "epoch:[199 / 1000] batch:[90 / 134] loss= 0.114\n",
      "epoch:[199 / 1000] batch:[120 / 134] loss= 0.068\n",
      "100 cycles trn_loss: 0.111, val_loss: 0.177, lr=9.757730e-05\n",
      "training set RMSE 1 cycle: 45.140, 10 cycle: 46.749, 100 cycle: 47.660\n",
      "testing set RMSE 1 cycle: 58.139, 10 cycle: 51.165, 100 cycle: 55.691\n",
      "epoch:[200 / 1000] batch:[30 / 134] loss= 0.066\n",
      "epoch:[200 / 1000] batch:[60 / 134] loss= 0.116\n",
      "epoch:[200 / 1000] batch:[90 / 134] loss= 0.110\n",
      "epoch:[200 / 1000] batch:[120 / 134] loss= 0.082\n",
      "100 cycles trn_loss: 0.101, val_loss: 0.183, lr=1.000000e-04\n",
      "training set RMSE 1 cycle: 46.563, 10 cycle: 44.645, 100 cycle: 43.708\n",
      "testing set RMSE 1 cycle: 59.260, 10 cycle: 56.070, 100 cycle: 56.550\n",
      "epoch:[201 / 1000] batch:[30 / 134] loss= 0.114\n",
      "epoch:[201 / 1000] batch:[60 / 134] loss= 0.031\n",
      "epoch:[201 / 1000] batch:[90 / 134] loss= 0.082\n",
      "epoch:[201 / 1000] batch:[120 / 134] loss= 0.098\n",
      "100 cycles trn_loss: 0.078, val_loss: 0.108, lr=9.757730e-05\n",
      "training set RMSE 1 cycle: 44.027, 10 cycle: 41.792, 100 cycle: 38.510\n",
      "testing set RMSE 1 cycle: 52.651, 10 cycle: 47.816, 100 cycle: 43.196\n",
      "epoch:[202 / 1000] batch:[30 / 134] loss= 0.206\n",
      "epoch:[202 / 1000] batch:[60 / 134] loss= 0.078\n",
      "epoch:[202 / 1000] batch:[90 / 134] loss= 0.110\n",
      "epoch:[202 / 1000] batch:[120 / 134] loss= 0.086\n",
      "100 cycles trn_loss: 0.087, val_loss: 0.159, lr=9.054634e-05\n",
      "training set RMSE 1 cycle: 47.346, 10 cycle: 47.027, 100 cycle: 41.001\n",
      "testing set RMSE 1 cycle: 55.542, 10 cycle: 57.739, 100 cycle: 52.847\n",
      "epoch:[203 / 1000] batch:[30 / 134] loss= 0.029\n",
      "epoch:[203 / 1000] batch:[60 / 134] loss= 0.031\n",
      "epoch:[203 / 1000] batch:[90 / 134] loss= 0.045\n",
      "epoch:[203 / 1000] batch:[120 / 134] loss= 0.061\n",
      "100 cycles trn_loss: 0.143, val_loss: 0.211, lr=7.959537e-05\n",
      "training set RMSE 1 cycle: 47.585, 10 cycle: 51.755, 100 cycle: 54.554\n",
      "testing set RMSE 1 cycle: 62.170, 10 cycle: 54.603, 100 cycle: 61.118\n",
      "epoch:[204 / 1000] batch:[30 / 134] loss= 0.110\n",
      "epoch:[204 / 1000] batch:[60 / 134] loss= 0.126\n",
      "epoch:[204 / 1000] batch:[90 / 134] loss= 0.040\n",
      "epoch:[204 / 1000] batch:[120 / 134] loss= 0.142\n",
      "100 cycles trn_loss: 0.262, val_loss: 0.391, lr=6.579634e-05\n",
      "training set RMSE 1 cycle: 72.148, 10 cycle: 73.538, 100 cycle: 76.515\n",
      "testing set RMSE 1 cycle: 82.036, 10 cycle: 83.756, 100 cycle: 88.949\n",
      "epoch:[205 / 1000] batch:[30 / 134] loss= 0.085\n",
      "epoch:[205 / 1000] batch:[60 / 134] loss= 0.114\n",
      "epoch:[205 / 1000] batch:[90 / 134] loss= 0.086\n",
      "epoch:[205 / 1000] batch:[120 / 134] loss= 0.120\n",
      "100 cycles trn_loss: 0.078, val_loss: 0.150, lr=5.050000e-05\n",
      "training set RMSE 1 cycle: 46.889, 10 cycle: 44.791, 100 cycle: 37.772\n",
      "testing set RMSE 1 cycle: 53.383, 10 cycle: 57.098, 100 cycle: 51.344\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:[206 / 1000] batch:[30 / 134] loss= 0.029\n",
      "epoch:[206 / 1000] batch:[60 / 134] loss= 0.046\n",
      "epoch:[206 / 1000] batch:[90 / 134] loss= 0.052\n",
      "epoch:[206 / 1000] batch:[120 / 134] loss= 0.105\n",
      "100 cycles trn_loss: 0.092, val_loss: 0.117, lr=3.520366e-05\n",
      "training set RMSE 1 cycle: 44.766, 10 cycle: 43.553, 100 cycle: 42.600\n",
      "testing set RMSE 1 cycle: 52.009, 10 cycle: 43.718, 100 cycle: 45.122\n",
      "epoch:[207 / 1000] batch:[30 / 134] loss= 0.053\n",
      "epoch:[207 / 1000] batch:[60 / 134] loss= 0.102\n",
      "epoch:[207 / 1000] batch:[90 / 134] loss= 0.045\n",
      "epoch:[207 / 1000] batch:[120 / 134] loss= 0.076\n",
      "100 cycles trn_loss: 0.073, val_loss: 0.131, lr=2.140463e-05\n",
      "training set RMSE 1 cycle: 44.801, 10 cycle: 42.690, 100 cycle: 37.231\n",
      "testing set RMSE 1 cycle: 52.485, 10 cycle: 54.407, 100 cycle: 47.724\n",
      "epoch:[208 / 1000] batch:[30 / 134] loss= 0.044\n",
      "epoch:[208 / 1000] batch:[60 / 134] loss= 0.101\n",
      "epoch:[208 / 1000] batch:[90 / 134] loss= 0.082\n",
      "epoch:[208 / 1000] batch:[120 / 134] loss= 0.103\n",
      "100 cycles trn_loss: 0.070, val_loss: 0.108, lr=1.045366e-05\n",
      "training set RMSE 1 cycle: 45.816, 10 cycle: 41.186, 100 cycle: 36.180\n",
      "testing set RMSE 1 cycle: 50.145, 10 cycle: 50.451, 100 cycle: 43.177\n",
      "epoch:[209 / 1000] batch:[30 / 134] loss= 0.077\n",
      "epoch:[209 / 1000] batch:[60 / 134] loss= 0.111\n",
      "epoch:[209 / 1000] batch:[90 / 134] loss= 0.205\n",
      "epoch:[209 / 1000] batch:[120 / 134] loss= 0.086\n",
      "100 cycles trn_loss: 0.071, val_loss: 0.114, lr=3.422702e-06\n",
      "training set RMSE 1 cycle: 43.784, 10 cycle: 40.452, 100 cycle: 36.213\n",
      "testing set RMSE 1 cycle: 52.597, 10 cycle: 50.585, 100 cycle: 44.534\n",
      "epoch:[210 / 1000] batch:[30 / 134] loss= 0.085\n",
      "epoch:[210 / 1000] batch:[60 / 134] loss= 0.039\n",
      "epoch:[210 / 1000] batch:[90 / 134] loss= 0.153\n",
      "epoch:[210 / 1000] batch:[120 / 134] loss= 0.052\n",
      "100 cycles trn_loss: 0.072, val_loss: 0.108, lr=1.000000e-06\n",
      "training set RMSE 1 cycle: 43.030, 10 cycle: 39.881, 100 cycle: 37.089\n",
      "testing set RMSE 1 cycle: 51.550, 10 cycle: 48.479, 100 cycle: 43.318\n",
      "epoch:[211 / 1000] batch:[30 / 134] loss= 0.096\n",
      "epoch:[211 / 1000] batch:[60 / 134] loss= 0.098\n",
      "epoch:[211 / 1000] batch:[90 / 134] loss= 0.034\n",
      "epoch:[211 / 1000] batch:[120 / 134] loss= 0.037\n",
      "100 cycles trn_loss: 0.072, val_loss: 0.112, lr=3.422702e-06\n",
      "training set RMSE 1 cycle: 43.365, 10 cycle: 40.089, 100 cycle: 36.769\n",
      "testing set RMSE 1 cycle: 51.818, 10 cycle: 49.757, 100 cycle: 44.063\n",
      "epoch:[212 / 1000] batch:[30 / 134] loss= 0.090\n",
      "epoch:[212 / 1000] batch:[60 / 134] loss= 0.064\n",
      "epoch:[212 / 1000] batch:[90 / 134] loss= 0.030\n",
      "epoch:[212 / 1000] batch:[120 / 134] loss= 0.129\n",
      "100 cycles trn_loss: 0.072, val_loss: 0.111, lr=1.045366e-05\n",
      "training set RMSE 1 cycle: 43.458, 10 cycle: 40.196, 100 cycle: 36.835\n",
      "testing set RMSE 1 cycle: 51.574, 10 cycle: 49.887, 100 cycle: 43.899\n",
      "epoch:[213 / 1000] batch:[30 / 134] loss= 0.087\n",
      "epoch:[213 / 1000] batch:[60 / 134] loss= 0.098\n",
      "epoch:[213 / 1000] batch:[90 / 134] loss= 0.055\n",
      "epoch:[213 / 1000] batch:[120 / 134] loss= 0.057\n",
      "100 cycles trn_loss: 0.076, val_loss: 0.106, lr=2.140463e-05\n",
      "training set RMSE 1 cycle: 43.384, 10 cycle: 40.588, 100 cycle: 38.373\n",
      "testing set RMSE 1 cycle: 50.325, 10 cycle: 48.679, 100 cycle: 42.829\n",
      "epoch:[214 / 1000] batch:[30 / 134] loss= 0.085\n",
      "epoch:[214 / 1000] batch:[60 / 134] loss= 0.062\n",
      "epoch:[214 / 1000] batch:[90 / 134] loss= 0.048\n",
      "epoch:[214 / 1000] batch:[120 / 134] loss= 0.127\n",
      "100 cycles trn_loss: 0.070, val_loss: 0.102, lr=3.520366e-05\n",
      "training set RMSE 1 cycle: 43.807, 10 cycle: 39.858, 100 cycle: 36.033\n",
      "testing set RMSE 1 cycle: 49.508, 10 cycle: 48.490, 100 cycle: 42.038\n",
      "epoch:[215 / 1000] batch:[30 / 134] loss= 0.086\n",
      "epoch:[215 / 1000] batch:[60 / 134] loss= 0.075\n",
      "epoch:[215 / 1000] batch:[90 / 134] loss= 0.048\n",
      "epoch:[215 / 1000] batch:[120 / 134] loss= 0.115\n",
      "100 cycles trn_loss: 0.076, val_loss: 0.095, lr=5.050000e-05\n",
      "training set RMSE 1 cycle: 42.768, 10 cycle: 40.063, 100 cycle: 38.374\n",
      "testing set RMSE 1 cycle: 49.867, 10 cycle: 44.303, 100 cycle: 40.525\n",
      "epoch:[216 / 1000] batch:[30 / 134] loss= 0.092\n",
      "epoch:[216 / 1000] batch:[60 / 134] loss= 0.066\n",
      "epoch:[216 / 1000] batch:[90 / 134] loss= 0.114\n",
      "epoch:[216 / 1000] batch:[120 / 134] loss= 0.067\n",
      "100 cycles trn_loss: 0.101, val_loss: 0.153, lr=6.579634e-05\n",
      "training set RMSE 1 cycle: 40.853, 10 cycle: 42.577, 100 cycle: 44.563\n",
      "testing set RMSE 1 cycle: 54.825, 10 cycle: 49.337, 100 cycle: 51.791\n",
      "epoch:[217 / 1000] batch:[30 / 134] loss= 0.050\n",
      "epoch:[217 / 1000] batch:[60 / 134] loss= 0.068\n",
      "epoch:[217 / 1000] batch:[90 / 134] loss= 0.093\n",
      "epoch:[217 / 1000] batch:[120 / 134] loss= 0.085\n",
      "100 cycles trn_loss: 0.122, val_loss: 0.219, lr=7.959537e-05\n",
      "training set RMSE 1 cycle: 43.393, 10 cycle: 47.007, 100 cycle: 48.872\n",
      "testing set RMSE 1 cycle: 65.468, 10 cycle: 57.702, 100 cycle: 62.382\n",
      "epoch:[218 / 1000] batch:[30 / 134] loss= 0.089\n",
      "epoch:[218 / 1000] batch:[60 / 134] loss= 0.108\n",
      "epoch:[218 / 1000] batch:[90 / 134] loss= 0.071\n",
      "epoch:[218 / 1000] batch:[120 / 134] loss= 0.060\n",
      "100 cycles trn_loss: 0.091, val_loss: 0.175, lr=9.054634e-05\n",
      "training set RMSE 1 cycle: 52.245, 10 cycle: 51.908, 100 cycle: 42.217\n",
      "testing set RMSE 1 cycle: 58.807, 10 cycle: 61.317, 100 cycle: 55.913\n",
      "epoch:[219 / 1000] batch:[30 / 134] loss= 0.114\n",
      "epoch:[219 / 1000] batch:[60 / 134] loss= 0.095\n",
      "epoch:[219 / 1000] batch:[90 / 134] loss= 0.065\n",
      "epoch:[219 / 1000] batch:[120 / 134] loss= 0.039\n",
      "100 cycles trn_loss: 0.081, val_loss: 0.164, lr=9.757730e-05\n",
      "training set RMSE 1 cycle: 42.548, 10 cycle: 41.517, 100 cycle: 39.065\n",
      "testing set RMSE 1 cycle: 59.694, 10 cycle: 56.319, 100 cycle: 53.500\n",
      "epoch:[220 / 1000] batch:[30 / 134] loss= 0.108\n",
      "epoch:[220 / 1000] batch:[60 / 134] loss= 0.045\n",
      "epoch:[220 / 1000] batch:[90 / 134] loss= 0.077\n",
      "epoch:[220 / 1000] batch:[120 / 134] loss= 0.151\n",
      "100 cycles trn_loss: 0.094, val_loss: 0.132, lr=1.000000e-04\n",
      "training set RMSE 1 cycle: 50.188, 10 cycle: 48.347, 100 cycle: 44.034\n",
      "testing set RMSE 1 cycle: 55.223, 10 cycle: 55.050, 100 cycle: 47.893\n",
      "epoch:[221 / 1000] batch:[30 / 134] loss= 0.154\n",
      "epoch:[221 / 1000] batch:[60 / 134] loss= 0.255\n",
      "epoch:[221 / 1000] batch:[90 / 134] loss= 0.081\n",
      "epoch:[221 / 1000] batch:[120 / 134] loss= 0.092\n",
      "100 cycles trn_loss: 0.182, val_loss: 0.263, lr=9.757730e-05\n",
      "training set RMSE 1 cycle: 57.991, 10 cycle: 61.173, 100 cycle: 62.770\n",
      "testing set RMSE 1 cycle: 67.549, 10 cycle: 62.640, 100 cycle: 68.853\n",
      "epoch:[222 / 1000] batch:[30 / 134] loss= 0.119\n",
      "epoch:[222 / 1000] batch:[60 / 134] loss= 0.079\n",
      "epoch:[222 / 1000] batch:[90 / 134] loss= 0.158\n",
      "epoch:[222 / 1000] batch:[120 / 134] loss= 0.058\n",
      "100 cycles trn_loss: 0.114, val_loss: 0.145, lr=9.054634e-05\n",
      "training set RMSE 1 cycle: 51.119, 10 cycle: 51.170, 100 cycle: 49.448\n",
      "testing set RMSE 1 cycle: 56.265, 10 cycle: 46.898, 100 cycle: 50.099\n",
      "epoch:[223 / 1000] batch:[30 / 134] loss= 0.090\n",
      "epoch:[223 / 1000] batch:[60 / 134] loss= 0.094\n",
      "epoch:[223 / 1000] batch:[90 / 134] loss= 0.145\n",
      "epoch:[223 / 1000] batch:[120 / 134] loss= 0.146\n",
      "100 cycles trn_loss: 0.088, val_loss: 0.171, lr=7.959537e-05\n",
      "training set RMSE 1 cycle: 46.746, 10 cycle: 45.512, 100 cycle: 41.547\n",
      "testing set RMSE 1 cycle: 58.536, 10 cycle: 59.993, 100 cycle: 54.847\n",
      "epoch:[224 / 1000] batch:[30 / 134] loss= 0.089\n",
      "epoch:[224 / 1000] batch:[60 / 134] loss= 0.191\n",
      "epoch:[224 / 1000] batch:[90 / 134] loss= 0.123\n",
      "epoch:[224 / 1000] batch:[120 / 134] loss= 0.091\n",
      "100 cycles trn_loss: 0.084, val_loss: 0.163, lr=6.579634e-05\n",
      "training set RMSE 1 cycle: 53.442, 10 cycle: 52.579, 100 cycle: 40.161\n",
      "testing set RMSE 1 cycle: 59.427, 10 cycle: 61.372, 100 cycle: 54.293\n",
      "epoch:[225 / 1000] batch:[30 / 134] loss= 0.111\n",
      "epoch:[225 / 1000] batch:[60 / 134] loss= 0.043\n",
      "epoch:[225 / 1000] batch:[90 / 134] loss= 0.071\n",
      "epoch:[225 / 1000] batch:[120 / 134] loss= 0.144\n",
      "100 cycles trn_loss: 0.086, val_loss: 0.155, lr=5.050000e-05\n",
      "training set RMSE 1 cycle: 41.722, 10 cycle: 40.542, 100 cycle: 40.559\n",
      "testing set RMSE 1 cycle: 58.887, 10 cycle: 51.848, 100 cycle: 52.114\n",
      "epoch:[226 / 1000] batch:[30 / 134] loss= 0.093\n",
      "epoch:[226 / 1000] batch:[60 / 134] loss= 0.111\n",
      "epoch:[226 / 1000] batch:[90 / 134] loss= 0.060\n",
      "epoch:[226 / 1000] batch:[120 / 134] loss= 0.240\n",
      "100 cycles trn_loss: 0.104, val_loss: 0.125, lr=3.520366e-05\n",
      "training set RMSE 1 cycle: 44.881, 10 cycle: 45.846, 100 cycle: 46.272\n",
      "testing set RMSE 1 cycle: 50.574, 10 cycle: 43.364, 100 cycle: 46.648\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:[227 / 1000] batch:[30 / 134] loss= 0.072\n",
      "epoch:[227 / 1000] batch:[60 / 134] loss= 0.051\n",
      "epoch:[227 / 1000] batch:[90 / 134] loss= 0.125\n",
      "epoch:[227 / 1000] batch:[120 / 134] loss= 0.144\n",
      "100 cycles trn_loss: 0.069, val_loss: 0.092, lr=2.140463e-05\n",
      "training set RMSE 1 cycle: 47.027, 10 cycle: 40.816, 100 cycle: 36.265\n",
      "testing set RMSE 1 cycle: 49.528, 10 cycle: 47.524, 100 cycle: 39.838\n",
      "epoch:[228 / 1000] batch:[30 / 134] loss= 0.057\n",
      "epoch:[228 / 1000] batch:[60 / 134] loss= 0.133\n",
      "epoch:[228 / 1000] batch:[90 / 134] loss= 0.098\n",
      "epoch:[228 / 1000] batch:[120 / 134] loss= 0.054\n",
      "100 cycles trn_loss: 0.070, val_loss: 0.117, lr=1.045366e-05\n",
      "training set RMSE 1 cycle: 44.608, 10 cycle: 38.976, 100 cycle: 36.103\n",
      "testing set RMSE 1 cycle: 52.678, 10 cycle: 50.385, 100 cycle: 45.128\n",
      "epoch:[229 / 1000] batch:[30 / 134] loss= 0.089\n",
      "epoch:[229 / 1000] batch:[60 / 134] loss= 0.059\n",
      "epoch:[229 / 1000] batch:[90 / 134] loss= 0.069\n",
      "epoch:[229 / 1000] batch:[120 / 134] loss= 0.091\n",
      "100 cycles trn_loss: 0.067, val_loss: 0.107, lr=3.422702e-06\n",
      "training set RMSE 1 cycle: 45.002, 10 cycle: 40.212, 100 cycle: 35.419\n",
      "testing set RMSE 1 cycle: 51.540, 10 cycle: 50.699, 100 cycle: 43.119\n",
      "epoch:[230 / 1000] batch:[30 / 134] loss= 0.108\n",
      "epoch:[230 / 1000] batch:[60 / 134] loss= 0.113\n",
      "epoch:[230 / 1000] batch:[90 / 134] loss= 0.029\n",
      "epoch:[230 / 1000] batch:[120 / 134] loss= 0.070\n",
      "100 cycles trn_loss: 0.068, val_loss: 0.104, lr=1.000000e-06\n",
      "training set RMSE 1 cycle: 44.487, 10 cycle: 38.917, 100 cycle: 35.489\n",
      "testing set RMSE 1 cycle: 51.402, 10 cycle: 48.847, 100 cycle: 42.483\n",
      "epoch:[231 / 1000] batch:[30 / 134] loss= 0.072\n",
      "epoch:[231 / 1000] batch:[60 / 134] loss= 0.073\n",
      "epoch:[231 / 1000] batch:[90 / 134] loss= 0.095\n",
      "epoch:[231 / 1000] batch:[120 / 134] loss= 0.123\n",
      "100 cycles trn_loss: 0.069, val_loss: 0.103, lr=3.422702e-06\n",
      "training set RMSE 1 cycle: 43.772, 10 cycle: 38.429, 100 cycle: 36.009\n",
      "testing set RMSE 1 cycle: 51.472, 10 cycle: 47.512, 100 cycle: 42.260\n",
      "epoch:[232 / 1000] batch:[30 / 134] loss= 0.066\n",
      "epoch:[232 / 1000] batch:[60 / 134] loss= 0.136\n",
      "epoch:[232 / 1000] batch:[90 / 134] loss= 0.029\n",
      "epoch:[232 / 1000] batch:[120 / 134] loss= 0.172\n",
      "100 cycles trn_loss: 0.069, val_loss: 0.109, lr=1.045366e-05\n",
      "training set RMSE 1 cycle: 44.083, 10 cycle: 38.433, 100 cycle: 35.855\n",
      "testing set RMSE 1 cycle: 52.417, 10 cycle: 48.939, 100 cycle: 43.585\n",
      "epoch:[233 / 1000] batch:[30 / 134] loss= 0.044\n",
      "epoch:[233 / 1000] batch:[60 / 134] loss= 0.119\n",
      "epoch:[233 / 1000] batch:[90 / 134] loss= 0.089\n",
      "epoch:[233 / 1000] batch:[120 / 134] loss= 0.124\n",
      "100 cycles trn_loss: 0.079, val_loss: 0.109, lr=2.140463e-05\n",
      "training set RMSE 1 cycle: 41.777, 10 cycle: 38.908, 100 cycle: 39.094\n",
      "testing set RMSE 1 cycle: 52.510, 10 cycle: 43.541, 100 cycle: 43.556\n",
      "epoch:[234 / 1000] batch:[30 / 134] loss= 0.121\n",
      "epoch:[234 / 1000] batch:[60 / 134] loss= 0.097\n",
      "epoch:[234 / 1000] batch:[90 / 134] loss= 0.059\n",
      "epoch:[234 / 1000] batch:[120 / 134] loss= 0.069\n",
      "100 cycles trn_loss: 0.070, val_loss: 0.093, lr=3.520366e-05\n",
      "training set RMSE 1 cycle: 46.351, 10 cycle: 40.145, 100 cycle: 36.755\n",
      "testing set RMSE 1 cycle: 48.541, 10 cycle: 47.737, 100 cycle: 40.190\n",
      "epoch:[235 / 1000] batch:[30 / 134] loss= 0.046\n",
      "epoch:[235 / 1000] batch:[60 / 134] loss= 0.085\n",
      "epoch:[235 / 1000] batch:[90 / 134] loss= 0.051\n",
      "epoch:[235 / 1000] batch:[120 / 134] loss= 0.025\n",
      "100 cycles trn_loss: 0.069, val_loss: 0.089, lr=5.050000e-05\n",
      "training set RMSE 1 cycle: 49.900, 10 cycle: 42.675, 100 cycle: 36.027\n",
      "testing set RMSE 1 cycle: 51.868, 10 cycle: 49.114, 100 cycle: 39.151\n",
      "epoch:[236 / 1000] batch:[30 / 134] loss= 0.040\n",
      "epoch:[236 / 1000] batch:[60 / 134] loss= 0.129\n",
      "epoch:[236 / 1000] batch:[90 / 134] loss= 0.076\n",
      "epoch:[236 / 1000] batch:[120 / 134] loss= 0.068\n",
      "100 cycles trn_loss: 0.093, val_loss: 0.145, lr=6.579634e-05\n",
      "training set RMSE 1 cycle: 39.618, 10 cycle: 40.673, 100 cycle: 42.681\n",
      "testing set RMSE 1 cycle: 53.589, 10 cycle: 48.204, 100 cycle: 50.356\n",
      "epoch:[237 / 1000] batch:[30 / 134] loss= 0.192\n",
      "epoch:[237 / 1000] batch:[60 / 134] loss= 0.051\n",
      "epoch:[237 / 1000] batch:[90 / 134] loss= 0.031\n",
      "epoch:[237 / 1000] batch:[120 / 134] loss= 0.037\n",
      "100 cycles trn_loss: 0.078, val_loss: 0.114, lr=7.959537e-05\n",
      "training set RMSE 1 cycle: 57.690, 10 cycle: 52.361, 100 cycle: 38.852\n",
      "testing set RMSE 1 cycle: 56.091, 10 cycle: 56.533, 100 cycle: 44.662\n",
      "epoch:[238 / 1000] batch:[30 / 134] loss= 0.116\n",
      "epoch:[238 / 1000] batch:[60 / 134] loss= 0.094\n",
      "epoch:[238 / 1000] batch:[90 / 134] loss= 0.090\n",
      "epoch:[238 / 1000] batch:[120 / 134] loss= 0.103\n",
      "100 cycles trn_loss: 0.071, val_loss: 0.115, lr=9.054634e-05\n",
      "training set RMSE 1 cycle: 57.466, 10 cycle: 51.122, 100 cycle: 36.315\n",
      "testing set RMSE 1 cycle: 55.028, 10 cycle: 57.735, 100 cycle: 45.541\n",
      "epoch:[239 / 1000] batch:[30 / 134] loss= 0.103\n",
      "epoch:[239 / 1000] batch:[60 / 134] loss= 0.068\n",
      "epoch:[239 / 1000] batch:[90 / 134] loss= 0.068\n",
      "epoch:[239 / 1000] batch:[120 / 134] loss= 0.127\n",
      "100 cycles trn_loss: 0.097, val_loss: 0.129, lr=9.757730e-05\n",
      "training set RMSE 1 cycle: 62.843, 10 cycle: 58.963, 100 cycle: 42.712\n",
      "testing set RMSE 1 cycle: 59.637, 10 cycle: 60.626, 100 cycle: 47.981\n",
      "epoch:[240 / 1000] batch:[30 / 134] loss= 0.119\n",
      "epoch:[240 / 1000] batch:[60 / 134] loss= 0.038\n",
      "epoch:[240 / 1000] batch:[90 / 134] loss= 0.227\n",
      "epoch:[240 / 1000] batch:[120 / 134] loss= 0.086\n",
      "100 cycles trn_loss: 0.072, val_loss: 0.117, lr=1.000000e-04\n",
      "training set RMSE 1 cycle: 47.615, 10 cycle: 43.798, 100 cycle: 37.537\n",
      "testing set RMSE 1 cycle: 52.811, 10 cycle: 53.651, 100 cycle: 44.973\n",
      "epoch:[241 / 1000] batch:[30 / 134] loss= 0.108\n",
      "epoch:[241 / 1000] batch:[60 / 134] loss= 0.066\n",
      "epoch:[241 / 1000] batch:[90 / 134] loss= 0.088\n",
      "epoch:[241 / 1000] batch:[120 / 134] loss= 0.118\n",
      "100 cycles trn_loss: 0.089, val_loss: 0.099, lr=9.757730e-05\n",
      "training set RMSE 1 cycle: 52.603, 10 cycle: 47.699, 100 cycle: 41.074\n",
      "testing set RMSE 1 cycle: 52.881, 10 cycle: 49.804, 100 cycle: 41.387\n",
      "epoch:[242 / 1000] batch:[30 / 134] loss= 0.111\n",
      "epoch:[242 / 1000] batch:[60 / 134] loss= 0.105\n",
      "epoch:[242 / 1000] batch:[90 / 134] loss= 0.100\n",
      "epoch:[242 / 1000] batch:[120 / 134] loss= 0.385\n",
      "100 cycles trn_loss: 0.106, val_loss: 0.204, lr=9.054634e-05\n",
      "training set RMSE 1 cycle: 43.452, 10 cycle: 43.932, 100 cycle: 44.227\n",
      "testing set RMSE 1 cycle: 66.047, 10 cycle: 60.319, 100 cycle: 60.331\n",
      "epoch:[243 / 1000] batch:[30 / 134] loss= 0.069\n",
      "epoch:[243 / 1000] batch:[60 / 134] loss= 0.096\n",
      "epoch:[243 / 1000] batch:[90 / 134] loss= 0.068\n",
      "epoch:[243 / 1000] batch:[120 / 134] loss= 0.114\n",
      "100 cycles trn_loss: 0.094, val_loss: 0.209, lr=7.959537e-05\n",
      "training set RMSE 1 cycle: 51.586, 10 cycle: 50.513, 100 cycle: 41.331\n",
      "testing set RMSE 1 cycle: 63.174, 10 cycle: 67.766, 100 cycle: 61.442\n",
      "epoch:[244 / 1000] batch:[30 / 134] loss= 0.071\n",
      "epoch:[244 / 1000] batch:[60 / 134] loss= 0.035\n",
      "epoch:[244 / 1000] batch:[90 / 134] loss= 0.106\n",
      "epoch:[244 / 1000] batch:[120 / 134] loss= 0.144\n",
      "100 cycles trn_loss: 0.075, val_loss: 0.140, lr=6.579634e-05\n",
      "training set RMSE 1 cycle: 40.878, 10 cycle: 39.261, 100 cycle: 37.606\n",
      "testing set RMSE 1 cycle: 58.125, 10 cycle: 53.952, 100 cycle: 49.457\n",
      "epoch:[245 / 1000] batch:[30 / 134] loss= 0.099\n",
      "epoch:[245 / 1000] batch:[60 / 134] loss= 0.152\n",
      "epoch:[245 / 1000] batch:[90 / 134] loss= 0.024\n",
      "epoch:[245 / 1000] batch:[120 / 134] loss= 0.112\n",
      "100 cycles trn_loss: 0.136, val_loss: 0.163, lr=5.050000e-05\n",
      "training set RMSE 1 cycle: 69.823, 10 cycle: 67.635, 100 cycle: 49.309\n",
      "testing set RMSE 1 cycle: 67.864, 10 cycle: 68.898, 100 cycle: 55.729\n",
      "epoch:[246 / 1000] batch:[30 / 134] loss= 0.082\n",
      "epoch:[246 / 1000] batch:[60 / 134] loss= 0.124\n",
      "epoch:[246 / 1000] batch:[90 / 134] loss= 0.068\n",
      "epoch:[246 / 1000] batch:[120 / 134] loss= 0.087\n",
      "100 cycles trn_loss: 0.084, val_loss: 0.116, lr=3.520366e-05\n",
      "training set RMSE 1 cycle: 43.788, 10 cycle: 41.657, 100 cycle: 40.906\n",
      "testing set RMSE 1 cycle: 53.829, 10 cycle: 47.372, 100 cycle: 44.857\n",
      "epoch:[247 / 1000] batch:[30 / 134] loss= 0.124\n",
      "epoch:[247 / 1000] batch:[60 / 134] loss= 0.094\n",
      "epoch:[247 / 1000] batch:[90 / 134] loss= 0.114\n",
      "epoch:[247 / 1000] batch:[120 / 134] loss= 0.116\n",
      "100 cycles trn_loss: 0.066, val_loss: 0.108, lr=2.140463e-05\n",
      "training set RMSE 1 cycle: 43.214, 10 cycle: 38.221, 100 cycle: 34.984\n",
      "testing set RMSE 1 cycle: 54.925, 10 cycle: 50.281, 100 cycle: 43.276\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:[248 / 1000] batch:[30 / 134] loss= 0.073\n",
      "epoch:[248 / 1000] batch:[60 / 134] loss= 0.080\n",
      "epoch:[248 / 1000] batch:[90 / 134] loss= 0.046\n",
      "epoch:[248 / 1000] batch:[120 / 134] loss= 0.073\n",
      "100 cycles trn_loss: 0.064, val_loss: 0.121, lr=1.045366e-05\n",
      "training set RMSE 1 cycle: 46.629, 10 cycle: 41.052, 100 cycle: 34.280\n",
      "testing set RMSE 1 cycle: 55.100, 10 cycle: 55.371, 100 cycle: 45.994\n",
      "epoch:[249 / 1000] batch:[30 / 134] loss= 0.043\n",
      "epoch:[249 / 1000] batch:[60 / 134] loss= 0.045\n",
      "epoch:[249 / 1000] batch:[90 / 134] loss= 0.087\n",
      "epoch:[249 / 1000] batch:[120 / 134] loss= 0.028\n",
      "100 cycles trn_loss: 0.070, val_loss: 0.111, lr=3.422702e-06\n",
      "training set RMSE 1 cycle: 41.131, 10 cycle: 37.038, 100 cycle: 35.969\n",
      "testing set RMSE 1 cycle: 56.505, 10 cycle: 48.173, 100 cycle: 44.034\n",
      "epoch:[250 / 1000] batch:[30 / 134] loss= 0.072\n",
      "epoch:[250 / 1000] batch:[60 / 134] loss= 0.133\n",
      "epoch:[250 / 1000] batch:[90 / 134] loss= 0.046\n",
      "epoch:[250 / 1000] batch:[120 / 134] loss= 0.026\n",
      "100 cycles trn_loss: 0.064, val_loss: 0.105, lr=1.000000e-06\n",
      "training set RMSE 1 cycle: 43.654, 10 cycle: 37.796, 100 cycle: 34.495\n",
      "testing set RMSE 1 cycle: 54.798, 10 cycle: 49.826, 100 cycle: 42.698\n",
      "epoch:[251 / 1000] batch:[30 / 134] loss= 0.065\n",
      "epoch:[251 / 1000] batch:[60 / 134] loss= 0.023\n",
      "epoch:[251 / 1000] batch:[90 / 134] loss= 0.040\n",
      "epoch:[251 / 1000] batch:[120 / 134] loss= 0.035\n",
      "100 cycles trn_loss: 0.067, val_loss: 0.109, lr=3.422702e-06\n",
      "training set RMSE 1 cycle: 42.075, 10 cycle: 37.322, 100 cycle: 35.300\n",
      "testing set RMSE 1 cycle: 55.153, 10 cycle: 49.290, 100 cycle: 43.463\n",
      "epoch:[252 / 1000] batch:[30 / 134] loss= 0.050\n",
      "epoch:[252 / 1000] batch:[60 / 134] loss= 0.134\n",
      "epoch:[252 / 1000] batch:[90 / 134] loss= 0.047\n",
      "epoch:[252 / 1000] batch:[120 / 134] loss= 0.121\n",
      "100 cycles trn_loss: 0.067, val_loss: 0.103, lr=1.045366e-05\n",
      "training set RMSE 1 cycle: 42.354, 10 cycle: 37.287, 100 cycle: 35.381\n",
      "testing set RMSE 1 cycle: 54.811, 10 cycle: 47.904, 100 cycle: 42.286\n",
      "epoch:[253 / 1000] batch:[30 / 134] loss= 0.113\n",
      "epoch:[253 / 1000] batch:[60 / 134] loss= 0.050\n",
      "epoch:[253 / 1000] batch:[90 / 134] loss= 0.097\n",
      "epoch:[253 / 1000] batch:[120 / 134] loss= 0.032\n",
      "100 cycles trn_loss: 0.064, val_loss: 0.100, lr=2.140463e-05\n",
      "training set RMSE 1 cycle: 43.716, 10 cycle: 38.085, 100 cycle: 34.752\n",
      "testing set RMSE 1 cycle: 54.093, 10 cycle: 49.159, 100 cycle: 41.691\n",
      "epoch:[254 / 1000] batch:[30 / 134] loss= 0.084\n",
      "epoch:[254 / 1000] batch:[60 / 134] loss= 0.058\n",
      "epoch:[254 / 1000] batch:[90 / 134] loss= 0.088\n",
      "epoch:[254 / 1000] batch:[120 / 134] loss= 0.096\n",
      "100 cycles trn_loss: 0.061, val_loss: 0.101, lr=3.520366e-05\n",
      "training set RMSE 1 cycle: 46.141, 10 cycle: 39.347, 100 cycle: 33.229\n",
      "testing set RMSE 1 cycle: 54.717, 10 cycle: 51.611, 100 cycle: 41.802\n",
      "epoch:[255 / 1000] batch:[30 / 134] loss= 0.054\n",
      "epoch:[255 / 1000] batch:[60 / 134] loss= 0.105\n",
      "epoch:[255 / 1000] batch:[90 / 134] loss= 0.072\n",
      "epoch:[255 / 1000] batch:[120 / 134] loss= 0.135\n",
      "100 cycles trn_loss: 0.094, val_loss: 0.120, lr=5.050000e-05\n",
      "training set RMSE 1 cycle: 42.812, 10 cycle: 43.900, 100 cycle: 43.969\n",
      "testing set RMSE 1 cycle: 54.858, 10 cycle: 41.331, 100 cycle: 45.749\n",
      "epoch:[256 / 1000] batch:[30 / 134] loss= 0.092\n",
      "epoch:[256 / 1000] batch:[60 / 134] loss= 0.126\n",
      "epoch:[256 / 1000] batch:[90 / 134] loss= 0.092\n",
      "epoch:[256 / 1000] batch:[120 / 134] loss= 0.122\n",
      "100 cycles trn_loss: 0.110, val_loss: 0.135, lr=6.579634e-05\n",
      "training set RMSE 1 cycle: 66.304, 10 cycle: 64.616, 100 cycle: 47.050\n",
      "testing set RMSE 1 cycle: 61.171, 10 cycle: 61.489, 100 cycle: 49.919\n",
      "epoch:[257 / 1000] batch:[30 / 134] loss= 0.035\n",
      "epoch:[257 / 1000] batch:[60 / 134] loss= 0.092\n",
      "epoch:[257 / 1000] batch:[90 / 134] loss= 0.042\n",
      "epoch:[257 / 1000] batch:[120 / 134] loss= 0.094\n",
      "100 cycles trn_loss: 0.063, val_loss: 0.120, lr=7.959537e-05\n",
      "training set RMSE 1 cycle: 48.308, 10 cycle: 43.369, 100 cycle: 34.246\n",
      "testing set RMSE 1 cycle: 54.764, 10 cycle: 56.004, 100 cycle: 45.738\n",
      "epoch:[258 / 1000] batch:[30 / 134] loss= 0.072\n",
      "epoch:[258 / 1000] batch:[60 / 134] loss= 0.072\n",
      "epoch:[258 / 1000] batch:[90 / 134] loss= 0.098\n",
      "epoch:[258 / 1000] batch:[120 / 134] loss= 0.061\n",
      "100 cycles trn_loss: 0.134, val_loss: 0.135, lr=9.054634e-05\n",
      "training set RMSE 1 cycle: 57.295, 10 cycle: 55.233, 100 cycle: 52.941\n",
      "testing set RMSE 1 cycle: 53.691, 10 cycle: 47.000, 100 cycle: 48.286\n",
      "epoch:[259 / 1000] batch:[30 / 134] loss= 0.074\n",
      "epoch:[259 / 1000] batch:[60 / 134] loss= 0.177\n",
      "epoch:[259 / 1000] batch:[90 / 134] loss= 0.249\n",
      "epoch:[259 / 1000] batch:[120 / 134] loss= 0.110\n",
      "100 cycles trn_loss: 0.106, val_loss: 0.165, lr=9.757730e-05\n",
      "training set RMSE 1 cycle: 63.737, 10 cycle: 49.166, 100 cycle: 46.615\n",
      "testing set RMSE 1 cycle: 56.584, 10 cycle: 53.492, 100 cycle: 53.368\n",
      "epoch:[260 / 1000] batch:[30 / 134] loss= 0.148\n",
      "epoch:[260 / 1000] batch:[60 / 134] loss= 0.134\n",
      "epoch:[260 / 1000] batch:[90 / 134] loss= 0.181\n",
      "epoch:[260 / 1000] batch:[120 / 134] loss= 0.122\n",
      "100 cycles trn_loss: 0.105, val_loss: 0.191, lr=1.000000e-04\n",
      "training set RMSE 1 cycle: 67.867, 10 cycle: 51.239, 100 cycle: 45.845\n",
      "testing set RMSE 1 cycle: 62.251, 10 cycle: 59.119, 100 cycle: 57.911\n",
      "epoch:[261 / 1000] batch:[30 / 134] loss= 0.158\n",
      "epoch:[261 / 1000] batch:[60 / 134] loss= 0.184\n",
      "epoch:[261 / 1000] batch:[90 / 134] loss= 0.132\n",
      "epoch:[261 / 1000] batch:[120 / 134] loss= 0.121\n",
      "100 cycles trn_loss: 0.107, val_loss: 0.179, lr=9.757730e-05\n",
      "training set RMSE 1 cycle: 57.640, 10 cycle: 48.731, 100 cycle: 47.170\n",
      "testing set RMSE 1 cycle: 58.897, 10 cycle: 54.244, 100 cycle: 55.753\n",
      "epoch:[262 / 1000] batch:[30 / 134] loss= 0.144\n",
      "epoch:[262 / 1000] batch:[60 / 134] loss= 0.062\n",
      "epoch:[262 / 1000] batch:[90 / 134] loss= 0.045\n",
      "epoch:[262 / 1000] batch:[120 / 134] loss= 0.137\n",
      "100 cycles trn_loss: 0.092, val_loss: 0.175, lr=9.054634e-05\n",
      "training set RMSE 1 cycle: 58.728, 10 cycle: 47.459, 100 cycle: 42.955\n",
      "testing set RMSE 1 cycle: 55.435, 10 cycle: 57.002, 100 cycle: 55.265\n",
      "epoch:[263 / 1000] batch:[30 / 134] loss= 0.074\n",
      "epoch:[263 / 1000] batch:[60 / 134] loss= 0.058\n",
      "epoch:[263 / 1000] batch:[90 / 134] loss= 0.118\n",
      "epoch:[263 / 1000] batch:[120 / 134] loss= 0.028\n",
      "100 cycles trn_loss: 0.138, val_loss: 0.222, lr=7.959537e-05\n",
      "training set RMSE 1 cycle: 55.208, 10 cycle: 52.294, 100 cycle: 53.742\n",
      "testing set RMSE 1 cycle: 61.608, 10 cycle: 57.640, 100 cycle: 62.601\n",
      "epoch:[264 / 1000] batch:[30 / 134] loss= 0.119\n",
      "epoch:[264 / 1000] batch:[60 / 134] loss= 0.115\n",
      "epoch:[264 / 1000] batch:[90 / 134] loss= 0.098\n",
      "epoch:[264 / 1000] batch:[120 / 134] loss= 0.097\n",
      "100 cycles trn_loss: 0.123, val_loss: 0.155, lr=6.579634e-05\n",
      "training set RMSE 1 cycle: 56.039, 10 cycle: 52.284, 100 cycle: 50.671\n",
      "testing set RMSE 1 cycle: 57.087, 10 cycle: 49.767, 100 cycle: 51.739\n",
      "epoch:[265 / 1000] batch:[30 / 134] loss= 0.092\n",
      "epoch:[265 / 1000] batch:[60 / 134] loss= 0.022\n",
      "epoch:[265 / 1000] batch:[90 / 134] loss= 0.031\n",
      "epoch:[265 / 1000] batch:[120 / 134] loss= 0.063\n",
      "100 cycles trn_loss: 0.085, val_loss: 0.126, lr=5.050000e-05\n",
      "training set RMSE 1 cycle: 61.925, 10 cycle: 54.362, 100 cycle: 40.274\n",
      "testing set RMSE 1 cycle: 55.105, 10 cycle: 56.978, 100 cycle: 46.920\n",
      "epoch:[266 / 1000] batch:[30 / 134] loss= 0.034\n",
      "epoch:[266 / 1000] batch:[60 / 134] loss= 0.195\n",
      "epoch:[266 / 1000] batch:[90 / 134] loss= 0.054\n",
      "epoch:[266 / 1000] batch:[120 / 134] loss= 0.163\n",
      "100 cycles trn_loss: 0.104, val_loss: 0.148, lr=3.520366e-05\n",
      "training set RMSE 1 cycle: 46.591, 10 cycle: 44.976, 100 cycle: 45.927\n",
      "testing set RMSE 1 cycle: 60.298, 10 cycle: 48.873, 100 cycle: 50.669\n",
      "epoch:[267 / 1000] batch:[30 / 134] loss= 0.137\n",
      "epoch:[267 / 1000] batch:[60 / 134] loss= 0.085\n",
      "epoch:[267 / 1000] batch:[90 / 134] loss= 0.114\n",
      "epoch:[267 / 1000] batch:[120 / 134] loss= 0.095\n",
      "100 cycles trn_loss: 0.092, val_loss: 0.133, lr=2.140463e-05\n",
      "training set RMSE 1 cycle: 46.936, 10 cycle: 41.856, 100 cycle: 42.319\n",
      "testing set RMSE 1 cycle: 50.794, 10 cycle: 48.687, 100 cycle: 48.034\n",
      "epoch:[268 / 1000] batch:[30 / 134] loss= 0.052\n",
      "epoch:[268 / 1000] batch:[60 / 134] loss= 0.124\n",
      "epoch:[268 / 1000] batch:[90 / 134] loss= 0.096\n",
      "epoch:[268 / 1000] batch:[120 / 134] loss= 0.105\n",
      "100 cycles trn_loss: 0.072, val_loss: 0.115, lr=1.045366e-05\n",
      "training set RMSE 1 cycle: 53.594, 10 cycle: 46.936, 100 cycle: 37.031\n",
      "testing set RMSE 1 cycle: 51.626, 10 cycle: 53.887, 100 cycle: 44.697\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:[269 / 1000] batch:[30 / 134] loss= 0.080\n",
      "epoch:[269 / 1000] batch:[60 / 134] loss= 0.057\n",
      "epoch:[269 / 1000] batch:[90 / 134] loss= 0.075\n",
      "epoch:[269 / 1000] batch:[120 / 134] loss= 0.145\n",
      "100 cycles trn_loss: 0.084, val_loss: 0.125, lr=3.422702e-06\n",
      "training set RMSE 1 cycle: 45.195, 10 cycle: 40.548, 100 cycle: 39.945\n",
      "testing set RMSE 1 cycle: 52.056, 10 cycle: 49.813, 100 cycle: 46.648\n",
      "epoch:[270 / 1000] batch:[30 / 134] loss= 0.143\n",
      "epoch:[270 / 1000] batch:[60 / 134] loss= 0.163\n",
      "epoch:[270 / 1000] batch:[90 / 134] loss= 0.101\n",
      "epoch:[270 / 1000] batch:[120 / 134] loss= 0.086\n",
      "100 cycles trn_loss: 0.075, val_loss: 0.106, lr=1.000000e-06\n",
      "training set RMSE 1 cycle: 47.740, 10 cycle: 41.137, 100 cycle: 37.620\n",
      "testing set RMSE 1 cycle: 50.098, 10 cycle: 49.492, 100 cycle: 42.824\n",
      "epoch:[271 / 1000] batch:[30 / 134] loss= 0.047\n",
      "epoch:[271 / 1000] batch:[60 / 134] loss= 0.036\n",
      "epoch:[271 / 1000] batch:[90 / 134] loss= 0.093\n",
      "epoch:[271 / 1000] batch:[120 / 134] loss= 0.165\n",
      "100 cycles trn_loss: 0.074, val_loss: 0.111, lr=3.422702e-06\n",
      "training set RMSE 1 cycle: 48.342, 10 cycle: 41.512, 100 cycle: 37.476\n",
      "testing set RMSE 1 cycle: 50.385, 10 cycle: 50.667, 100 cycle: 43.907\n",
      "epoch:[272 / 1000] batch:[30 / 134] loss= 0.033\n",
      "epoch:[272 / 1000] batch:[60 / 134] loss= 0.078\n",
      "epoch:[272 / 1000] batch:[90 / 134] loss= 0.128\n",
      "epoch:[272 / 1000] batch:[120 / 134] loss= 0.084\n",
      "100 cycles trn_loss: 0.075, val_loss: 0.109, lr=1.045366e-05\n",
      "training set RMSE 1 cycle: 47.064, 10 cycle: 40.756, 100 cycle: 37.703\n",
      "testing set RMSE 1 cycle: 50.372, 10 cycle: 49.715, 100 cycle: 43.486\n",
      "epoch:[273 / 1000] batch:[30 / 134] loss= 0.154\n",
      "epoch:[273 / 1000] batch:[60 / 134] loss= 0.117\n",
      "epoch:[273 / 1000] batch:[90 / 134] loss= 0.141\n",
      "epoch:[273 / 1000] batch:[120 / 134] loss= 0.078\n",
      "100 cycles trn_loss: 0.076, val_loss: 0.106, lr=2.140463e-05\n",
      "training set RMSE 1 cycle: 45.194, 10 cycle: 40.524, 100 cycle: 37.785\n",
      "testing set RMSE 1 cycle: 51.023, 10 cycle: 49.264, 100 cycle: 42.899\n",
      "epoch:[274 / 1000] batch:[30 / 134] loss= 0.135\n",
      "epoch:[274 / 1000] batch:[60 / 134] loss= 0.079\n",
      "epoch:[274 / 1000] batch:[90 / 134] loss= 0.047\n",
      "epoch:[274 / 1000] batch:[120 / 134] loss= 0.120\n",
      "100 cycles trn_loss: 0.071, val_loss: 0.108, lr=3.520366e-05\n",
      "training set RMSE 1 cycle: 47.644, 10 cycle: 42.152, 100 cycle: 36.410\n",
      "testing set RMSE 1 cycle: 50.709, 10 cycle: 51.184, 100 cycle: 43.143\n",
      "epoch:[275 / 1000] batch:[30 / 134] loss= 0.051\n",
      "epoch:[275 / 1000] batch:[60 / 134] loss= 0.090\n",
      "epoch:[275 / 1000] batch:[90 / 134] loss= 0.060\n",
      "epoch:[275 / 1000] batch:[120 / 134] loss= 0.093\n",
      "100 cycles trn_loss: 0.073, val_loss: 0.132, lr=5.050000e-05\n",
      "training set RMSE 1 cycle: 55.405, 10 cycle: 46.693, 100 cycle: 37.244\n",
      "testing set RMSE 1 cycle: 51.574, 10 cycle: 55.195, 100 cycle: 47.814\n",
      "epoch:[276 / 1000] batch:[30 / 134] loss= 0.113\n",
      "epoch:[276 / 1000] batch:[60 / 134] loss= 0.074\n",
      "epoch:[276 / 1000] batch:[90 / 134] loss= 0.123\n",
      "epoch:[276 / 1000] batch:[120 / 134] loss= 0.070\n",
      "100 cycles trn_loss: 0.077, val_loss: 0.149, lr=6.579634e-05\n",
      "training set RMSE 1 cycle: 49.212, 10 cycle: 43.317, 100 cycle: 37.934\n",
      "testing set RMSE 1 cycle: 54.906, 10 cycle: 57.285, 100 cycle: 50.803\n",
      "epoch:[277 / 1000] batch:[30 / 134] loss= 0.092\n",
      "epoch:[277 / 1000] batch:[60 / 134] loss= 0.065\n",
      "epoch:[277 / 1000] batch:[90 / 134] loss= 0.143\n",
      "epoch:[277 / 1000] batch:[120 / 134] loss= 0.173\n",
      "100 cycles trn_loss: 0.090, val_loss: 0.096, lr=7.959537e-05\n",
      "training set RMSE 1 cycle: 53.333, 10 cycle: 47.710, 100 cycle: 40.610\n",
      "testing set RMSE 1 cycle: 54.410, 10 cycle: 51.114, 100 cycle: 40.676\n",
      "epoch:[278 / 1000] batch:[30 / 134] loss= 0.233\n",
      "epoch:[278 / 1000] batch:[60 / 134] loss= 0.071\n",
      "epoch:[278 / 1000] batch:[90 / 134] loss= 0.133\n",
      "epoch:[278 / 1000] batch:[120 / 134] loss= 0.113\n",
      "100 cycles trn_loss: 0.097, val_loss: 0.113, lr=9.054634e-05\n",
      "training set RMSE 1 cycle: 46.063, 10 cycle: 46.066, 100 cycle: 44.008\n",
      "testing set RMSE 1 cycle: 54.380, 10 cycle: 46.126, 100 cycle: 44.273\n",
      "epoch:[279 / 1000] batch:[30 / 134] loss= 0.116\n",
      "epoch:[279 / 1000] batch:[60 / 134] loss= 0.138\n",
      "epoch:[279 / 1000] batch:[90 / 134] loss= 0.160\n",
      "epoch:[279 / 1000] batch:[120 / 134] loss= 0.109\n",
      "100 cycles trn_loss: 0.100, val_loss: 0.140, lr=9.757730e-05\n",
      "training set RMSE 1 cycle: 43.397, 10 cycle: 43.725, 100 cycle: 44.555\n",
      "testing set RMSE 1 cycle: 50.860, 10 cycle: 48.408, 100 cycle: 49.362\n",
      "epoch:[280 / 1000] batch:[30 / 134] loss= 0.082\n",
      "epoch:[280 / 1000] batch:[60 / 134] loss= 0.102\n",
      "epoch:[280 / 1000] batch:[90 / 134] loss= 0.106\n",
      "epoch:[280 / 1000] batch:[120 / 134] loss= 0.076\n",
      "100 cycles trn_loss: 0.073, val_loss: 0.090, lr=1.000000e-04\n",
      "training set RMSE 1 cycle: 49.698, 10 cycle: 43.919, 100 cycle: 36.892\n",
      "testing set RMSE 1 cycle: 49.647, 10 cycle: 49.573, 100 cycle: 39.379\n",
      "epoch:[281 / 1000] batch:[30 / 134] loss= 0.128\n",
      "epoch:[281 / 1000] batch:[60 / 134] loss= 0.148\n",
      "epoch:[281 / 1000] batch:[90 / 134] loss= 0.122\n",
      "epoch:[281 / 1000] batch:[120 / 134] loss= 0.119\n",
      "100 cycles trn_loss: 0.119, val_loss: 0.115, lr=9.757730e-05\n",
      "training set RMSE 1 cycle: 66.692, 10 cycle: 64.423, 100 cycle: 47.656\n",
      "testing set RMSE 1 cycle: 62.136, 10 cycle: 61.599, 100 cycle: 45.503\n",
      "epoch:[282 / 1000] batch:[30 / 134] loss= 0.163\n",
      "epoch:[282 / 1000] batch:[60 / 134] loss= 0.161\n",
      "epoch:[282 / 1000] batch:[90 / 134] loss= 0.067\n",
      "epoch:[282 / 1000] batch:[120 / 134] loss= 0.115\n",
      "100 cycles trn_loss: 0.115, val_loss: 0.185, lr=9.054634e-05\n",
      "training set RMSE 1 cycle: 45.564, 10 cycle: 46.582, 100 cycle: 47.937\n",
      "testing set RMSE 1 cycle: 61.501, 10 cycle: 55.411, 100 cycle: 57.006\n",
      "epoch:[283 / 1000] batch:[30 / 134] loss= 0.054\n",
      "epoch:[283 / 1000] batch:[60 / 134] loss= 0.130\n",
      "epoch:[283 / 1000] batch:[90 / 134] loss= 0.146\n",
      "epoch:[283 / 1000] batch:[120 / 134] loss= 0.132\n",
      "100 cycles trn_loss: 0.092, val_loss: 0.148, lr=7.959537e-05\n",
      "training set RMSE 1 cycle: 41.804, 10 cycle: 42.593, 100 cycle: 42.772\n",
      "testing set RMSE 1 cycle: 55.353, 10 cycle: 52.293, 100 cycle: 50.774\n",
      "epoch:[284 / 1000] batch:[30 / 134] loss= 0.152\n",
      "epoch:[284 / 1000] batch:[60 / 134] loss= 0.054\n",
      "epoch:[284 / 1000] batch:[90 / 134] loss= 0.122\n",
      "epoch:[284 / 1000] batch:[120 / 134] loss= 0.091\n",
      "100 cycles trn_loss: 0.085, val_loss: 0.093, lr=6.579634e-05\n",
      "training set RMSE 1 cycle: 43.134, 10 cycle: 42.043, 100 cycle: 40.295\n",
      "testing set RMSE 1 cycle: 49.297, 10 cycle: 42.330, 100 cycle: 40.085\n",
      "epoch:[285 / 1000] batch:[30 / 134] loss= 0.082\n",
      "epoch:[285 / 1000] batch:[60 / 134] loss= 0.166\n",
      "epoch:[285 / 1000] batch:[90 / 134] loss= 0.111\n",
      "epoch:[285 / 1000] batch:[120 / 134] loss= 0.099\n",
      "100 cycles trn_loss: 0.129, val_loss: 0.169, lr=5.050000e-05\n",
      "training set RMSE 1 cycle: 45.553, 10 cycle: 50.648, 100 cycle: 52.209\n",
      "testing set RMSE 1 cycle: 57.300, 10 cycle: 48.925, 100 cycle: 54.382\n",
      "epoch:[286 / 1000] batch:[30 / 134] loss= 0.135\n",
      "epoch:[286 / 1000] batch:[60 / 134] loss= 0.091\n",
      "epoch:[286 / 1000] batch:[90 / 134] loss= 0.106\n",
      "epoch:[286 / 1000] batch:[120 / 134] loss= 0.070\n",
      "100 cycles trn_loss: 0.066, val_loss: 0.103, lr=3.520366e-05\n",
      "training set RMSE 1 cycle: 47.811, 10 cycle: 42.140, 100 cycle: 34.957\n",
      "testing set RMSE 1 cycle: 51.498, 10 cycle: 53.642, 100 cycle: 42.295\n",
      "epoch:[287 / 1000] batch:[30 / 134] loss= 0.099\n",
      "epoch:[287 / 1000] batch:[60 / 134] loss= 0.084\n",
      "epoch:[287 / 1000] batch:[90 / 134] loss= 0.079\n",
      "epoch:[287 / 1000] batch:[120 / 134] loss= 0.130\n",
      "100 cycles trn_loss: 0.065, val_loss: 0.081, lr=2.140463e-05\n",
      "training set RMSE 1 cycle: 48.603, 10 cycle: 41.436, 100 cycle: 34.961\n",
      "testing set RMSE 1 cycle: 49.799, 10 cycle: 50.002, 100 cycle: 37.549\n",
      "epoch:[288 / 1000] batch:[30 / 134] loss= 0.065\n",
      "epoch:[288 / 1000] batch:[60 / 134] loss= 0.124\n",
      "epoch:[288 / 1000] batch:[90 / 134] loss= 0.116\n",
      "epoch:[288 / 1000] batch:[120 / 134] loss= 0.061\n",
      "100 cycles trn_loss: 0.068, val_loss: 0.094, lr=1.045366e-05\n",
      "training set RMSE 1 cycle: 40.134, 10 cycle: 35.696, 100 cycle: 35.282\n",
      "testing set RMSE 1 cycle: 49.318, 10 cycle: 46.252, 100 cycle: 40.472\n",
      "epoch:[289 / 1000] batch:[30 / 134] loss= 0.048\n",
      "epoch:[289 / 1000] batch:[60 / 134] loss= 0.066\n",
      "epoch:[289 / 1000] batch:[90 / 134] loss= 0.065\n",
      "epoch:[289 / 1000] batch:[120 / 134] loss= 0.088\n",
      "100 cycles trn_loss: 0.060, val_loss: 0.077, lr=3.422702e-06\n",
      "training set RMSE 1 cycle: 46.762, 10 cycle: 38.885, 100 cycle: 32.923\n",
      "testing set RMSE 1 cycle: 50.184, 10 cycle: 49.582, 100 cycle: 36.565\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:[290 / 1000] batch:[30 / 134] loss= 0.103\n",
      "epoch:[290 / 1000] batch:[60 / 134] loss= 0.072\n",
      "epoch:[290 / 1000] batch:[90 / 134] loss= 0.036\n",
      "epoch:[290 / 1000] batch:[120 / 134] loss= 0.097\n",
      "100 cycles trn_loss: 0.059, val_loss: 0.085, lr=1.000000e-06\n",
      "training set RMSE 1 cycle: 43.216, 10 cycle: 36.020, 100 cycle: 32.599\n",
      "testing set RMSE 1 cycle: 51.050, 10 cycle: 49.313, 100 cycle: 38.458\n",
      "epoch:[291 / 1000] batch:[30 / 134] loss= 0.089\n",
      "epoch:[291 / 1000] batch:[60 / 134] loss= 0.048\n",
      "epoch:[291 / 1000] batch:[90 / 134] loss= 0.036\n",
      "epoch:[291 / 1000] batch:[120 / 134] loss= 0.095\n",
      "100 cycles trn_loss: 0.060, val_loss: 0.089, lr=3.422702e-06\n",
      "training set RMSE 1 cycle: 42.875, 10 cycle: 35.853, 100 cycle: 32.647\n",
      "testing set RMSE 1 cycle: 51.416, 10 cycle: 49.724, 100 cycle: 39.236\n",
      "epoch:[292 / 1000] batch:[30 / 134] loss= 0.084\n",
      "epoch:[292 / 1000] batch:[60 / 134] loss= 0.080\n",
      "epoch:[292 / 1000] batch:[90 / 134] loss= 0.182\n",
      "epoch:[292 / 1000] batch:[120 / 134] loss= 0.060\n",
      "100 cycles trn_loss: 0.063, val_loss: 0.089, lr=1.045366e-05\n",
      "training set RMSE 1 cycle: 40.620, 10 cycle: 35.155, 100 cycle: 33.676\n",
      "testing set RMSE 1 cycle: 50.906, 10 cycle: 47.527, 100 cycle: 39.308\n",
      "epoch:[293 / 1000] batch:[30 / 134] loss= 0.060\n",
      "epoch:[293 / 1000] batch:[60 / 134] loss= 0.101\n",
      "epoch:[293 / 1000] batch:[90 / 134] loss= 0.054\n",
      "epoch:[293 / 1000] batch:[120 / 134] loss= 0.130\n",
      "100 cycles trn_loss: 0.065, val_loss: 0.093, lr=2.140463e-05\n",
      "training set RMSE 1 cycle: 40.374, 10 cycle: 35.117, 100 cycle: 34.325\n",
      "testing set RMSE 1 cycle: 50.244, 10 cycle: 47.154, 100 cycle: 40.174\n",
      "epoch:[294 / 1000] batch:[30 / 134] loss= 0.042\n",
      "epoch:[294 / 1000] batch:[60 / 134] loss= 0.033\n",
      "epoch:[294 / 1000] batch:[90 / 134] loss= 0.062\n",
      "epoch:[294 / 1000] batch:[120 / 134] loss= 0.029\n",
      "100 cycles trn_loss: 0.057, val_loss: 0.093, lr=3.520366e-05\n",
      "training set RMSE 1 cycle: 48.482, 10 cycle: 38.805, 100 cycle: 31.807\n",
      "testing set RMSE 1 cycle: 52.305, 10 cycle: 53.811, 100 cycle: 40.137\n",
      "epoch:[295 / 1000] batch:[30 / 134] loss= 0.066\n",
      "epoch:[295 / 1000] batch:[60 / 134] loss= 0.044\n",
      "epoch:[295 / 1000] batch:[90 / 134] loss= 0.122\n",
      "epoch:[295 / 1000] batch:[120 / 134] loss= 0.058\n",
      "100 cycles trn_loss: 0.059, val_loss: 0.085, lr=5.050000e-05\n",
      "training set RMSE 1 cycle: 42.756, 10 cycle: 35.530, 100 cycle: 32.274\n",
      "testing set RMSE 1 cycle: 49.897, 10 cycle: 49.226, 100 cycle: 38.365\n",
      "epoch:[296 / 1000] batch:[30 / 134] loss= 0.086\n",
      "epoch:[296 / 1000] batch:[60 / 134] loss= 0.097\n",
      "epoch:[296 / 1000] batch:[90 / 134] loss= 0.055\n",
      "epoch:[296 / 1000] batch:[120 / 134] loss= 0.069\n",
      "100 cycles trn_loss: 0.074, val_loss: 0.107, lr=6.579634e-05\n",
      "training set RMSE 1 cycle: 38.136, 10 cycle: 36.073, 100 cycle: 36.812\n",
      "testing set RMSE 1 cycle: 53.535, 10 cycle: 45.412, 100 cycle: 43.070\n",
      "epoch:[297 / 1000] batch:[30 / 134] loss= 0.066\n",
      "epoch:[297 / 1000] batch:[60 / 134] loss= 0.091\n",
      "epoch:[297 / 1000] batch:[90 / 134] loss= 0.073\n",
      "epoch:[297 / 1000] batch:[120 / 134] loss= 0.068\n",
      "100 cycles trn_loss: 0.080, val_loss: 0.088, lr=7.959537e-05\n",
      "training set RMSE 1 cycle: 47.680, 10 cycle: 43.913, 100 cycle: 40.019\n",
      "testing set RMSE 1 cycle: 48.424, 10 cycle: 47.752, 100 cycle: 39.104\n",
      "epoch:[298 / 1000] batch:[30 / 134] loss= 0.115\n",
      "epoch:[298 / 1000] batch:[60 / 134] loss= 0.071\n",
      "epoch:[298 / 1000] batch:[90 / 134] loss= 0.101\n",
      "epoch:[298 / 1000] batch:[120 / 134] loss= 0.139\n",
      "100 cycles trn_loss: 0.081, val_loss: 0.118, lr=9.054634e-05\n",
      "training set RMSE 1 cycle: 38.772, 10 cycle: 39.064, 100 cycle: 39.181\n",
      "testing set RMSE 1 cycle: 54.611, 10 cycle: 46.057, 100 cycle: 45.345\n",
      "epoch:[299 / 1000] batch:[30 / 134] loss= 0.109\n",
      "epoch:[299 / 1000] batch:[60 / 134] loss= 0.111\n",
      "epoch:[299 / 1000] batch:[90 / 134] loss= 0.189\n",
      "epoch:[299 / 1000] batch:[120 / 134] loss= 0.127\n",
      "100 cycles trn_loss: 0.097, val_loss: 0.121, lr=9.757730e-05\n",
      "training set RMSE 1 cycle: 60.688, 10 cycle: 57.451, 100 cycle: 42.940\n",
      "testing set RMSE 1 cycle: 63.188, 10 cycle: 61.323, 100 cycle: 46.666\n",
      "epoch:[300 / 1000] batch:[30 / 134] loss= 0.084\n",
      "epoch:[300 / 1000] batch:[60 / 134] loss= 0.039\n",
      "epoch:[300 / 1000] batch:[90 / 134] loss= 0.061\n",
      "epoch:[300 / 1000] batch:[120 / 134] loss= 0.122\n",
      "100 cycles trn_loss: 0.079, val_loss: 0.127, lr=1.000000e-04\n",
      "training set RMSE 1 cycle: 58.213, 10 cycle: 53.150, 100 cycle: 38.075\n",
      "testing set RMSE 1 cycle: 57.776, 10 cycle: 58.527, 100 cycle: 46.895\n",
      "epoch:[301 / 1000] batch:[30 / 134] loss= 0.185\n",
      "epoch:[301 / 1000] batch:[60 / 134] loss= 0.159\n",
      "epoch:[301 / 1000] batch:[90 / 134] loss= 0.078\n",
      "epoch:[301 / 1000] batch:[120 / 134] loss= 0.040\n",
      "100 cycles trn_loss: 0.099, val_loss: 0.108, lr=9.757730e-05\n",
      "training set RMSE 1 cycle: 43.314, 10 cycle: 46.711, 100 cycle: 45.547\n",
      "testing set RMSE 1 cycle: 52.913, 10 cycle: 42.520, 100 cycle: 43.349\n",
      "epoch:[302 / 1000] batch:[30 / 134] loss= 0.064\n",
      "epoch:[302 / 1000] batch:[60 / 134] loss= 0.097\n",
      "epoch:[302 / 1000] batch:[90 / 134] loss= 0.103\n",
      "epoch:[302 / 1000] batch:[120 / 134] loss= 0.149\n",
      "100 cycles trn_loss: 0.098, val_loss: 0.164, lr=9.054634e-05\n",
      "training set RMSE 1 cycle: 45.838, 10 cycle: 42.758, 100 cycle: 42.828\n",
      "testing set RMSE 1 cycle: 65.774, 10 cycle: 52.920, 100 cycle: 53.663\n",
      "epoch:[303 / 1000] batch:[30 / 134] loss= 0.047\n",
      "epoch:[303 / 1000] batch:[60 / 134] loss= 0.098\n",
      "epoch:[303 / 1000] batch:[90 / 134] loss= 0.094\n",
      "epoch:[303 / 1000] batch:[120 / 134] loss= 0.063\n",
      "100 cycles trn_loss: 0.100, val_loss: 0.125, lr=7.959537e-05\n",
      "training set RMSE 1 cycle: 39.489, 10 cycle: 44.129, 100 cycle: 44.836\n",
      "testing set RMSE 1 cycle: 55.493, 10 cycle: 46.678, 100 cycle: 46.792\n",
      "epoch:[304 / 1000] batch:[30 / 134] loss= 0.089\n",
      "epoch:[304 / 1000] batch:[60 / 134] loss= 0.115\n",
      "epoch:[304 / 1000] batch:[90 / 134] loss= 0.065\n",
      "epoch:[304 / 1000] batch:[120 / 134] loss= 0.057\n",
      "100 cycles trn_loss: 0.101, val_loss: 0.167, lr=6.579634e-05\n",
      "training set RMSE 1 cycle: 53.542, 10 cycle: 50.127, 100 cycle: 45.743\n",
      "testing set RMSE 1 cycle: 58.361, 10 cycle: 53.688, 100 cycle: 54.016\n",
      "epoch:[305 / 1000] batch:[30 / 134] loss= 0.072\n",
      "epoch:[305 / 1000] batch:[60 / 134] loss= 0.147\n",
      "epoch:[305 / 1000] batch:[90 / 134] loss= 0.130\n",
      "epoch:[305 / 1000] batch:[120 / 134] loss= 0.202\n",
      "100 cycles trn_loss: 0.089, val_loss: 0.121, lr=5.050000e-05\n",
      "training set RMSE 1 cycle: 48.173, 10 cycle: 46.357, 100 cycle: 42.710\n",
      "testing set RMSE 1 cycle: 50.697, 10 cycle: 47.789, 100 cycle: 45.785\n",
      "epoch:[306 / 1000] batch:[30 / 134] loss= 0.068\n",
      "epoch:[306 / 1000] batch:[60 / 134] loss= 0.085\n",
      "epoch:[306 / 1000] batch:[90 / 134] loss= 0.110\n",
      "epoch:[306 / 1000] batch:[120 / 134] loss= 0.072\n",
      "100 cycles trn_loss: 0.083, val_loss: 0.146, lr=3.520366e-05\n",
      "training set RMSE 1 cycle: 46.353, 10 cycle: 44.127, 100 cycle: 40.850\n",
      "testing set RMSE 1 cycle: 56.125, 10 cycle: 53.925, 100 cycle: 50.326\n",
      "epoch:[307 / 1000] batch:[30 / 134] loss= 0.070\n",
      "epoch:[307 / 1000] batch:[60 / 134] loss= 0.120\n",
      "epoch:[307 / 1000] batch:[90 / 134] loss= 0.094\n",
      "epoch:[307 / 1000] batch:[120 / 134] loss= 0.159\n",
      "100 cycles trn_loss: 0.083, val_loss: 0.151, lr=2.140463e-05\n",
      "training set RMSE 1 cycle: 47.126, 10 cycle: 45.149, 100 cycle: 40.502\n",
      "testing set RMSE 1 cycle: 56.691, 10 cycle: 56.209, 100 cycle: 51.208\n",
      "epoch:[308 / 1000] batch:[30 / 134] loss= 0.144\n",
      "epoch:[308 / 1000] batch:[60 / 134] loss= 0.069\n",
      "epoch:[308 / 1000] batch:[90 / 134] loss= 0.203\n",
      "epoch:[308 / 1000] batch:[120 / 134] loss= 0.086\n",
      "100 cycles trn_loss: 0.080, val_loss: 0.130, lr=1.045366e-05\n",
      "training set RMSE 1 cycle: 44.952, 10 cycle: 42.657, 100 cycle: 39.947\n",
      "testing set RMSE 1 cycle: 53.102, 10 cycle: 51.593, 100 cycle: 47.426\n",
      "epoch:[309 / 1000] batch:[30 / 134] loss= 0.063\n",
      "epoch:[309 / 1000] batch:[60 / 134] loss= 0.090\n",
      "epoch:[309 / 1000] batch:[90 / 134] loss= 0.023\n",
      "epoch:[309 / 1000] batch:[120 / 134] loss= 0.041\n",
      "100 cycles trn_loss: 0.079, val_loss: 0.119, lr=3.422702e-06\n",
      "training set RMSE 1 cycle: 44.703, 10 cycle: 42.603, 100 cycle: 39.984\n",
      "testing set RMSE 1 cycle: 51.229, 10 cycle: 49.460, 100 cycle: 45.349\n",
      "epoch:[310 / 1000] batch:[30 / 134] loss= 0.067\n",
      "epoch:[310 / 1000] batch:[60 / 134] loss= 0.200\n",
      "epoch:[310 / 1000] batch:[90 / 134] loss= 0.087\n",
      "epoch:[310 / 1000] batch:[120 / 134] loss= 0.066\n",
      "100 cycles trn_loss: 0.079, val_loss: 0.122, lr=1.000000e-06\n",
      "training set RMSE 1 cycle: 44.613, 10 cycle: 42.481, 100 cycle: 39.852\n",
      "testing set RMSE 1 cycle: 51.764, 10 cycle: 50.319, 100 cycle: 46.052\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:[311 / 1000] batch:[30 / 134] loss= 0.151\n",
      "epoch:[311 / 1000] batch:[60 / 134] loss= 0.032\n",
      "epoch:[311 / 1000] batch:[90 / 134] loss= 0.075\n",
      "epoch:[311 / 1000] batch:[120 / 134] loss= 0.105\n",
      "100 cycles trn_loss: 0.078, val_loss: 0.122, lr=3.422702e-06\n",
      "training set RMSE 1 cycle: 44.421, 10 cycle: 42.247, 100 cycle: 39.536\n",
      "testing set RMSE 1 cycle: 52.056, 10 cycle: 50.378, 100 cycle: 45.986\n",
      "epoch:[312 / 1000] batch:[30 / 134] loss= 0.189\n",
      "epoch:[312 / 1000] batch:[60 / 134] loss= 0.124\n",
      "epoch:[312 / 1000] batch:[90 / 134] loss= 0.175\n",
      "epoch:[312 / 1000] batch:[120 / 134] loss= 0.070\n",
      "100 cycles trn_loss: 0.079, val_loss: 0.124, lr=1.045366e-05\n",
      "training set RMSE 1 cycle: 44.021, 10 cycle: 42.092, 100 cycle: 39.724\n",
      "testing set RMSE 1 cycle: 52.188, 10 cycle: 50.632, 100 cycle: 46.398\n",
      "epoch:[313 / 1000] batch:[30 / 134] loss= 0.070\n",
      "epoch:[313 / 1000] batch:[60 / 134] loss= 0.141\n",
      "epoch:[313 / 1000] batch:[90 / 134] loss= 0.055\n",
      "epoch:[313 / 1000] batch:[120 / 134] loss= 0.061\n",
      "100 cycles trn_loss: 0.077, val_loss: 0.124, lr=2.140463e-05\n",
      "training set RMSE 1 cycle: 44.727, 10 cycle: 42.310, 100 cycle: 39.010\n",
      "testing set RMSE 1 cycle: 53.095, 10 cycle: 52.018, 100 cycle: 46.341\n",
      "epoch:[314 / 1000] batch:[30 / 134] loss= 0.053\n",
      "epoch:[314 / 1000] batch:[60 / 134] loss= 0.106\n",
      "epoch:[314 / 1000] batch:[90 / 134] loss= 0.098\n",
      "epoch:[314 / 1000] batch:[120 / 134] loss= 0.040\n",
      "100 cycles trn_loss: 0.075, val_loss: 0.116, lr=3.520366e-05\n",
      "training set RMSE 1 cycle: 46.007, 10 cycle: 43.313, 100 cycle: 38.475\n",
      "testing set RMSE 1 cycle: 53.297, 10 cycle: 51.938, 100 cycle: 44.743\n",
      "epoch:[315 / 1000] batch:[30 / 134] loss= 0.071\n",
      "epoch:[315 / 1000] batch:[60 / 134] loss= 0.111\n",
      "epoch:[315 / 1000] batch:[90 / 134] loss= 0.031\n",
      "epoch:[315 / 1000] batch:[120 / 134] loss= 0.063\n",
      "100 cycles trn_loss: 0.077, val_loss: 0.085, lr=5.050000e-05\n",
      "training set RMSE 1 cycle: 46.843, 10 cycle: 43.614, 100 cycle: 38.560\n",
      "testing set RMSE 1 cycle: 47.682, 10 cycle: 44.965, 100 cycle: 38.265\n",
      "epoch:[316 / 1000] batch:[30 / 134] loss= 0.090\n",
      "epoch:[316 / 1000] batch:[60 / 134] loss= 0.084\n",
      "epoch:[316 / 1000] batch:[90 / 134] loss= 0.165\n",
      "epoch:[316 / 1000] batch:[120 / 134] loss= 0.156\n",
      "100 cycles trn_loss: 0.076, val_loss: 0.121, lr=6.579634e-05\n",
      "training set RMSE 1 cycle: 44.920, 10 cycle: 42.501, 100 cycle: 38.906\n",
      "testing set RMSE 1 cycle: 52.741, 10 cycle: 51.901, 100 cycle: 45.807\n",
      "epoch:[317 / 1000] batch:[30 / 134] loss= 0.072\n",
      "epoch:[317 / 1000] batch:[60 / 134] loss= 0.192\n",
      "epoch:[317 / 1000] batch:[90 / 134] loss= 0.056\n",
      "epoch:[317 / 1000] batch:[120 / 134] loss= 0.109\n",
      "100 cycles trn_loss: 0.093, val_loss: 0.104, lr=7.959537e-05\n",
      "training set RMSE 1 cycle: 58.191, 10 cycle: 53.771, 100 cycle: 41.591\n",
      "testing set RMSE 1 cycle: 58.777, 10 cycle: 57.093, 100 cycle: 42.667\n",
      "epoch:[318 / 1000] batch:[30 / 134] loss= 0.078\n",
      "epoch:[318 / 1000] batch:[60 / 134] loss= 0.048\n",
      "epoch:[318 / 1000] batch:[90 / 134] loss= 0.076\n",
      "epoch:[318 / 1000] batch:[120 / 134] loss= 0.095\n",
      "100 cycles trn_loss: 0.101, val_loss: 0.117, lr=9.054634e-05\n",
      "training set RMSE 1 cycle: 49.260, 10 cycle: 48.087, 100 cycle: 43.782\n",
      "testing set RMSE 1 cycle: 49.730, 10 cycle: 45.847, 100 cycle: 44.995\n",
      "epoch:[319 / 1000] batch:[30 / 134] loss= 0.190\n",
      "epoch:[319 / 1000] batch:[60 / 134] loss= 0.041\n",
      "epoch:[319 / 1000] batch:[90 / 134] loss= 0.087\n",
      "epoch:[319 / 1000] batch:[120 / 134] loss= 0.113\n",
      "100 cycles trn_loss: 0.104, val_loss: 0.148, lr=9.757730e-05\n",
      "training set RMSE 1 cycle: 46.993, 10 cycle: 46.159, 100 cycle: 46.543\n",
      "testing set RMSE 1 cycle: 54.482, 10 cycle: 50.238, 100 cycle: 50.830\n",
      "epoch:[320 / 1000] batch:[30 / 134] loss= 0.078\n",
      "epoch:[320 / 1000] batch:[60 / 134] loss= 0.131\n",
      "epoch:[320 / 1000] batch:[90 / 134] loss= 0.130\n",
      "epoch:[320 / 1000] batch:[120 / 134] loss= 0.054\n",
      "100 cycles trn_loss: 0.079, val_loss: 0.089, lr=1.000000e-04\n",
      "training set RMSE 1 cycle: 49.411, 10 cycle: 44.240, 100 cycle: 38.912\n",
      "testing set RMSE 1 cycle: 50.709, 10 cycle: 48.273, 100 cycle: 39.162\n",
      "epoch:[321 / 1000] batch:[30 / 134] loss= 0.126\n",
      "epoch:[321 / 1000] batch:[60 / 134] loss= 0.089\n",
      "epoch:[321 / 1000] batch:[90 / 134] loss= 0.129\n",
      "epoch:[321 / 1000] batch:[120 / 134] loss= 0.040\n",
      "100 cycles trn_loss: 0.107, val_loss: 0.145, lr=9.757730e-05\n",
      "training set RMSE 1 cycle: 45.295, 10 cycle: 46.965, 100 cycle: 46.963\n",
      "testing set RMSE 1 cycle: 50.953, 10 cycle: 47.346, 100 cycle: 50.156\n",
      "epoch:[322 / 1000] batch:[30 / 134] loss= 0.113\n",
      "epoch:[322 / 1000] batch:[60 / 134] loss= 0.122\n",
      "epoch:[322 / 1000] batch:[90 / 134] loss= 0.073\n",
      "epoch:[322 / 1000] batch:[120 / 134] loss= 0.076\n",
      "100 cycles trn_loss: 0.072, val_loss: 0.104, lr=9.054634e-05\n",
      "training set RMSE 1 cycle: 46.900, 10 cycle: 42.708, 100 cycle: 37.246\n",
      "testing set RMSE 1 cycle: 52.685, 10 cycle: 52.718, 100 cycle: 42.327\n",
      "epoch:[323 / 1000] batch:[30 / 134] loss= 0.030\n",
      "epoch:[323 / 1000] batch:[60 / 134] loss= 0.144\n",
      "epoch:[323 / 1000] batch:[90 / 134] loss= 0.118\n",
      "epoch:[323 / 1000] batch:[120 / 134] loss= 0.057\n",
      "100 cycles trn_loss: 0.080, val_loss: 0.133, lr=7.959537e-05\n",
      "training set RMSE 1 cycle: 52.637, 10 cycle: 51.209, 100 cycle: 39.630\n",
      "testing set RMSE 1 cycle: 57.540, 10 cycle: 58.188, 100 cycle: 48.200\n",
      "epoch:[324 / 1000] batch:[30 / 134] loss= 0.077\n",
      "epoch:[324 / 1000] batch:[60 / 134] loss= 0.048\n",
      "epoch:[324 / 1000] batch:[90 / 134] loss= 0.070\n",
      "epoch:[324 / 1000] batch:[120 / 134] loss= 0.107\n",
      "100 cycles trn_loss: 0.070, val_loss: 0.125, lr=6.579634e-05\n",
      "training set RMSE 1 cycle: 49.881, 10 cycle: 45.517, 100 cycle: 35.833\n",
      "testing set RMSE 1 cycle: 57.326, 10 cycle: 58.221, 100 cycle: 46.995\n",
      "epoch:[325 / 1000] batch:[30 / 134] loss= 0.052\n",
      "epoch:[325 / 1000] batch:[60 / 134] loss= 0.053\n",
      "epoch:[325 / 1000] batch:[90 / 134] loss= 0.110\n",
      "epoch:[325 / 1000] batch:[120 / 134] loss= 0.094\n",
      "100 cycles trn_loss: 0.102, val_loss: 0.126, lr=5.050000e-05\n",
      "training set RMSE 1 cycle: 42.139, 10 cycle: 43.933, 100 cycle: 45.368\n",
      "testing set RMSE 1 cycle: 49.669, 10 cycle: 45.573, 100 cycle: 47.064\n",
      "epoch:[326 / 1000] batch:[30 / 134] loss= 0.090\n",
      "epoch:[326 / 1000] batch:[60 / 134] loss= 0.096\n",
      "epoch:[326 / 1000] batch:[90 / 134] loss= 0.104\n",
      "epoch:[326 / 1000] batch:[120 / 134] loss= 0.030\n",
      "100 cycles trn_loss: 0.093, val_loss: 0.111, lr=3.520366e-05\n",
      "training set RMSE 1 cycle: 42.837, 10 cycle: 43.065, 100 cycle: 43.454\n",
      "testing set RMSE 1 cycle: 47.802, 10 cycle: 42.077, 100 cycle: 43.977\n",
      "epoch:[327 / 1000] batch:[30 / 134] loss= 0.072\n",
      "epoch:[327 / 1000] batch:[60 / 134] loss= 0.121\n",
      "epoch:[327 / 1000] batch:[90 / 134] loss= 0.059\n",
      "epoch:[327 / 1000] batch:[120 / 134] loss= 0.093\n",
      "100 cycles trn_loss: 0.066, val_loss: 0.092, lr=2.140463e-05\n",
      "training set RMSE 1 cycle: 42.619, 10 cycle: 37.969, 100 cycle: 35.243\n",
      "testing set RMSE 1 cycle: 49.507, 10 cycle: 49.853, 100 cycle: 39.873\n",
      "epoch:[328 / 1000] batch:[30 / 134] loss= 0.134\n",
      "epoch:[328 / 1000] batch:[60 / 134] loss= 0.081\n",
      "epoch:[328 / 1000] batch:[90 / 134] loss= 0.081\n",
      "epoch:[328 / 1000] batch:[120 / 134] loss= 0.065\n",
      "100 cycles trn_loss: 0.068, val_loss: 0.108, lr=1.045366e-05\n",
      "training set RMSE 1 cycle: 44.472, 10 cycle: 39.571, 100 cycle: 35.788\n",
      "testing set RMSE 1 cycle: 52.563, 10 cycle: 53.817, 100 cycle: 43.341\n",
      "epoch:[329 / 1000] batch:[30 / 134] loss= 0.118\n",
      "epoch:[329 / 1000] batch:[60 / 134] loss= 0.107\n",
      "epoch:[329 / 1000] batch:[90 / 134] loss= 0.027\n",
      "epoch:[329 / 1000] batch:[120 / 134] loss= 0.081\n",
      "100 cycles trn_loss: 0.068, val_loss: 0.104, lr=3.422702e-06\n",
      "training set RMSE 1 cycle: 41.146, 10 cycle: 36.975, 100 cycle: 35.563\n",
      "testing set RMSE 1 cycle: 52.042, 10 cycle: 52.179, 100 cycle: 42.623\n",
      "epoch:[330 / 1000] batch:[30 / 134] loss= 0.079\n",
      "epoch:[330 / 1000] batch:[60 / 134] loss= 0.035\n",
      "epoch:[330 / 1000] batch:[90 / 134] loss= 0.119\n",
      "epoch:[330 / 1000] batch:[120 / 134] loss= 0.064\n",
      "100 cycles trn_loss: 0.066, val_loss: 0.092, lr=1.000000e-06\n",
      "training set RMSE 1 cycle: 40.922, 10 cycle: 36.589, 100 cycle: 34.960\n",
      "testing set RMSE 1 cycle: 49.999, 10 cycle: 49.412, 100 cycle: 39.904\n",
      "epoch:[331 / 1000] batch:[30 / 134] loss= 0.096\n",
      "epoch:[331 / 1000] batch:[60 / 134] loss= 0.105\n",
      "epoch:[331 / 1000] batch:[90 / 134] loss= 0.058\n",
      "epoch:[331 / 1000] batch:[120 / 134] loss= 0.108\n",
      "100 cycles trn_loss: 0.065, val_loss: 0.091, lr=3.422702e-06\n",
      "training set RMSE 1 cycle: 41.324, 10 cycle: 36.709, 100 cycle: 34.665\n",
      "testing set RMSE 1 cycle: 50.093, 10 cycle: 49.697, 100 cycle: 39.743\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:[332 / 1000] batch:[30 / 134] loss= 0.089\n",
      "epoch:[332 / 1000] batch:[60 / 134] loss= 0.040\n",
      "epoch:[332 / 1000] batch:[90 / 134] loss= 0.072\n",
      "epoch:[332 / 1000] batch:[120 / 134] loss= 0.051\n",
      "100 cycles trn_loss: 0.066, val_loss: 0.093, lr=1.045366e-05\n",
      "training set RMSE 1 cycle: 41.030, 10 cycle: 36.648, 100 cycle: 35.023\n",
      "testing set RMSE 1 cycle: 50.239, 10 cycle: 49.708, 100 cycle: 40.155\n",
      "epoch:[333 / 1000] batch:[30 / 134] loss= 0.058\n",
      "epoch:[333 / 1000] batch:[60 / 134] loss= 0.052\n",
      "epoch:[333 / 1000] batch:[90 / 134] loss= 0.043\n",
      "epoch:[333 / 1000] batch:[120 / 134] loss= 0.050\n",
      "100 cycles trn_loss: 0.068, val_loss: 0.106, lr=2.140463e-05\n",
      "training set RMSE 1 cycle: 41.803, 10 cycle: 36.449, 100 cycle: 35.047\n",
      "testing set RMSE 1 cycle: 51.504, 10 cycle: 52.134, 100 cycle: 42.851\n",
      "epoch:[334 / 1000] batch:[30 / 134] loss= 0.053\n",
      "epoch:[334 / 1000] batch:[60 / 134] loss= 0.098\n",
      "epoch:[334 / 1000] batch:[90 / 134] loss= 0.054\n",
      "epoch:[334 / 1000] batch:[120 / 134] loss= 0.078\n",
      "100 cycles trn_loss: 0.077, val_loss: 0.088, lr=3.520366e-05\n",
      "training set RMSE 1 cycle: 40.382, 10 cycle: 37.905, 100 cycle: 38.159\n",
      "testing set RMSE 1 cycle: 47.940, 10 cycle: 45.976, 100 cycle: 39.159\n",
      "epoch:[335 / 1000] batch:[30 / 134] loss= 0.044\n",
      "epoch:[335 / 1000] batch:[60 / 134] loss= 0.090\n",
      "epoch:[335 / 1000] batch:[90 / 134] loss= 0.062\n",
      "epoch:[335 / 1000] batch:[120 / 134] loss= 0.074\n",
      "100 cycles trn_loss: 0.080, val_loss: 0.105, lr=5.050000e-05\n",
      "training set RMSE 1 cycle: 40.109, 10 cycle: 37.230, 100 cycle: 38.229\n",
      "testing set RMSE 1 cycle: 51.197, 10 cycle: 48.558, 100 cycle: 42.699\n",
      "epoch:[336 / 1000] batch:[30 / 134] loss= 0.041\n",
      "epoch:[336 / 1000] batch:[60 / 134] loss= 0.108\n",
      "epoch:[336 / 1000] batch:[90 / 134] loss= 0.040\n",
      "epoch:[336 / 1000] batch:[120 / 134] loss= 0.144\n",
      "100 cycles trn_loss: 0.115, val_loss: 0.139, lr=6.579634e-05\n",
      "training set RMSE 1 cycle: 43.296, 10 cycle: 46.641, 100 cycle: 48.859\n",
      "testing set RMSE 1 cycle: 52.712, 10 cycle: 45.213, 100 cycle: 49.337\n",
      "epoch:[337 / 1000] batch:[30 / 134] loss= 0.093\n",
      "epoch:[337 / 1000] batch:[60 / 134] loss= 0.055\n",
      "epoch:[337 / 1000] batch:[90 / 134] loss= 0.092\n",
      "epoch:[337 / 1000] batch:[120 / 134] loss= 0.108\n",
      "100 cycles trn_loss: 0.124, val_loss: 0.118, lr=7.959537e-05\n",
      "training set RMSE 1 cycle: 57.755, 10 cycle: 57.693, 100 cycle: 48.866\n",
      "testing set RMSE 1 cycle: 52.952, 10 cycle: 46.481, 100 cycle: 45.309\n",
      "epoch:[338 / 1000] batch:[30 / 134] loss= 0.038\n",
      "epoch:[338 / 1000] batch:[60 / 134] loss= 0.174\n",
      "epoch:[338 / 1000] batch:[90 / 134] loss= 0.078\n",
      "epoch:[338 / 1000] batch:[120 / 134] loss= 0.184\n",
      "100 cycles trn_loss: 0.087, val_loss: 0.115, lr=9.054634e-05\n",
      "training set RMSE 1 cycle: 43.998, 10 cycle: 41.808, 100 cycle: 40.221\n",
      "testing set RMSE 1 cycle: 48.240, 10 cycle: 46.873, 100 cycle: 44.689\n",
      "epoch:[339 / 1000] batch:[30 / 134] loss= 0.102\n",
      "epoch:[339 / 1000] batch:[60 / 134] loss= 0.111\n",
      "epoch:[339 / 1000] batch:[90 / 134] loss= 0.157\n",
      "epoch:[339 / 1000] batch:[120 / 134] loss= 0.050\n",
      "100 cycles trn_loss: 0.088, val_loss: 0.135, lr=9.757730e-05\n",
      "training set RMSE 1 cycle: 61.078, 10 cycle: 58.366, 100 cycle: 40.059\n",
      "testing set RMSE 1 cycle: 63.579, 10 cycle: 63.795, 100 cycle: 50.495\n",
      "epoch:[340 / 1000] batch:[30 / 134] loss= 0.278\n",
      "epoch:[340 / 1000] batch:[60 / 134] loss= 0.108\n",
      "epoch:[340 / 1000] batch:[90 / 134] loss= 0.080\n",
      "epoch:[340 / 1000] batch:[120 / 134] loss= 0.113\n",
      "100 cycles trn_loss: 0.085, val_loss: 0.179, lr=1.000000e-04\n",
      "training set RMSE 1 cycle: 42.018, 10 cycle: 40.094, 100 cycle: 39.265\n",
      "testing set RMSE 1 cycle: 60.708, 10 cycle: 61.970, 100 cycle: 56.122\n",
      "epoch:[341 / 1000] batch:[30 / 134] loss= 0.276\n",
      "epoch:[341 / 1000] batch:[60 / 134] loss= 0.070\n",
      "epoch:[341 / 1000] batch:[90 / 134] loss= 0.084\n",
      "epoch:[341 / 1000] batch:[120 / 134] loss= 0.030\n",
      "100 cycles trn_loss: 0.096, val_loss: 0.119, lr=9.757730e-05\n",
      "training set RMSE 1 cycle: 44.382, 10 cycle: 44.165, 100 cycle: 43.958\n",
      "testing set RMSE 1 cycle: 48.664, 10 cycle: 43.185, 100 cycle: 45.551\n",
      "epoch:[342 / 1000] batch:[30 / 134] loss= 0.042\n",
      "epoch:[342 / 1000] batch:[60 / 134] loss= 0.099\n",
      "epoch:[342 / 1000] batch:[90 / 134] loss= 0.162\n",
      "epoch:[342 / 1000] batch:[120 / 134] loss= 0.153\n",
      "100 cycles trn_loss: 0.086, val_loss: 0.156, lr=9.054634e-05\n",
      "training set RMSE 1 cycle: 43.273, 10 cycle: 42.074, 100 cycle: 40.612\n",
      "testing set RMSE 1 cycle: 60.291, 10 cycle: 59.829, 100 cycle: 52.148\n",
      "epoch:[343 / 1000] batch:[30 / 134] loss= 0.037\n",
      "epoch:[343 / 1000] batch:[60 / 134] loss= 0.083\n",
      "epoch:[343 / 1000] batch:[90 / 134] loss= 0.082\n",
      "epoch:[343 / 1000] batch:[120 / 134] loss= 0.092\n",
      "100 cycles trn_loss: 0.091, val_loss: 0.107, lr=7.959537e-05\n",
      "training set RMSE 1 cycle: 45.512, 10 cycle: 43.769, 100 cycle: 43.292\n",
      "testing set RMSE 1 cycle: 48.924, 10 cycle: 41.970, 100 cycle: 43.158\n",
      "epoch:[344 / 1000] batch:[30 / 134] loss= 0.042\n",
      "epoch:[344 / 1000] batch:[60 / 134] loss= 0.074\n",
      "epoch:[344 / 1000] batch:[90 / 134] loss= 0.167\n",
      "epoch:[344 / 1000] batch:[120 / 134] loss= 0.055\n",
      "100 cycles trn_loss: 0.123, val_loss: 0.155, lr=6.579634e-05\n",
      "training set RMSE 1 cycle: 54.336, 10 cycle: 54.192, 100 cycle: 52.530\n",
      "testing set RMSE 1 cycle: 53.386, 10 cycle: 50.426, 100 cycle: 52.763\n",
      "epoch:[345 / 1000] batch:[30 / 134] loss= 0.117\n",
      "epoch:[345 / 1000] batch:[60 / 134] loss= 0.059\n",
      "epoch:[345 / 1000] batch:[90 / 134] loss= 0.121\n",
      "epoch:[345 / 1000] batch:[120 / 134] loss= 0.092\n",
      "100 cycles trn_loss: 0.061, val_loss: 0.083, lr=5.050000e-05\n",
      "training set RMSE 1 cycle: 43.402, 10 cycle: 36.014, 100 cycle: 32.932\n",
      "testing set RMSE 1 cycle: 48.444, 10 cycle: 48.719, 100 cycle: 37.998\n",
      "epoch:[346 / 1000] batch:[30 / 134] loss= 0.064\n",
      "epoch:[346 / 1000] batch:[60 / 134] loss= 0.061\n",
      "epoch:[346 / 1000] batch:[90 / 134] loss= 0.068\n",
      "epoch:[346 / 1000] batch:[120 / 134] loss= 0.148\n",
      "100 cycles trn_loss: 0.060, val_loss: 0.092, lr=3.520366e-05\n",
      "training set RMSE 1 cycle: 55.879, 10 cycle: 46.556, 100 cycle: 32.802\n",
      "testing set RMSE 1 cycle: 53.984, 10 cycle: 55.932, 100 cycle: 40.107\n",
      "epoch:[347 / 1000] batch:[30 / 134] loss= 0.104\n",
      "epoch:[347 / 1000] batch:[60 / 134] loss= 0.120\n",
      "epoch:[347 / 1000] batch:[90 / 134] loss= 0.050\n",
      "epoch:[347 / 1000] batch:[120 / 134] loss= 0.090\n",
      "100 cycles trn_loss: 0.062, val_loss: 0.077, lr=2.140463e-05\n",
      "training set RMSE 1 cycle: 42.131, 10 cycle: 35.727, 100 cycle: 33.347\n",
      "testing set RMSE 1 cycle: 46.340, 10 cycle: 45.976, 100 cycle: 36.484\n",
      "epoch:[348 / 1000] batch:[30 / 134] loss= 0.048\n",
      "epoch:[348 / 1000] batch:[60 / 134] loss= 0.078\n",
      "epoch:[348 / 1000] batch:[90 / 134] loss= 0.151\n",
      "epoch:[348 / 1000] batch:[120 / 134] loss= 0.053\n",
      "100 cycles trn_loss: 0.055, val_loss: 0.085, lr=1.045366e-05\n",
      "training set RMSE 1 cycle: 42.398, 10 cycle: 34.420, 100 cycle: 31.113\n",
      "testing set RMSE 1 cycle: 47.340, 10 cycle: 51.035, 100 cycle: 38.511\n",
      "epoch:[349 / 1000] batch:[30 / 134] loss= 0.031\n",
      "epoch:[349 / 1000] batch:[60 / 134] loss= 0.064\n",
      "epoch:[349 / 1000] batch:[90 / 134] loss= 0.056\n",
      "epoch:[349 / 1000] batch:[120 / 134] loss= 0.040\n",
      "100 cycles trn_loss: 0.058, val_loss: 0.099, lr=3.422702e-06\n",
      "training set RMSE 1 cycle: 39.384, 10 cycle: 33.447, 100 cycle: 32.205\n",
      "testing set RMSE 1 cycle: 49.541, 10 cycle: 51.436, 100 cycle: 41.563\n",
      "epoch:[350 / 1000] batch:[30 / 134] loss= 0.100\n",
      "epoch:[350 / 1000] batch:[60 / 134] loss= 0.107\n",
      "epoch:[350 / 1000] batch:[90 / 134] loss= 0.050\n",
      "epoch:[350 / 1000] batch:[120 / 134] loss= 0.050\n",
      "100 cycles trn_loss: 0.051, val_loss: 0.097, lr=1.000000e-06\n",
      "training set RMSE 1 cycle: 42.463, 10 cycle: 33.863, 100 cycle: 29.785\n",
      "testing set RMSE 1 cycle: 49.478, 10 cycle: 53.276, 100 cycle: 41.066\n",
      "epoch:[351 / 1000] batch:[30 / 134] loss= 0.047\n",
      "epoch:[351 / 1000] batch:[60 / 134] loss= 0.144\n",
      "epoch:[351 / 1000] batch:[90 / 134] loss= 0.108\n",
      "epoch:[351 / 1000] batch:[120 / 134] loss= 0.038\n",
      "100 cycles trn_loss: 0.051, val_loss: 0.100, lr=3.422702e-06\n",
      "training set RMSE 1 cycle: 41.687, 10 cycle: 33.495, 100 cycle: 29.976\n",
      "testing set RMSE 1 cycle: 49.733, 10 cycle: 53.364, 100 cycle: 41.646\n",
      "epoch:[352 / 1000] batch:[30 / 134] loss= 0.042\n",
      "epoch:[352 / 1000] batch:[60 / 134] loss= 0.049\n",
      "epoch:[352 / 1000] batch:[90 / 134] loss= 0.048\n",
      "epoch:[352 / 1000] batch:[120 / 134] loss= 0.039\n",
      "100 cycles trn_loss: 0.050, val_loss: 0.098, lr=1.045366e-05\n",
      "training set RMSE 1 cycle: 42.131, 10 cycle: 33.647, 100 cycle: 29.498\n",
      "testing set RMSE 1 cycle: 49.669, 10 cycle: 53.349, 100 cycle: 41.279\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:[353 / 1000] batch:[30 / 134] loss= 0.097\n",
      "epoch:[353 / 1000] batch:[60 / 134] loss= 0.089\n",
      "epoch:[353 / 1000] batch:[90 / 134] loss= 0.032\n",
      "epoch:[353 / 1000] batch:[120 / 134] loss= 0.053\n",
      "100 cycles trn_loss: 0.052, val_loss: 0.088, lr=2.140463e-05\n",
      "training set RMSE 1 cycle: 40.366, 10 cycle: 33.499, 100 cycle: 30.191\n",
      "testing set RMSE 1 cycle: 48.569, 10 cycle: 51.312, 100 cycle: 39.109\n",
      "epoch:[354 / 1000] batch:[30 / 134] loss= 0.028\n",
      "epoch:[354 / 1000] batch:[60 / 134] loss= 0.057\n",
      "epoch:[354 / 1000] batch:[90 / 134] loss= 0.119\n",
      "epoch:[354 / 1000] batch:[120 / 134] loss= 0.111\n",
      "100 cycles trn_loss: 0.049, val_loss: 0.105, lr=3.520366e-05\n",
      "training set RMSE 1 cycle: 42.480, 10 cycle: 34.948, 100 cycle: 29.320\n",
      "testing set RMSE 1 cycle: 51.729, 10 cycle: 55.375, 100 cycle: 42.684\n",
      "epoch:[355 / 1000] batch:[30 / 134] loss= 0.072\n",
      "epoch:[355 / 1000] batch:[60 / 134] loss= 0.037\n",
      "epoch:[355 / 1000] batch:[90 / 134] loss= 0.094\n",
      "epoch:[355 / 1000] batch:[120 / 134] loss= 0.061\n",
      "100 cycles trn_loss: 0.048, val_loss: 0.096, lr=5.050000e-05\n",
      "training set RMSE 1 cycle: 44.506, 10 cycle: 36.672, 100 cycle: 29.085\n",
      "testing set RMSE 1 cycle: 51.303, 10 cycle: 55.822, 100 cycle: 40.864\n",
      "epoch:[356 / 1000] batch:[30 / 134] loss= 0.117\n",
      "epoch:[356 / 1000] batch:[60 / 134] loss= 0.119\n",
      "epoch:[356 / 1000] batch:[90 / 134] loss= 0.060\n",
      "epoch:[356 / 1000] batch:[120 / 134] loss= 0.080\n",
      "100 cycles trn_loss: 0.052, val_loss: 0.112, lr=6.579634e-05\n",
      "training set RMSE 1 cycle: 41.075, 10 cycle: 34.217, 100 cycle: 30.230\n",
      "testing set RMSE 1 cycle: 51.176, 10 cycle: 55.837, 100 cycle: 44.067\n",
      "epoch:[357 / 1000] batch:[30 / 134] loss= 0.062\n",
      "epoch:[357 / 1000] batch:[60 / 134] loss= 0.062\n",
      "epoch:[357 / 1000] batch:[90 / 134] loss= 0.071\n",
      "epoch:[357 / 1000] batch:[120 / 134] loss= 0.048\n",
      "100 cycles trn_loss: 0.054, val_loss: 0.116, lr=7.959537e-05\n",
      "training set RMSE 1 cycle: 54.963, 10 cycle: 46.314, 100 cycle: 30.504\n",
      "testing set RMSE 1 cycle: 56.793, 10 cycle: 62.768, 100 cycle: 45.240\n",
      "epoch:[358 / 1000] batch:[30 / 134] loss= 0.151\n",
      "epoch:[358 / 1000] batch:[60 / 134] loss= 0.082\n",
      "epoch:[358 / 1000] batch:[90 / 134] loss= 0.063\n",
      "epoch:[358 / 1000] batch:[120 / 134] loss= 0.067\n",
      "100 cycles trn_loss: 0.097, val_loss: 0.129, lr=9.054634e-05\n",
      "training set RMSE 1 cycle: 46.036, 10 cycle: 45.607, 100 cycle: 43.686\n",
      "testing set RMSE 1 cycle: 54.339, 10 cycle: 46.071, 100 cycle: 47.278\n",
      "epoch:[359 / 1000] batch:[30 / 134] loss= 0.114\n",
      "epoch:[359 / 1000] batch:[60 / 134] loss= 0.075\n",
      "epoch:[359 / 1000] batch:[90 / 134] loss= 0.087\n",
      "epoch:[359 / 1000] batch:[120 / 134] loss= 0.143\n",
      "100 cycles trn_loss: 0.106, val_loss: 0.139, lr=9.757730e-05\n",
      "training set RMSE 1 cycle: 48.783, 10 cycle: 47.228, 100 cycle: 47.435\n",
      "testing set RMSE 1 cycle: 54.062, 10 cycle: 44.843, 100 cycle: 49.285\n",
      "epoch:[360 / 1000] batch:[30 / 134] loss= 0.026\n",
      "epoch:[360 / 1000] batch:[60 / 134] loss= 0.033\n",
      "epoch:[360 / 1000] batch:[90 / 134] loss= 0.194\n",
      "epoch:[360 / 1000] batch:[120 / 134] loss= 0.091\n",
      "100 cycles trn_loss: 0.085, val_loss: 0.218, lr=1.000000e-04\n",
      "training set RMSE 1 cycle: 42.970, 10 cycle: 39.793, 100 cycle: 38.889\n",
      "testing set RMSE 1 cycle: 65.042, 10 cycle: 67.826, 100 cycle: 62.717\n",
      "epoch:[361 / 1000] batch:[30 / 134] loss= 0.107\n",
      "epoch:[361 / 1000] batch:[60 / 134] loss= 0.068\n",
      "epoch:[361 / 1000] batch:[90 / 134] loss= 0.119\n",
      "epoch:[361 / 1000] batch:[120 / 134] loss= 0.094\n",
      "100 cycles trn_loss: 0.188, val_loss: 0.296, lr=9.757730e-05\n",
      "training set RMSE 1 cycle: 64.045, 10 cycle: 65.218, 100 cycle: 64.926\n",
      "testing set RMSE 1 cycle: 68.212, 10 cycle: 69.622, 100 cycle: 74.072\n",
      "epoch:[362 / 1000] batch:[30 / 134] loss= 0.217\n",
      "epoch:[362 / 1000] batch:[60 / 134] loss= 0.099\n",
      "epoch:[362 / 1000] batch:[90 / 134] loss= 0.105\n",
      "epoch:[362 / 1000] batch:[120 / 134] loss= 0.078\n",
      "100 cycles trn_loss: 0.084, val_loss: 0.144, lr=9.054634e-05\n",
      "training set RMSE 1 cycle: 40.884, 10 cycle: 40.307, 100 cycle: 39.777\n",
      "testing set RMSE 1 cycle: 54.460, 10 cycle: 51.524, 100 cycle: 50.060\n",
      "epoch:[363 / 1000] batch:[30 / 134] loss= 0.071\n",
      "epoch:[363 / 1000] batch:[60 / 134] loss= 0.052\n",
      "epoch:[363 / 1000] batch:[90 / 134] loss= 0.152\n",
      "epoch:[363 / 1000] batch:[120 / 134] loss= 0.103\n",
      "100 cycles trn_loss: 0.143, val_loss: 0.235, lr=7.959537e-05\n",
      "training set RMSE 1 cycle: 47.375, 10 cycle: 51.299, 100 cycle: 53.386\n",
      "testing set RMSE 1 cycle: 66.611, 10 cycle: 60.499, 100 cycle: 65.024\n",
      "epoch:[364 / 1000] batch:[30 / 134] loss= 0.055\n",
      "epoch:[364 / 1000] batch:[60 / 134] loss= 0.058\n",
      "epoch:[364 / 1000] batch:[90 / 134] loss= 0.046\n",
      "epoch:[364 / 1000] batch:[120 / 134] loss= 0.147\n",
      "100 cycles trn_loss: 0.066, val_loss: 0.143, lr=6.579634e-05\n",
      "training set RMSE 1 cycle: 37.813, 10 cycle: 35.477, 100 cycle: 34.465\n",
      "testing set RMSE 1 cycle: 58.633, 10 cycle: 56.954, 100 cycle: 49.917\n",
      "epoch:[365 / 1000] batch:[30 / 134] loss= 0.089\n",
      "epoch:[365 / 1000] batch:[60 / 134] loss= 0.104\n",
      "epoch:[365 / 1000] batch:[90 / 134] loss= 0.158\n",
      "epoch:[365 / 1000] batch:[120 / 134] loss= 0.063\n",
      "100 cycles trn_loss: 0.071, val_loss: 0.138, lr=5.050000e-05\n",
      "training set RMSE 1 cycle: 48.826, 10 cycle: 44.293, 100 cycle: 37.018\n",
      "testing set RMSE 1 cycle: 54.923, 10 cycle: 57.454, 100 cycle: 48.993\n",
      "epoch:[366 / 1000] batch:[30 / 134] loss= 0.130\n",
      "epoch:[366 / 1000] batch:[60 / 134] loss= 0.089\n",
      "epoch:[366 / 1000] batch:[90 / 134] loss= 0.045\n",
      "epoch:[366 / 1000] batch:[120 / 134] loss= 0.076\n",
      "100 cycles trn_loss: 0.085, val_loss: 0.123, lr=3.520366e-05\n",
      "training set RMSE 1 cycle: 39.007, 10 cycle: 39.487, 100 cycle: 40.408\n",
      "testing set RMSE 1 cycle: 53.810, 10 cycle: 47.277, 100 cycle: 46.295\n",
      "epoch:[367 / 1000] batch:[30 / 134] loss= 0.069\n",
      "epoch:[367 / 1000] batch:[60 / 134] loss= 0.104\n",
      "epoch:[367 / 1000] batch:[90 / 134] loss= 0.061\n",
      "epoch:[367 / 1000] batch:[120 / 134] loss= 0.083\n",
      "100 cycles trn_loss: 0.070, val_loss: 0.107, lr=2.140463e-05\n",
      "training set RMSE 1 cycle: 36.982, 10 cycle: 34.789, 100 cycle: 35.767\n",
      "testing set RMSE 1 cycle: 51.049, 10 cycle: 48.417, 100 cycle: 43.196\n",
      "epoch:[368 / 1000] batch:[30 / 134] loss= 0.043\n",
      "epoch:[368 / 1000] batch:[60 / 134] loss= 0.091\n",
      "epoch:[368 / 1000] batch:[90 / 134] loss= 0.080\n",
      "epoch:[368 / 1000] batch:[120 / 134] loss= 0.130\n",
      "100 cycles trn_loss: 0.047, val_loss: 0.143, lr=1.045366e-05\n",
      "training set RMSE 1 cycle: 49.559, 10 cycle: 41.641, 100 cycle: 28.517\n",
      "testing set RMSE 1 cycle: 56.492, 10 cycle: 62.982, 100 cycle: 50.440\n",
      "epoch:[369 / 1000] batch:[30 / 134] loss= 0.099\n",
      "epoch:[369 / 1000] batch:[60 / 134] loss= 0.060\n",
      "epoch:[369 / 1000] batch:[90 / 134] loss= 0.064\n",
      "epoch:[369 / 1000] batch:[120 / 134] loss= 0.092\n",
      "100 cycles trn_loss: 0.046, val_loss: 0.100, lr=3.422702e-06\n",
      "training set RMSE 1 cycle: 37.627, 10 cycle: 31.365, 100 cycle: 28.307\n",
      "testing set RMSE 1 cycle: 48.473, 10 cycle: 51.777, 100 cycle: 41.702\n",
      "epoch:[370 / 1000] batch:[30 / 134] loss= 0.067\n",
      "epoch:[370 / 1000] batch:[60 / 134] loss= 0.058\n",
      "epoch:[370 / 1000] batch:[90 / 134] loss= 0.066\n",
      "epoch:[370 / 1000] batch:[120 / 134] loss= 0.034\n",
      "100 cycles trn_loss: 0.044, val_loss: 0.100, lr=1.000000e-06\n",
      "training set RMSE 1 cycle: 37.844, 10 cycle: 31.653, 100 cycle: 27.836\n",
      "testing set RMSE 1 cycle: 48.646, 10 cycle: 52.510, 100 cycle: 41.661\n",
      "epoch:[371 / 1000] batch:[30 / 134] loss= 0.025\n",
      "epoch:[371 / 1000] batch:[60 / 134] loss= 0.103\n",
      "epoch:[371 / 1000] batch:[90 / 134] loss= 0.043\n",
      "epoch:[371 / 1000] batch:[120 / 134] loss= 0.070\n",
      "100 cycles trn_loss: 0.040, val_loss: 0.108, lr=3.422702e-06\n",
      "training set RMSE 1 cycle: 39.823, 10 cycle: 32.347, 100 cycle: 26.513\n",
      "testing set RMSE 1 cycle: 49.570, 10 cycle: 55.095, 100 cycle: 43.333\n",
      "epoch:[372 / 1000] batch:[30 / 134] loss= 0.074\n",
      "epoch:[372 / 1000] batch:[60 / 134] loss= 0.091\n",
      "epoch:[372 / 1000] batch:[90 / 134] loss= 0.045\n",
      "epoch:[372 / 1000] batch:[120 / 134] loss= 0.116\n",
      "100 cycles trn_loss: 0.047, val_loss: 0.105, lr=1.045366e-05\n",
      "training set RMSE 1 cycle: 37.073, 10 cycle: 31.584, 100 cycle: 28.580\n",
      "testing set RMSE 1 cycle: 48.814, 10 cycle: 52.679, 100 cycle: 42.692\n",
      "epoch:[373 / 1000] batch:[30 / 134] loss= 0.066\n",
      "epoch:[373 / 1000] batch:[60 / 134] loss= 0.062\n",
      "epoch:[373 / 1000] batch:[90 / 134] loss= 0.033\n",
      "epoch:[373 / 1000] batch:[120 / 134] loss= 0.072\n",
      "100 cycles trn_loss: 0.037, val_loss: 0.120, lr=2.140463e-05\n",
      "training set RMSE 1 cycle: 42.732, 10 cycle: 34.075, 100 cycle: 25.224\n",
      "testing set RMSE 1 cycle: 51.549, 10 cycle: 58.523, 100 cycle: 45.681\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:[374 / 1000] batch:[30 / 134] loss= 0.051\n",
      "epoch:[374 / 1000] batch:[60 / 134] loss= 0.050\n",
      "epoch:[374 / 1000] batch:[90 / 134] loss= 0.027\n",
      "epoch:[374 / 1000] batch:[120 / 134] loss= 0.047\n",
      "100 cycles trn_loss: 0.045, val_loss: 0.101, lr=3.520366e-05\n",
      "training set RMSE 1 cycle: 41.122, 10 cycle: 33.546, 100 cycle: 28.091\n",
      "testing set RMSE 1 cycle: 50.648, 10 cycle: 55.052, 100 cycle: 42.000\n",
      "epoch:[375 / 1000] batch:[30 / 134] loss= 0.045\n",
      "epoch:[375 / 1000] batch:[60 / 134] loss= 0.069\n",
      "epoch:[375 / 1000] batch:[90 / 134] loss= 0.051\n",
      "epoch:[375 / 1000] batch:[120 / 134] loss= 0.091\n",
      "100 cycles trn_loss: 0.059, val_loss: 0.108, lr=5.050000e-05\n",
      "training set RMSE 1 cycle: 34.389, 10 cycle: 33.276, 100 cycle: 32.730\n",
      "testing set RMSE 1 cycle: 48.736, 10 cycle: 48.759, 100 cycle: 43.341\n",
      "epoch:[376 / 1000] batch:[30 / 134] loss= 0.108\n",
      "epoch:[376 / 1000] batch:[60 / 134] loss= 0.070\n",
      "epoch:[376 / 1000] batch:[90 / 134] loss= 0.042\n",
      "epoch:[376 / 1000] batch:[120 / 134] loss= 0.056\n",
      "100 cycles trn_loss: 0.071, val_loss: 0.090, lr=6.579634e-05\n",
      "training set RMSE 1 cycle: 40.607, 10 cycle: 35.435, 100 cycle: 35.793\n",
      "testing set RMSE 1 cycle: 42.130, 10 cycle: 43.840, 100 cycle: 39.571\n",
      "epoch:[377 / 1000] batch:[30 / 134] loss= 0.082\n",
      "epoch:[377 / 1000] batch:[60 / 134] loss= 0.108\n",
      "epoch:[377 / 1000] batch:[90 / 134] loss= 0.063\n",
      "epoch:[377 / 1000] batch:[120 / 134] loss= 0.081\n",
      "100 cycles trn_loss: 0.072, val_loss: 0.119, lr=7.959537e-05\n",
      "training set RMSE 1 cycle: 54.151, 10 cycle: 51.059, 100 cycle: 36.592\n",
      "testing set RMSE 1 cycle: 59.949, 10 cycle: 58.505, 100 cycle: 46.640\n",
      "epoch:[378 / 1000] batch:[30 / 134] loss= 0.038\n",
      "epoch:[378 / 1000] batch:[60 / 134] loss= 0.097\n",
      "epoch:[378 / 1000] batch:[90 / 134] loss= 0.034\n",
      "epoch:[378 / 1000] batch:[120 / 134] loss= 0.060\n",
      "100 cycles trn_loss: 0.208, val_loss: 0.309, lr=9.054634e-05\n",
      "training set RMSE 1 cycle: 64.124, 10 cycle: 66.394, 100 cycle: 67.859\n",
      "testing set RMSE 1 cycle: 71.213, 10 cycle: 70.765, 100 cycle: 75.850\n",
      "epoch:[379 / 1000] batch:[30 / 134] loss= 0.097\n",
      "epoch:[379 / 1000] batch:[60 / 134] loss= 0.051\n",
      "epoch:[379 / 1000] batch:[90 / 134] loss= 0.067\n",
      "epoch:[379 / 1000] batch:[120 / 134] loss= 0.312\n",
      "100 cycles trn_loss: 0.082, val_loss: 0.177, lr=9.757730e-05\n",
      "training set RMSE 1 cycle: 42.218, 10 cycle: 40.861, 100 cycle: 39.213\n",
      "testing set RMSE 1 cycle: 71.722, 10 cycle: 60.783, 100 cycle: 55.888\n",
      "epoch:[380 / 1000] batch:[30 / 134] loss= 0.197\n",
      "epoch:[380 / 1000] batch:[60 / 134] loss= 0.068\n",
      "epoch:[380 / 1000] batch:[90 / 134] loss= 0.087\n",
      "epoch:[380 / 1000] batch:[120 / 134] loss= 0.073\n",
      "100 cycles trn_loss: 0.061, val_loss: 0.133, lr=1.000000e-04\n",
      "training set RMSE 1 cycle: 37.579, 10 cycle: 35.200, 100 cycle: 33.110\n",
      "testing set RMSE 1 cycle: 53.306, 10 cycle: 53.755, 100 cycle: 48.110\n",
      "epoch:[381 / 1000] batch:[30 / 134] loss= 0.235\n",
      "epoch:[381 / 1000] batch:[60 / 134] loss= 0.261\n",
      "epoch:[381 / 1000] batch:[90 / 134] loss= 0.065\n",
      "epoch:[381 / 1000] batch:[120 / 134] loss= 0.128\n",
      "100 cycles trn_loss: 0.069, val_loss: 0.134, lr=9.757730e-05\n",
      "training set RMSE 1 cycle: 50.239, 10 cycle: 45.071, 100 cycle: 35.599\n",
      "testing set RMSE 1 cycle: 60.975, 10 cycle: 59.620, 100 cycle: 48.732\n",
      "epoch:[382 / 1000] batch:[30 / 134] loss= 0.077\n",
      "epoch:[382 / 1000] batch:[60 / 134] loss= 0.030\n",
      "epoch:[382 / 1000] batch:[90 / 134] loss= 0.187\n",
      "epoch:[382 / 1000] batch:[120 / 134] loss= 0.067\n",
      "100 cycles trn_loss: 0.108, val_loss: 0.199, lr=9.054634e-05\n",
      "training set RMSE 1 cycle: 72.271, 10 cycle: 69.392, 100 cycle: 43.492\n",
      "testing set RMSE 1 cycle: 79.559, 10 cycle: 74.502, 100 cycle: 61.123\n",
      "epoch:[383 / 1000] batch:[30 / 134] loss= 0.059\n",
      "epoch:[383 / 1000] batch:[60 / 134] loss= 0.098\n",
      "epoch:[383 / 1000] batch:[90 / 134] loss= 0.086\n",
      "epoch:[383 / 1000] batch:[120 / 134] loss= 0.083\n",
      "100 cycles trn_loss: 0.065, val_loss: 0.120, lr=7.959537e-05\n",
      "training set RMSE 1 cycle: 36.440, 10 cycle: 35.630, 100 cycle: 34.351\n",
      "testing set RMSE 1 cycle: 54.617, 10 cycle: 52.282, 100 cycle: 45.706\n",
      "epoch:[384 / 1000] batch:[30 / 134] loss= 0.077\n",
      "epoch:[384 / 1000] batch:[60 / 134] loss= 0.088\n",
      "epoch:[384 / 1000] batch:[90 / 134] loss= 0.234\n",
      "epoch:[384 / 1000] batch:[120 / 134] loss= 0.155\n",
      "100 cycles trn_loss: 0.125, val_loss: 0.236, lr=6.579634e-05\n",
      "training set RMSE 1 cycle: 57.493, 10 cycle: 60.181, 100 cycle: 50.234\n",
      "testing set RMSE 1 cycle: 63.779, 10 cycle: 63.284, 100 cycle: 64.654\n",
      "epoch:[385 / 1000] batch:[30 / 134] loss= 0.071\n",
      "epoch:[385 / 1000] batch:[60 / 134] loss= 0.210\n",
      "epoch:[385 / 1000] batch:[90 / 134] loss= 0.121\n",
      "epoch:[385 / 1000] batch:[120 / 134] loss= 0.079\n",
      "100 cycles trn_loss: 0.087, val_loss: 0.169, lr=5.050000e-05\n",
      "training set RMSE 1 cycle: 47.306, 10 cycle: 47.044, 100 cycle: 41.903\n",
      "testing set RMSE 1 cycle: 57.500, 10 cycle: 55.527, 100 cycle: 54.102\n",
      "epoch:[386 / 1000] batch:[30 / 134] loss= 0.085\n",
      "epoch:[386 / 1000] batch:[60 / 134] loss= 0.078\n",
      "epoch:[386 / 1000] batch:[90 / 134] loss= 0.072\n",
      "epoch:[386 / 1000] batch:[120 / 134] loss= 0.106\n",
      "100 cycles trn_loss: 0.087, val_loss: 0.124, lr=3.520366e-05\n",
      "training set RMSE 1 cycle: 45.918, 10 cycle: 44.699, 100 cycle: 42.243\n",
      "testing set RMSE 1 cycle: 49.775, 10 cycle: 47.654, 100 cycle: 46.405\n",
      "epoch:[387 / 1000] batch:[30 / 134] loss= 0.046\n",
      "epoch:[387 / 1000] batch:[60 / 134] loss= 0.050\n",
      "epoch:[387 / 1000] batch:[90 / 134] loss= 0.125\n",
      "epoch:[387 / 1000] batch:[120 / 134] loss= 0.111\n",
      "100 cycles trn_loss: 0.082, val_loss: 0.107, lr=2.140463e-05\n",
      "training set RMSE 1 cycle: 48.942, 10 cycle: 46.066, 100 cycle: 40.395\n",
      "testing set RMSE 1 cycle: 48.450, 10 cycle: 46.237, 100 cycle: 42.958\n",
      "epoch:[388 / 1000] batch:[30 / 134] loss= 0.112\n",
      "epoch:[388 / 1000] batch:[60 / 134] loss= 0.102\n",
      "epoch:[388 / 1000] batch:[90 / 134] loss= 0.047\n",
      "epoch:[388 / 1000] batch:[120 / 134] loss= 0.089\n",
      "100 cycles trn_loss: 0.080, val_loss: 0.123, lr=1.045366e-05\n",
      "training set RMSE 1 cycle: 44.958, 10 cycle: 43.450, 100 cycle: 40.643\n",
      "testing set RMSE 1 cycle: 48.671, 10 cycle: 47.222, 100 cycle: 46.181\n",
      "epoch:[389 / 1000] batch:[30 / 134] loss= 0.060\n",
      "epoch:[389 / 1000] batch:[60 / 134] loss= 0.060\n",
      "epoch:[389 / 1000] batch:[90 / 134] loss= 0.044\n",
      "epoch:[389 / 1000] batch:[120 / 134] loss= 0.028\n",
      "100 cycles trn_loss: 0.077, val_loss: 0.124, lr=3.422702e-06\n",
      "training set RMSE 1 cycle: 45.699, 10 cycle: 43.777, 100 cycle: 39.432\n",
      "testing set RMSE 1 cycle: 49.627, 10 cycle: 48.029, 100 cycle: 46.300\n",
      "epoch:[390 / 1000] batch:[30 / 134] loss= 0.099\n",
      "epoch:[390 / 1000] batch:[60 / 134] loss= 0.061\n",
      "epoch:[390 / 1000] batch:[90 / 134] loss= 0.128\n",
      "epoch:[390 / 1000] batch:[120 / 134] loss= 0.085\n",
      "100 cycles trn_loss: 0.077, val_loss: 0.130, lr=1.000000e-06\n",
      "training set RMSE 1 cycle: 45.344, 10 cycle: 43.594, 100 cycle: 39.643\n",
      "testing set RMSE 1 cycle: 50.027, 10 cycle: 48.625, 100 cycle: 47.395\n",
      "epoch:[391 / 1000] batch:[30 / 134] loss= 0.051\n",
      "epoch:[391 / 1000] batch:[60 / 134] loss= 0.055\n",
      "epoch:[391 / 1000] batch:[90 / 134] loss= 0.076\n",
      "epoch:[391 / 1000] batch:[120 / 134] loss= 0.045\n",
      "100 cycles trn_loss: 0.078, val_loss: 0.128, lr=3.422702e-06\n",
      "training set RMSE 1 cycle: 44.860, 10 cycle: 43.179, 100 cycle: 40.012\n",
      "testing set RMSE 1 cycle: 49.526, 10 cycle: 48.222, 100 cycle: 47.160\n",
      "epoch:[392 / 1000] batch:[30 / 134] loss= 0.032\n",
      "epoch:[392 / 1000] batch:[60 / 134] loss= 0.043\n",
      "epoch:[392 / 1000] batch:[90 / 134] loss= 0.132\n",
      "epoch:[392 / 1000] batch:[120 / 134] loss= 0.125\n",
      "100 cycles trn_loss: 0.077, val_loss: 0.129, lr=1.045366e-05\n",
      "training set RMSE 1 cycle: 45.021, 10 cycle: 43.324, 100 cycle: 39.741\n",
      "testing set RMSE 1 cycle: 49.798, 10 cycle: 48.459, 100 cycle: 47.299\n",
      "epoch:[393 / 1000] batch:[30 / 134] loss= 0.092\n",
      "epoch:[393 / 1000] batch:[60 / 134] loss= 0.126\n",
      "epoch:[393 / 1000] batch:[90 / 134] loss= 0.028\n",
      "epoch:[393 / 1000] batch:[120 / 134] loss= 0.123\n",
      "100 cycles trn_loss: 0.079, val_loss: 0.125, lr=2.140463e-05\n",
      "training set RMSE 1 cycle: 44.541, 10 cycle: 42.806, 100 cycle: 40.441\n",
      "testing set RMSE 1 cycle: 48.286, 10 cycle: 47.215, 100 cycle: 46.573\n",
      "epoch:[394 / 1000] batch:[30 / 134] loss= 0.085\n",
      "epoch:[394 / 1000] batch:[60 / 134] loss= 0.112\n",
      "epoch:[394 / 1000] batch:[90 / 134] loss= 0.118\n",
      "epoch:[394 / 1000] batch:[120 / 134] loss= 0.195\n",
      "100 cycles trn_loss: 0.083, val_loss: 0.120, lr=3.520366e-05\n",
      "training set RMSE 1 cycle: 44.446, 10 cycle: 43.280, 100 cycle: 41.364\n",
      "testing set RMSE 1 cycle: 46.715, 10 cycle: 45.633, 100 cycle: 45.618\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:[395 / 1000] batch:[30 / 134] loss= 0.072\n",
      "epoch:[395 / 1000] batch:[60 / 134] loss= 0.105\n",
      "epoch:[395 / 1000] batch:[90 / 134] loss= 0.077\n",
      "epoch:[395 / 1000] batch:[120 / 134] loss= 0.097\n",
      "100 cycles trn_loss: 0.074, val_loss: 0.121, lr=5.050000e-05\n",
      "training set RMSE 1 cycle: 45.338, 10 cycle: 42.834, 100 cycle: 38.605\n",
      "testing set RMSE 1 cycle: 48.233, 10 cycle: 47.005, 100 cycle: 45.766\n",
      "epoch:[396 / 1000] batch:[30 / 134] loss= 0.067\n",
      "epoch:[396 / 1000] batch:[60 / 134] loss= 0.095\n",
      "epoch:[396 / 1000] batch:[90 / 134] loss= 0.071\n",
      "epoch:[396 / 1000] batch:[120 / 134] loss= 0.094\n",
      "100 cycles trn_loss: 0.075, val_loss: 0.126, lr=6.579634e-05\n",
      "training set RMSE 1 cycle: 49.013, 10 cycle: 47.031, 100 cycle: 38.034\n",
      "testing set RMSE 1 cycle: 51.468, 10 cycle: 49.631, 100 cycle: 46.749\n",
      "epoch:[397 / 1000] batch:[30 / 134] loss= 0.032\n",
      "epoch:[397 / 1000] batch:[60 / 134] loss= 0.099\n",
      "epoch:[397 / 1000] batch:[90 / 134] loss= 0.055\n",
      "epoch:[397 / 1000] batch:[120 / 134] loss= 0.122\n",
      "100 cycles trn_loss: 0.079, val_loss: 0.104, lr=7.959537e-05\n",
      "training set RMSE 1 cycle: 52.168, 10 cycle: 48.911, 100 cycle: 38.635\n",
      "testing set RMSE 1 cycle: 49.953, 10 cycle: 48.141, 100 cycle: 42.438\n",
      "epoch:[398 / 1000] batch:[30 / 134] loss= 0.156\n",
      "epoch:[398 / 1000] batch:[60 / 134] loss= 0.150\n",
      "epoch:[398 / 1000] batch:[90 / 134] loss= 0.067\n",
      "epoch:[398 / 1000] batch:[120 / 134] loss= 0.118\n",
      "100 cycles trn_loss: 0.072, val_loss: 0.110, lr=9.054634e-05\n",
      "training set RMSE 1 cycle: 46.924, 10 cycle: 44.295, 100 cycle: 37.609\n",
      "testing set RMSE 1 cycle: 50.038, 10 cycle: 47.969, 100 cycle: 43.555\n",
      "epoch:[399 / 1000] batch:[30 / 134] loss= 0.113\n",
      "epoch:[399 / 1000] batch:[60 / 134] loss= 0.065\n",
      "epoch:[399 / 1000] batch:[90 / 134] loss= 0.126\n",
      "epoch:[399 / 1000] batch:[120 / 134] loss= 0.071\n",
      "100 cycles trn_loss: 0.079, val_loss: 0.112, lr=9.757730e-05\n",
      "training set RMSE 1 cycle: 42.905, 10 cycle: 42.470, 100 cycle: 39.858\n",
      "testing set RMSE 1 cycle: 47.218, 10 cycle: 44.339, 100 cycle: 44.065\n",
      "epoch:[400 / 1000] batch:[30 / 134] loss= 0.116\n",
      "epoch:[400 / 1000] batch:[60 / 134] loss= 0.152\n",
      "epoch:[400 / 1000] batch:[90 / 134] loss= 0.084\n",
      "epoch:[400 / 1000] batch:[120 / 134] loss= 0.071\n",
      "100 cycles trn_loss: 0.071, val_loss: 0.140, lr=1.000000e-04\n",
      "training set RMSE 1 cycle: 43.826, 10 cycle: 41.671, 100 cycle: 36.931\n",
      "testing set RMSE 1 cycle: 53.542, 10 cycle: 51.713, 100 cycle: 49.410\n",
      "epoch:[401 / 1000] batch:[30 / 134] loss= 0.064\n",
      "epoch:[401 / 1000] batch:[60 / 134] loss= 0.224\n",
      "epoch:[401 / 1000] batch:[90 / 134] loss= 0.070\n",
      "epoch:[401 / 1000] batch:[120 / 134] loss= 0.060\n",
      "100 cycles trn_loss: 0.094, val_loss: 0.135, lr=9.757730e-05\n",
      "training set RMSE 1 cycle: 46.899, 10 cycle: 45.298, 100 cycle: 44.299\n",
      "testing set RMSE 1 cycle: 48.071, 10 cycle: 45.280, 100 cycle: 48.464\n",
      "epoch:[402 / 1000] batch:[30 / 134] loss= 0.038\n",
      "epoch:[402 / 1000] batch:[60 / 134] loss= 0.053\n",
      "epoch:[402 / 1000] batch:[90 / 134] loss= 0.087\n",
      "epoch:[402 / 1000] batch:[120 / 134] loss= 0.155\n",
      "100 cycles trn_loss: 0.090, val_loss: 0.150, lr=9.054634e-05\n",
      "training set RMSE 1 cycle: 44.508, 10 cycle: 43.895, 100 cycle: 43.063\n",
      "testing set RMSE 1 cycle: 55.128, 10 cycle: 53.919, 100 cycle: 51.028\n",
      "epoch:[403 / 1000] batch:[30 / 134] loss= 0.122\n",
      "epoch:[403 / 1000] batch:[60 / 134] loss= 0.094\n",
      "epoch:[403 / 1000] batch:[90 / 134] loss= 0.103\n",
      "epoch:[403 / 1000] batch:[120 / 134] loss= 0.062\n",
      "100 cycles trn_loss: 0.084, val_loss: 0.106, lr=7.959537e-05\n",
      "training set RMSE 1 cycle: 43.852, 10 cycle: 42.682, 100 cycle: 41.718\n",
      "testing set RMSE 1 cycle: 49.402, 10 cycle: 43.407, 100 cycle: 42.903\n",
      "epoch:[404 / 1000] batch:[30 / 134] loss= 0.155\n",
      "epoch:[404 / 1000] batch:[60 / 134] loss= 0.039\n",
      "epoch:[404 / 1000] batch:[90 / 134] loss= 0.096\n",
      "epoch:[404 / 1000] batch:[120 / 134] loss= 0.120\n",
      "100 cycles trn_loss: 0.075, val_loss: 0.155, lr=6.579634e-05\n",
      "training set RMSE 1 cycle: 50.742, 10 cycle: 48.984, 100 cycle: 37.127\n",
      "testing set RMSE 1 cycle: 58.378, 10 cycle: 57.961, 100 cycle: 53.173\n",
      "epoch:[405 / 1000] batch:[30 / 134] loss= 0.029\n",
      "epoch:[405 / 1000] batch:[60 / 134] loss= 0.059\n",
      "epoch:[405 / 1000] batch:[90 / 134] loss= 0.040\n",
      "epoch:[405 / 1000] batch:[120 / 134] loss= 0.111\n",
      "100 cycles trn_loss: 0.089, val_loss: 0.114, lr=5.050000e-05\n",
      "training set RMSE 1 cycle: 53.417, 10 cycle: 50.459, 100 cycle: 40.964\n",
      "testing set RMSE 1 cycle: 55.685, 10 cycle: 55.421, 100 cycle: 44.556\n",
      "epoch:[406 / 1000] batch:[30 / 134] loss= 0.233\n",
      "epoch:[406 / 1000] batch:[60 / 134] loss= 0.111\n",
      "epoch:[406 / 1000] batch:[90 / 134] loss= 0.083\n",
      "epoch:[406 / 1000] batch:[120 / 134] loss= 0.093\n",
      "100 cycles trn_loss: 0.058, val_loss: 0.114, lr=3.520366e-05\n",
      "training set RMSE 1 cycle: 40.858, 10 cycle: 37.434, 100 cycle: 32.858\n",
      "testing set RMSE 1 cycle: 51.444, 10 cycle: 50.051, 100 cycle: 44.363\n",
      "epoch:[407 / 1000] batch:[30 / 134] loss= 0.134\n",
      "epoch:[407 / 1000] batch:[60 / 134] loss= 0.164\n",
      "epoch:[407 / 1000] batch:[90 / 134] loss= 0.062\n",
      "epoch:[407 / 1000] batch:[120 / 134] loss= 0.043\n",
      "100 cycles trn_loss: 0.059, val_loss: 0.104, lr=2.140463e-05\n",
      "training set RMSE 1 cycle: 40.547, 10 cycle: 35.999, 100 cycle: 33.300\n",
      "testing set RMSE 1 cycle: 48.881, 10 cycle: 46.197, 100 cycle: 42.500\n",
      "epoch:[408 / 1000] batch:[30 / 134] loss= 0.037\n",
      "epoch:[408 / 1000] batch:[60 / 134] loss= 0.059\n",
      "epoch:[408 / 1000] batch:[90 / 134] loss= 0.133\n",
      "epoch:[408 / 1000] batch:[120 / 134] loss= 0.089\n",
      "100 cycles trn_loss: 0.057, val_loss: 0.099, lr=1.045366e-05\n",
      "training set RMSE 1 cycle: 38.709, 10 cycle: 35.530, 100 cycle: 32.798\n",
      "testing set RMSE 1 cycle: 48.264, 10 cycle: 45.753, 100 cycle: 41.468\n",
      "epoch:[409 / 1000] batch:[30 / 134] loss= 0.107\n",
      "epoch:[409 / 1000] batch:[60 / 134] loss= 0.063\n",
      "epoch:[409 / 1000] batch:[90 / 134] loss= 0.061\n",
      "epoch:[409 / 1000] batch:[120 / 134] loss= 0.022\n",
      "100 cycles trn_loss: 0.050, val_loss: 0.103, lr=3.422702e-06\n",
      "training set RMSE 1 cycle: 42.482, 10 cycle: 37.666, 100 cycle: 29.935\n",
      "testing set RMSE 1 cycle: 49.058, 10 cycle: 48.524, 100 cycle: 42.271\n",
      "epoch:[410 / 1000] batch:[30 / 134] loss= 0.031\n",
      "epoch:[410 / 1000] batch:[60 / 134] loss= 0.042\n",
      "epoch:[410 / 1000] batch:[90 / 134] loss= 0.051\n",
      "epoch:[410 / 1000] batch:[120 / 134] loss= 0.030\n",
      "100 cycles trn_loss: 0.050, val_loss: 0.102, lr=1.000000e-06\n",
      "training set RMSE 1 cycle: 41.003, 10 cycle: 36.339, 100 cycle: 30.300\n",
      "testing set RMSE 1 cycle: 49.024, 10 cycle: 48.326, 100 cycle: 41.999\n",
      "epoch:[411 / 1000] batch:[30 / 134] loss= 0.043\n",
      "epoch:[411 / 1000] batch:[60 / 134] loss= 0.054\n",
      "epoch:[411 / 1000] batch:[90 / 134] loss= 0.120\n",
      "epoch:[411 / 1000] batch:[120 / 134] loss= 0.132\n",
      "100 cycles trn_loss: 0.052, val_loss: 0.101, lr=3.422702e-06\n",
      "training set RMSE 1 cycle: 39.703, 10 cycle: 35.418, 100 cycle: 30.839\n",
      "testing set RMSE 1 cycle: 48.641, 10 cycle: 47.562, 100 cycle: 41.870\n",
      "epoch:[412 / 1000] batch:[30 / 134] loss= 0.052\n",
      "epoch:[412 / 1000] batch:[60 / 134] loss= 0.090\n",
      "epoch:[412 / 1000] batch:[90 / 134] loss= 0.045\n",
      "epoch:[412 / 1000] batch:[120 / 134] loss= 0.025\n",
      "100 cycles trn_loss: 0.052, val_loss: 0.099, lr=1.045366e-05\n",
      "training set RMSE 1 cycle: 39.287, 10 cycle: 35.134, 100 cycle: 31.104\n",
      "testing set RMSE 1 cycle: 48.227, 10 cycle: 47.092, 100 cycle: 41.509\n",
      "epoch:[413 / 1000] batch:[30 / 134] loss= 0.036\n",
      "epoch:[413 / 1000] batch:[60 / 134] loss= 0.051\n",
      "epoch:[413 / 1000] batch:[90 / 134] loss= 0.061\n",
      "epoch:[413 / 1000] batch:[120 / 134] loss= 0.021\n",
      "100 cycles trn_loss: 0.055, val_loss: 0.115, lr=2.140463e-05\n",
      "training set RMSE 1 cycle: 38.772, 10 cycle: 35.233, 100 cycle: 31.799\n",
      "testing set RMSE 1 cycle: 50.243, 10 cycle: 49.630, 100 cycle: 44.697\n",
      "epoch:[414 / 1000] batch:[30 / 134] loss= 0.014\n",
      "epoch:[414 / 1000] batch:[60 / 134] loss= 0.116\n",
      "epoch:[414 / 1000] batch:[90 / 134] loss= 0.021\n",
      "epoch:[414 / 1000] batch:[120 / 134] loss= 0.122\n",
      "100 cycles trn_loss: 0.058, val_loss: 0.103, lr=3.520366e-05\n",
      "training set RMSE 1 cycle: 37.270, 10 cycle: 34.868, 100 cycle: 32.976\n",
      "testing set RMSE 1 cycle: 48.188, 10 cycle: 46.148, 100 cycle: 42.246\n",
      "epoch:[415 / 1000] batch:[30 / 134] loss= 0.021\n",
      "epoch:[415 / 1000] batch:[60 / 134] loss= 0.031\n",
      "epoch:[415 / 1000] batch:[90 / 134] loss= 0.077\n",
      "epoch:[415 / 1000] batch:[120 / 134] loss= 0.069\n",
      "100 cycles trn_loss: 0.051, val_loss: 0.094, lr=5.050000e-05\n",
      "training set RMSE 1 cycle: 43.172, 10 cycle: 36.795, 100 cycle: 30.264\n",
      "testing set RMSE 1 cycle: 50.101, 10 cycle: 48.897, 100 cycle: 40.318\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:[416 / 1000] batch:[30 / 134] loss= 0.068\n",
      "epoch:[416 / 1000] batch:[60 / 134] loss= 0.069\n",
      "epoch:[416 / 1000] batch:[90 / 134] loss= 0.050\n",
      "epoch:[416 / 1000] batch:[120 / 134] loss= 0.019\n",
      "100 cycles trn_loss: 0.066, val_loss: 0.179, lr=6.579634e-05\n",
      "training set RMSE 1 cycle: 38.876, 10 cycle: 38.097, 100 cycle: 34.615\n",
      "testing set RMSE 1 cycle: 59.788, 10 cycle: 59.466, 100 cycle: 56.251\n",
      "epoch:[417 / 1000] batch:[30 / 134] loss= 0.063\n",
      "epoch:[417 / 1000] batch:[60 / 134] loss= 0.066\n",
      "epoch:[417 / 1000] batch:[90 / 134] loss= 0.108\n",
      "epoch:[417 / 1000] batch:[120 / 134] loss= 0.087\n",
      "100 cycles trn_loss: 0.057, val_loss: 0.111, lr=7.959537e-05\n",
      "training set RMSE 1 cycle: 52.623, 10 cycle: 45.740, 100 cycle: 31.439\n",
      "testing set RMSE 1 cycle: 53.053, 10 cycle: 53.611, 100 cycle: 44.598\n",
      "epoch:[418 / 1000] batch:[30 / 134] loss= 0.068\n",
      "epoch:[418 / 1000] batch:[60 / 134] loss= 0.128\n",
      "epoch:[418 / 1000] batch:[90 / 134] loss= 0.116\n",
      "epoch:[418 / 1000] batch:[120 / 134] loss= 0.064\n",
      "100 cycles trn_loss: 0.093, val_loss: 0.104, lr=9.054634e-05\n",
      "training set RMSE 1 cycle: 49.310, 10 cycle: 43.197, 100 cycle: 41.723\n",
      "testing set RMSE 1 cycle: 49.850, 10 cycle: 43.745, 100 cycle: 42.422\n",
      "epoch:[419 / 1000] batch:[30 / 134] loss= 0.066\n",
      "epoch:[419 / 1000] batch:[60 / 134] loss= 0.116\n",
      "epoch:[419 / 1000] batch:[90 / 134] loss= 0.100\n",
      "epoch:[419 / 1000] batch:[120 / 134] loss= 0.089\n",
      "100 cycles trn_loss: 0.073, val_loss: 0.123, lr=9.757730e-05\n",
      "training set RMSE 1 cycle: 53.174, 10 cycle: 48.395, 100 cycle: 37.228\n",
      "testing set RMSE 1 cycle: 56.223, 10 cycle: 53.767, 100 cycle: 47.998\n",
      "epoch:[420 / 1000] batch:[30 / 134] loss= 0.115\n",
      "epoch:[420 / 1000] batch:[60 / 134] loss= 0.074\n",
      "epoch:[420 / 1000] batch:[90 / 134] loss= 0.089\n",
      "epoch:[420 / 1000] batch:[120 / 134] loss= 0.059\n",
      "100 cycles trn_loss: 0.055, val_loss: 0.100, lr=1.000000e-04\n",
      "training set RMSE 1 cycle: 42.771, 10 cycle: 38.093, 100 cycle: 31.809\n",
      "testing set RMSE 1 cycle: 52.828, 10 cycle: 50.818, 100 cycle: 41.580\n",
      "epoch:[421 / 1000] batch:[30 / 134] loss= 0.074\n",
      "epoch:[421 / 1000] batch:[60 / 134] loss= 0.069\n",
      "epoch:[421 / 1000] batch:[90 / 134] loss= 0.057\n",
      "epoch:[421 / 1000] batch:[120 / 134] loss= 0.069\n",
      "100 cycles trn_loss: 0.084, val_loss: 0.137, lr=9.757730e-05\n",
      "training set RMSE 1 cycle: 40.247, 10 cycle: 40.841, 100 cycle: 40.927\n",
      "testing set RMSE 1 cycle: 57.104, 10 cycle: 48.329, 100 cycle: 48.792\n",
      "epoch:[422 / 1000] batch:[30 / 134] loss= 0.092\n",
      "epoch:[422 / 1000] batch:[60 / 134] loss= 0.040\n",
      "epoch:[422 / 1000] batch:[90 / 134] loss= 0.148\n",
      "epoch:[422 / 1000] batch:[120 / 134] loss= 0.037\n",
      "100 cycles trn_loss: 0.065, val_loss: 0.125, lr=9.054634e-05\n",
      "training set RMSE 1 cycle: 38.594, 10 cycle: 36.580, 100 cycle: 34.960\n",
      "testing set RMSE 1 cycle: 51.036, 10 cycle: 50.340, 100 cycle: 46.619\n",
      "epoch:[423 / 1000] batch:[30 / 134] loss= 0.094\n",
      "epoch:[423 / 1000] batch:[60 / 134] loss= 0.052\n",
      "epoch:[423 / 1000] batch:[90 / 134] loss= 0.052\n",
      "epoch:[423 / 1000] batch:[120 / 134] loss= 0.119\n",
      "100 cycles trn_loss: 0.065, val_loss: 0.089, lr=7.959537e-05\n",
      "training set RMSE 1 cycle: 49.230, 10 cycle: 43.121, 100 cycle: 33.964\n",
      "testing set RMSE 1 cycle: 47.713, 10 cycle: 47.878, 100 cycle: 39.190\n",
      "epoch:[424 / 1000] batch:[30 / 134] loss= 0.143\n",
      "epoch:[424 / 1000] batch:[60 / 134] loss= 0.095\n",
      "epoch:[424 / 1000] batch:[90 / 134] loss= 0.029\n",
      "epoch:[424 / 1000] batch:[120 / 134] loss= 0.078\n",
      "100 cycles trn_loss: 0.072, val_loss: 0.101, lr=6.579634e-05\n",
      "training set RMSE 1 cycle: 60.628, 10 cycle: 54.214, 100 cycle: 35.370\n",
      "testing set RMSE 1 cycle: 57.476, 10 cycle: 58.454, 100 cycle: 42.948\n",
      "epoch:[425 / 1000] batch:[30 / 134] loss= 0.088\n",
      "epoch:[425 / 1000] batch:[60 / 134] loss= 0.048\n",
      "epoch:[425 / 1000] batch:[90 / 134] loss= 0.058\n",
      "epoch:[425 / 1000] batch:[120 / 134] loss= 0.028\n",
      "100 cycles trn_loss: 0.038, val_loss: 0.100, lr=5.050000e-05\n",
      "training set RMSE 1 cycle: 41.957, 10 cycle: 36.660, 100 cycle: 25.627\n",
      "testing set RMSE 1 cycle: 48.903, 10 cycle: 50.398, 100 cycle: 41.779\n",
      "epoch:[426 / 1000] batch:[30 / 134] loss= 0.056\n",
      "epoch:[426 / 1000] batch:[60 / 134] loss= 0.100\n",
      "epoch:[426 / 1000] batch:[90 / 134] loss= 0.046\n",
      "epoch:[426 / 1000] batch:[120 / 134] loss= 0.115\n",
      "100 cycles trn_loss: 0.038, val_loss: 0.107, lr=3.520366e-05\n",
      "training set RMSE 1 cycle: 40.087, 10 cycle: 34.158, 100 cycle: 25.959\n",
      "testing set RMSE 1 cycle: 49.241, 10 cycle: 52.012, 100 cycle: 43.482\n",
      "epoch:[427 / 1000] batch:[30 / 134] loss= 0.084\n",
      "epoch:[427 / 1000] batch:[60 / 134] loss= 0.067\n",
      "epoch:[427 / 1000] batch:[90 / 134] loss= 0.064\n",
      "epoch:[427 / 1000] batch:[120 / 134] loss= 0.053\n",
      "100 cycles trn_loss: 0.037, val_loss: 0.115, lr=2.140463e-05\n",
      "training set RMSE 1 cycle: 36.599, 10 cycle: 30.549, 100 cycle: 25.577\n",
      "testing set RMSE 1 cycle: 48.547, 10 cycle: 51.685, 100 cycle: 44.649\n",
      "epoch:[428 / 1000] batch:[30 / 134] loss= 0.042\n",
      "epoch:[428 / 1000] batch:[60 / 134] loss= 0.074\n",
      "epoch:[428 / 1000] batch:[90 / 134] loss= 0.051\n",
      "epoch:[428 / 1000] batch:[120 / 134] loss= 0.026\n",
      "100 cycles trn_loss: 0.040, val_loss: 0.113, lr=1.045366e-05\n",
      "training set RMSE 1 cycle: 34.461, 10 cycle: 29.625, 100 cycle: 26.613\n",
      "testing set RMSE 1 cycle: 48.074, 10 cycle: 50.091, 100 cycle: 44.236\n",
      "epoch:[429 / 1000] batch:[30 / 134] loss= 0.040\n",
      "epoch:[429 / 1000] batch:[60 / 134] loss= 0.073\n",
      "epoch:[429 / 1000] batch:[90 / 134] loss= 0.048\n",
      "epoch:[429 / 1000] batch:[120 / 134] loss= 0.120\n",
      "100 cycles trn_loss: 0.039, val_loss: 0.146, lr=3.422702e-06\n",
      "training set RMSE 1 cycle: 38.764, 10 cycle: 34.320, 100 cycle: 26.214\n",
      "testing set RMSE 1 cycle: 52.720, 10 cycle: 58.217, 100 cycle: 51.497\n",
      "epoch:[430 / 1000] batch:[30 / 134] loss= 0.068\n",
      "epoch:[430 / 1000] batch:[60 / 134] loss= 0.031\n",
      "epoch:[430 / 1000] batch:[90 / 134] loss= 0.040\n",
      "epoch:[430 / 1000] batch:[120 / 134] loss= 0.042\n",
      "100 cycles trn_loss: 0.033, val_loss: 0.123, lr=1.000000e-06\n",
      "training set RMSE 1 cycle: 36.061, 10 cycle: 30.529, 100 cycle: 23.943\n",
      "testing set RMSE 1 cycle: 50.934, 10 cycle: 53.987, 100 cycle: 46.400\n",
      "epoch:[431 / 1000] batch:[30 / 134] loss= 0.051\n",
      "epoch:[431 / 1000] batch:[60 / 134] loss= 0.053\n",
      "epoch:[431 / 1000] batch:[90 / 134] loss= 0.018\n",
      "epoch:[431 / 1000] batch:[120 / 134] loss= 0.035\n",
      "100 cycles trn_loss: 0.035, val_loss: 0.121, lr=3.422702e-06\n",
      "training set RMSE 1 cycle: 34.754, 10 cycle: 29.476, 100 cycle: 24.614\n",
      "testing set RMSE 1 cycle: 50.307, 10 cycle: 52.307, 100 cycle: 45.786\n",
      "epoch:[432 / 1000] batch:[30 / 134] loss= 0.054\n",
      "epoch:[432 / 1000] batch:[60 / 134] loss= 0.090\n",
      "epoch:[432 / 1000] batch:[90 / 134] loss= 0.040\n",
      "epoch:[432 / 1000] batch:[120 / 134] loss= 0.059\n",
      "100 cycles trn_loss: 0.035, val_loss: 0.119, lr=1.045366e-05\n",
      "training set RMSE 1 cycle: 34.689, 10 cycle: 29.380, 100 cycle: 24.692\n",
      "testing set RMSE 1 cycle: 49.957, 10 cycle: 51.565, 100 cycle: 45.400\n",
      "epoch:[433 / 1000] batch:[30 / 134] loss= 0.114\n",
      "epoch:[433 / 1000] batch:[60 / 134] loss= 0.047\n",
      "epoch:[433 / 1000] batch:[90 / 134] loss= 0.034\n",
      "epoch:[433 / 1000] batch:[120 / 134] loss= 0.057\n",
      "100 cycles trn_loss: 0.032, val_loss: 0.117, lr=2.140463e-05\n",
      "training set RMSE 1 cycle: 38.030, 10 cycle: 31.325, 100 cycle: 23.433\n",
      "testing set RMSE 1 cycle: 49.009, 10 cycle: 51.816, 100 cycle: 44.979\n",
      "epoch:[434 / 1000] batch:[30 / 134] loss= 0.048\n",
      "epoch:[434 / 1000] batch:[60 / 134] loss= 0.046\n",
      "epoch:[434 / 1000] batch:[90 / 134] loss= 0.073\n",
      "epoch:[434 / 1000] batch:[120 / 134] loss= 0.024\n",
      "100 cycles trn_loss: 0.031, val_loss: 0.123, lr=3.520366e-05\n",
      "training set RMSE 1 cycle: 36.801, 10 cycle: 30.756, 100 cycle: 23.136\n",
      "testing set RMSE 1 cycle: 49.556, 10 cycle: 53.489, 100 cycle: 46.043\n",
      "epoch:[435 / 1000] batch:[30 / 134] loss= 0.073\n",
      "epoch:[435 / 1000] batch:[60 / 134] loss= 0.059\n",
      "epoch:[435 / 1000] batch:[90 / 134] loss= 0.033\n",
      "epoch:[435 / 1000] batch:[120 / 134] loss= 0.062\n",
      "100 cycles trn_loss: 0.063, val_loss: 0.110, lr=5.050000e-05\n",
      "training set RMSE 1 cycle: 36.183, 10 cycle: 34.901, 100 cycle: 34.535\n",
      "testing set RMSE 1 cycle: 47.025, 10 cycle: 46.539, 100 cycle: 43.786\n",
      "epoch:[436 / 1000] batch:[30 / 134] loss= 0.081\n",
      "epoch:[436 / 1000] batch:[60 / 134] loss= 0.093\n",
      "epoch:[436 / 1000] batch:[90 / 134] loss= 0.047\n",
      "epoch:[436 / 1000] batch:[120 / 134] loss= 0.053\n",
      "100 cycles trn_loss: 0.050, val_loss: 0.154, lr=6.579634e-05\n",
      "training set RMSE 1 cycle: 36.755, 10 cycle: 32.232, 100 cycle: 29.407\n",
      "testing set RMSE 1 cycle: 52.607, 10 cycle: 54.447, 100 cycle: 51.612\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:[437 / 1000] batch:[30 / 134] loss= 0.088\n",
      "epoch:[437 / 1000] batch:[60 / 134] loss= 0.070\n",
      "epoch:[437 / 1000] batch:[90 / 134] loss= 0.084\n",
      "epoch:[437 / 1000] batch:[120 / 134] loss= 0.090\n",
      "100 cycles trn_loss: 0.091, val_loss: 0.200, lr=7.959537e-05\n",
      "training set RMSE 1 cycle: 63.642, 10 cycle: 59.197, 100 cycle: 40.213\n",
      "testing set RMSE 1 cycle: 66.795, 10 cycle: 69.750, 100 cycle: 59.603\n",
      "epoch:[438 / 1000] batch:[30 / 134] loss= 0.094\n",
      "epoch:[438 / 1000] batch:[60 / 134] loss= 0.054\n",
      "epoch:[438 / 1000] batch:[90 / 134] loss= 0.116\n",
      "epoch:[438 / 1000] batch:[120 / 134] loss= 0.048\n",
      "100 cycles trn_loss: 0.047, val_loss: 0.166, lr=9.054634e-05\n",
      "training set RMSE 1 cycle: 36.038, 10 cycle: 32.637, 100 cycle: 28.654\n",
      "testing set RMSE 1 cycle: 51.609, 10 cycle: 57.123, 100 cycle: 53.852\n",
      "epoch:[439 / 1000] batch:[30 / 134] loss= 0.101\n",
      "epoch:[439 / 1000] batch:[60 / 134] loss= 0.073\n",
      "epoch:[439 / 1000] batch:[90 / 134] loss= 0.118\n",
      "epoch:[439 / 1000] batch:[120 / 134] loss= 0.053\n",
      "100 cycles trn_loss: 0.061, val_loss: 0.170, lr=9.757730e-05\n",
      "training set RMSE 1 cycle: 36.334, 10 cycle: 34.919, 100 cycle: 33.558\n",
      "testing set RMSE 1 cycle: 56.950, 10 cycle: 58.770, 100 cycle: 54.403\n",
      "epoch:[440 / 1000] batch:[30 / 134] loss= 0.053\n",
      "epoch:[440 / 1000] batch:[60 / 134] loss= 0.252\n",
      "epoch:[440 / 1000] batch:[90 / 134] loss= 0.077\n",
      "epoch:[440 / 1000] batch:[120 / 134] loss= 0.061\n",
      "100 cycles trn_loss: 0.059, val_loss: 0.176, lr=1.000000e-04\n",
      "training set RMSE 1 cycle: 39.034, 10 cycle: 34.777, 100 cycle: 32.087\n",
      "testing set RMSE 1 cycle: 57.318, 10 cycle: 57.886, 100 cycle: 55.332\n",
      "epoch:[441 / 1000] batch:[30 / 134] loss= 0.078\n",
      "epoch:[441 / 1000] batch:[60 / 134] loss= 0.052\n",
      "epoch:[441 / 1000] batch:[90 / 134] loss= 0.046\n",
      "epoch:[441 / 1000] batch:[120 / 134] loss= 0.081\n",
      "100 cycles trn_loss: 0.064, val_loss: 0.208, lr=9.757730e-05\n",
      "training set RMSE 1 cycle: 45.290, 10 cycle: 41.582, 100 cycle: 33.471\n",
      "testing set RMSE 1 cycle: 57.020, 10 cycle: 65.863, 100 cycle: 60.533\n",
      "epoch:[442 / 1000] batch:[30 / 134] loss= 0.113\n",
      "epoch:[442 / 1000] batch:[60 / 134] loss= 0.087\n",
      "epoch:[442 / 1000] batch:[90 / 134] loss= 0.061\n",
      "epoch:[442 / 1000] batch:[120 / 134] loss= 0.074\n",
      "100 cycles trn_loss: 0.140, val_loss: 0.147, lr=9.054634e-05\n",
      "training set RMSE 1 cycle: 57.836, 10 cycle: 55.406, 100 cycle: 55.193\n",
      "testing set RMSE 1 cycle: 55.547, 10 cycle: 46.904, 100 cycle: 50.973\n",
      "epoch:[443 / 1000] batch:[30 / 134] loss= 0.137\n",
      "epoch:[443 / 1000] batch:[60 / 134] loss= 0.082\n",
      "epoch:[443 / 1000] batch:[90 / 134] loss= 0.122\n",
      "epoch:[443 / 1000] batch:[120 / 134] loss= 0.051\n",
      "100 cycles trn_loss: 0.038, val_loss: 0.121, lr=7.959537e-05\n",
      "training set RMSE 1 cycle: 40.855, 10 cycle: 34.978, 100 cycle: 25.733\n",
      "testing set RMSE 1 cycle: 50.582, 10 cycle: 53.829, 100 cycle: 45.795\n",
      "epoch:[444 / 1000] batch:[30 / 134] loss= 0.089\n",
      "epoch:[444 / 1000] batch:[60 / 134] loss= 0.104\n",
      "epoch:[444 / 1000] batch:[90 / 134] loss= 0.167\n",
      "epoch:[444 / 1000] batch:[120 / 134] loss= 0.158\n",
      "100 cycles trn_loss: 0.082, val_loss: 0.126, lr=6.579634e-05\n",
      "training set RMSE 1 cycle: 40.939, 10 cycle: 41.831, 100 cycle: 39.706\n",
      "testing set RMSE 1 cycle: 55.936, 10 cycle: 46.067, 100 cycle: 46.774\n",
      "epoch:[445 / 1000] batch:[30 / 134] loss= 0.049\n",
      "epoch:[445 / 1000] batch:[60 / 134] loss= 0.036\n",
      "epoch:[445 / 1000] batch:[90 / 134] loss= 0.067\n",
      "epoch:[445 / 1000] batch:[120 / 134] loss= 0.093\n",
      "100 cycles trn_loss: 0.045, val_loss: 0.166, lr=5.050000e-05\n",
      "training set RMSE 1 cycle: 39.943, 10 cycle: 36.512, 100 cycle: 27.943\n",
      "testing set RMSE 1 cycle: 53.552, 10 cycle: 60.225, 100 cycle: 54.135\n",
      "epoch:[446 / 1000] batch:[30 / 134] loss= 0.068\n",
      "epoch:[446 / 1000] batch:[60 / 134] loss= 0.019\n",
      "epoch:[446 / 1000] batch:[90 / 134] loss= 0.024\n",
      "epoch:[446 / 1000] batch:[120 / 134] loss= 0.055\n",
      "100 cycles trn_loss: 0.028, val_loss: 0.149, lr=3.520366e-05\n",
      "training set RMSE 1 cycle: 42.893, 10 cycle: 35.918, 100 cycle: 22.107\n",
      "testing set RMSE 1 cycle: 52.579, 10 cycle: 59.872, 100 cycle: 51.397\n",
      "epoch:[447 / 1000] batch:[30 / 134] loss= 0.036\n",
      "epoch:[447 / 1000] batch:[60 / 134] loss= 0.047\n",
      "epoch:[447 / 1000] batch:[90 / 134] loss= 0.050\n",
      "epoch:[447 / 1000] batch:[120 / 134] loss= 0.067\n",
      "100 cycles trn_loss: 0.032, val_loss: 0.172, lr=2.140463e-05\n",
      "training set RMSE 1 cycle: 37.473, 10 cycle: 32.864, 100 cycle: 23.404\n",
      "testing set RMSE 1 cycle: 54.866, 10 cycle: 61.868, 100 cycle: 55.518\n",
      "epoch:[448 / 1000] batch:[30 / 134] loss= 0.090\n",
      "epoch:[448 / 1000] batch:[60 / 134] loss= 0.033\n",
      "epoch:[448 / 1000] batch:[90 / 134] loss= 0.089\n",
      "epoch:[448 / 1000] batch:[120 / 134] loss= 0.043\n",
      "100 cycles trn_loss: 0.036, val_loss: 0.160, lr=1.045366e-05\n",
      "training set RMSE 1 cycle: 31.068, 10 cycle: 27.855, 100 cycle: 25.136\n",
      "testing set RMSE 1 cycle: 53.802, 10 cycle: 56.502, 100 cycle: 52.759\n",
      "epoch:[449 / 1000] batch:[30 / 134] loss= 0.055\n",
      "epoch:[449 / 1000] batch:[60 / 134] loss= 0.091\n",
      "epoch:[449 / 1000] batch:[90 / 134] loss= 0.042\n",
      "epoch:[449 / 1000] batch:[120 / 134] loss= 0.018\n",
      "100 cycles trn_loss: 0.026, val_loss: 0.150, lr=3.422702e-06\n",
      "training set RMSE 1 cycle: 34.635, 10 cycle: 28.209, 100 cycle: 21.164\n",
      "testing set RMSE 1 cycle: 51.039, 10 cycle: 56.428, 100 cycle: 51.055\n",
      "epoch:[450 / 1000] batch:[30 / 134] loss= 0.063\n",
      "epoch:[450 / 1000] batch:[60 / 134] loss= 0.079\n",
      "epoch:[450 / 1000] batch:[90 / 134] loss= 0.026\n",
      "epoch:[450 / 1000] batch:[120 / 134] loss= 0.054\n",
      "100 cycles trn_loss: 0.027, val_loss: 0.151, lr=1.000000e-06\n",
      "training set RMSE 1 cycle: 32.078, 10 cycle: 27.059, 100 cycle: 21.575\n",
      "testing set RMSE 1 cycle: 50.815, 10 cycle: 56.116, 100 cycle: 51.255\n",
      "epoch:[451 / 1000] batch:[30 / 134] loss= 0.044\n",
      "epoch:[451 / 1000] batch:[60 / 134] loss= 0.027\n",
      "epoch:[451 / 1000] batch:[90 / 134] loss= 0.019\n",
      "epoch:[451 / 1000] batch:[120 / 134] loss= 0.036\n",
      "100 cycles trn_loss: 0.025, val_loss: 0.154, lr=3.422702e-06\n",
      "training set RMSE 1 cycle: 32.610, 10 cycle: 27.428, 100 cycle: 20.829\n",
      "testing set RMSE 1 cycle: 51.019, 10 cycle: 57.142, 100 cycle: 51.747\n",
      "epoch:[452 / 1000] batch:[30 / 134] loss= 0.031\n",
      "epoch:[452 / 1000] batch:[60 / 134] loss= 0.030\n",
      "epoch:[452 / 1000] batch:[90 / 134] loss= 0.054\n",
      "epoch:[452 / 1000] batch:[120 / 134] loss= 0.039\n",
      "100 cycles trn_loss: 0.030, val_loss: 0.150, lr=1.045366e-05\n",
      "training set RMSE 1 cycle: 30.799, 10 cycle: 26.747, 100 cycle: 22.846\n",
      "testing set RMSE 1 cycle: 50.745, 10 cycle: 55.294, 100 cycle: 51.090\n",
      "epoch:[453 / 1000] batch:[30 / 134] loss= 0.038\n",
      "epoch:[453 / 1000] batch:[60 / 134] loss= 0.028\n",
      "epoch:[453 / 1000] batch:[90 / 134] loss= 0.040\n",
      "epoch:[453 / 1000] batch:[120 / 134] loss= 0.020\n",
      "100 cycles trn_loss: 0.026, val_loss: 0.153, lr=2.140463e-05\n",
      "training set RMSE 1 cycle: 31.592, 10 cycle: 27.235, 100 cycle: 21.171\n",
      "testing set RMSE 1 cycle: 51.519, 10 cycle: 56.666, 100 cycle: 51.526\n",
      "epoch:[454 / 1000] batch:[30 / 134] loss= 0.075\n",
      "epoch:[454 / 1000] batch:[60 / 134] loss= 0.059\n",
      "epoch:[454 / 1000] batch:[90 / 134] loss= 0.053\n",
      "epoch:[454 / 1000] batch:[120 / 134] loss= 0.056\n",
      "100 cycles trn_loss: 0.023, val_loss: 0.168, lr=3.520366e-05\n",
      "training set RMSE 1 cycle: 37.195, 10 cycle: 30.545, 100 cycle: 19.952\n",
      "testing set RMSE 1 cycle: 51.227, 10 cycle: 59.361, 100 cycle: 54.315\n",
      "epoch:[455 / 1000] batch:[30 / 134] loss= 0.039\n",
      "epoch:[455 / 1000] batch:[60 / 134] loss= 0.029\n",
      "epoch:[455 / 1000] batch:[90 / 134] loss= 0.045\n",
      "epoch:[455 / 1000] batch:[120 / 134] loss= 0.029\n",
      "100 cycles trn_loss: 0.033, val_loss: 0.147, lr=5.050000e-05\n",
      "training set RMSE 1 cycle: 48.760, 10 cycle: 40.040, 100 cycle: 23.743\n",
      "testing set RMSE 1 cycle: 55.907, 10 cycle: 61.048, 100 cycle: 51.557\n",
      "epoch:[456 / 1000] batch:[30 / 134] loss= 0.077\n",
      "epoch:[456 / 1000] batch:[60 / 134] loss= 0.060\n",
      "epoch:[456 / 1000] batch:[90 / 134] loss= 0.161\n",
      "epoch:[456 / 1000] batch:[120 / 134] loss= 0.037\n",
      "100 cycles trn_loss: 0.056, val_loss: 0.130, lr=6.579634e-05\n",
      "training set RMSE 1 cycle: 33.266, 10 cycle: 33.224, 100 cycle: 32.431\n",
      "testing set RMSE 1 cycle: 52.092, 10 cycle: 50.219, 100 cycle: 47.438\n",
      "epoch:[457 / 1000] batch:[30 / 134] loss= 0.041\n",
      "epoch:[457 / 1000] batch:[60 / 134] loss= 0.055\n",
      "epoch:[457 / 1000] batch:[90 / 134] loss= 0.021\n",
      "epoch:[457 / 1000] batch:[120 / 134] loss= 0.052\n",
      "100 cycles trn_loss: 0.030, val_loss: 0.167, lr=7.959537e-05\n",
      "training set RMSE 1 cycle: 33.175, 10 cycle: 28.720, 100 cycle: 22.875\n",
      "testing set RMSE 1 cycle: 53.021, 10 cycle: 57.306, 100 cycle: 53.802\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:[458 / 1000] batch:[30 / 134] loss= 0.028\n",
      "epoch:[458 / 1000] batch:[60 / 134] loss= 0.050\n",
      "epoch:[458 / 1000] batch:[90 / 134] loss= 0.106\n",
      "epoch:[458 / 1000] batch:[120 / 134] loss= 0.079\n",
      "100 cycles trn_loss: 0.058, val_loss: 0.127, lr=9.054634e-05\n",
      "training set RMSE 1 cycle: 35.043, 10 cycle: 33.346, 100 cycle: 32.898\n",
      "testing set RMSE 1 cycle: 51.193, 10 cycle: 48.469, 100 cycle: 46.884\n",
      "epoch:[459 / 1000] batch:[30 / 134] loss= 0.060\n",
      "epoch:[459 / 1000] batch:[60 / 134] loss= 0.120\n",
      "epoch:[459 / 1000] batch:[90 / 134] loss= 0.038\n",
      "epoch:[459 / 1000] batch:[120 / 134] loss= 0.027\n",
      "100 cycles trn_loss: 0.073, val_loss: 0.125, lr=9.757730e-05\n",
      "training set RMSE 1 cycle: 41.673, 10 cycle: 39.698, 100 cycle: 37.985\n",
      "testing set RMSE 1 cycle: 50.081, 10 cycle: 46.648, 100 cycle: 46.560\n",
      "epoch:[460 / 1000] batch:[30 / 134] loss= 0.130\n",
      "epoch:[460 / 1000] batch:[60 / 134] loss= 0.073\n",
      "epoch:[460 / 1000] batch:[90 / 134] loss= 0.067\n",
      "epoch:[460 / 1000] batch:[120 / 134] loss= 0.094\n",
      "100 cycles trn_loss: 0.044, val_loss: 0.124, lr=1.000000e-04\n",
      "training set RMSE 1 cycle: 47.880, 10 cycle: 38.722, 100 cycle: 27.668\n",
      "testing set RMSE 1 cycle: 50.554, 10 cycle: 53.448, 100 cycle: 46.486\n",
      "epoch:[461 / 1000] batch:[30 / 134] loss= 0.060\n",
      "epoch:[461 / 1000] batch:[60 / 134] loss= 0.072\n",
      "epoch:[461 / 1000] batch:[90 / 134] loss= 0.049\n",
      "epoch:[461 / 1000] batch:[120 / 134] loss= 0.026\n",
      "100 cycles trn_loss: 0.052, val_loss: 0.142, lr=9.757730e-05\n",
      "training set RMSE 1 cycle: 35.556, 10 cycle: 30.635, 100 cycle: 31.023\n",
      "testing set RMSE 1 cycle: 45.304, 10 cycle: 48.675, 100 cycle: 49.741\n",
      "epoch:[462 / 1000] batch:[30 / 134] loss= 0.015\n",
      "epoch:[462 / 1000] batch:[60 / 134] loss= 0.118\n",
      "epoch:[462 / 1000] batch:[90 / 134] loss= 0.041\n",
      "epoch:[462 / 1000] batch:[120 / 134] loss= 0.050\n",
      "100 cycles trn_loss: 0.052, val_loss: 0.135, lr=9.054634e-05\n",
      "training set RMSE 1 cycle: 43.719, 10 cycle: 36.156, 100 cycle: 30.132\n",
      "testing set RMSE 1 cycle: 43.775, 10 cycle: 49.620, 100 cycle: 48.567\n",
      "epoch:[463 / 1000] batch:[30 / 134] loss= 0.055\n",
      "epoch:[463 / 1000] batch:[60 / 134] loss= 0.101\n",
      "epoch:[463 / 1000] batch:[90 / 134] loss= 0.078\n",
      "epoch:[463 / 1000] batch:[120 / 134] loss= 0.097\n",
      "100 cycles trn_loss: 0.104, val_loss: 0.104, lr=7.959537e-05\n",
      "training set RMSE 1 cycle: 50.339, 10 cycle: 49.392, 100 cycle: 46.430\n",
      "testing set RMSE 1 cycle: 49.880, 10 cycle: 40.992, 100 cycle: 42.458\n",
      "epoch:[464 / 1000] batch:[30 / 134] loss= 0.143\n",
      "epoch:[464 / 1000] batch:[60 / 134] loss= 0.085\n",
      "epoch:[464 / 1000] batch:[90 / 134] loss= 0.069\n",
      "epoch:[464 / 1000] batch:[120 / 134] loss= 0.118\n",
      "100 cycles trn_loss: 0.040, val_loss: 0.129, lr=6.579634e-05\n",
      "training set RMSE 1 cycle: 42.253, 10 cycle: 37.931, 100 cycle: 26.283\n",
      "testing set RMSE 1 cycle: 54.941, 10 cycle: 56.738, 100 cycle: 47.410\n",
      "epoch:[465 / 1000] batch:[30 / 134] loss= 0.033\n",
      "epoch:[465 / 1000] batch:[60 / 134] loss= 0.025\n",
      "epoch:[465 / 1000] batch:[90 / 134] loss= 0.094\n",
      "epoch:[465 / 1000] batch:[120 / 134] loss= 0.082\n",
      "100 cycles trn_loss: 0.087, val_loss: 0.144, lr=5.050000e-05\n",
      "training set RMSE 1 cycle: 39.452, 10 cycle: 41.568, 100 cycle: 42.509\n",
      "testing set RMSE 1 cycle: 53.673, 10 cycle: 49.529, 100 cycle: 50.083\n",
      "epoch:[466 / 1000] batch:[30 / 134] loss= 0.082\n",
      "epoch:[466 / 1000] batch:[60 / 134] loss= 0.034\n",
      "epoch:[466 / 1000] batch:[90 / 134] loss= 0.053\n",
      "epoch:[466 / 1000] batch:[120 / 134] loss= 0.047\n",
      "100 cycles trn_loss: 0.069, val_loss: 0.116, lr=3.520366e-05\n",
      "training set RMSE 1 cycle: 37.460, 10 cycle: 38.330, 100 cycle: 37.262\n",
      "testing set RMSE 1 cycle: 50.632, 10 cycle: 46.247, 100 cycle: 44.812\n",
      "epoch:[467 / 1000] batch:[30 / 134] loss= 0.032\n",
      "epoch:[467 / 1000] batch:[60 / 134] loss= 0.028\n",
      "epoch:[467 / 1000] batch:[90 / 134] loss= 0.023\n",
      "epoch:[467 / 1000] batch:[120 / 134] loss= 0.052\n",
      "100 cycles trn_loss: 0.027, val_loss: 0.150, lr=2.140463e-05\n",
      "training set RMSE 1 cycle: 40.696, 10 cycle: 32.706, 100 cycle: 21.449\n",
      "testing set RMSE 1 cycle: 58.223, 10 cycle: 59.748, 100 cycle: 51.609\n",
      "epoch:[468 / 1000] batch:[30 / 134] loss= 0.031\n",
      "epoch:[468 / 1000] batch:[60 / 134] loss= 0.038\n",
      "epoch:[468 / 1000] batch:[90 / 134] loss= 0.020\n",
      "epoch:[468 / 1000] batch:[120 / 134] loss= 0.021\n",
      "100 cycles trn_loss: 0.024, val_loss: 0.167, lr=1.045366e-05\n",
      "training set RMSE 1 cycle: 30.903, 10 cycle: 25.598, 100 cycle: 20.521\n",
      "testing set RMSE 1 cycle: 51.800, 10 cycle: 56.943, 100 cycle: 53.886\n",
      "epoch:[469 / 1000] batch:[30 / 134] loss= 0.041\n",
      "epoch:[469 / 1000] batch:[60 / 134] loss= 0.026\n",
      "epoch:[469 / 1000] batch:[90 / 134] loss= 0.053\n",
      "epoch:[469 / 1000] batch:[120 / 134] loss= 0.030\n",
      "100 cycles trn_loss: 0.020, val_loss: 0.178, lr=3.422702e-06\n",
      "training set RMSE 1 cycle: 33.089, 10 cycle: 26.822, 100 cycle: 18.471\n",
      "testing set RMSE 1 cycle: 53.430, 10 cycle: 59.370, 100 cycle: 55.819\n",
      "epoch:[470 / 1000] batch:[30 / 134] loss= 0.042\n",
      "epoch:[470 / 1000] batch:[60 / 134] loss= 0.066\n",
      "epoch:[470 / 1000] batch:[90 / 134] loss= 0.024\n",
      "epoch:[470 / 1000] batch:[120 / 134] loss= 0.043\n",
      "100 cycles trn_loss: 0.019, val_loss: 0.174, lr=1.000000e-06\n",
      "training set RMSE 1 cycle: 33.225, 10 cycle: 26.829, 100 cycle: 18.105\n",
      "testing set RMSE 1 cycle: 53.389, 10 cycle: 58.986, 100 cycle: 55.151\n",
      "epoch:[471 / 1000] batch:[30 / 134] loss= 0.022\n",
      "epoch:[471 / 1000] batch:[60 / 134] loss= 0.031\n",
      "epoch:[471 / 1000] batch:[90 / 134] loss= 0.018\n",
      "epoch:[471 / 1000] batch:[120 / 134] loss= 0.013\n",
      "100 cycles trn_loss: 0.020, val_loss: 0.171, lr=3.422702e-06\n",
      "training set RMSE 1 cycle: 31.475, 10 cycle: 25.881, 100 cycle: 18.675\n",
      "testing set RMSE 1 cycle: 52.961, 10 cycle: 58.180, 100 cycle: 54.502\n",
      "epoch:[472 / 1000] batch:[30 / 134] loss= 0.031\n",
      "epoch:[472 / 1000] batch:[60 / 134] loss= 0.031\n",
      "epoch:[472 / 1000] batch:[90 / 134] loss= 0.027\n",
      "epoch:[472 / 1000] batch:[120 / 134] loss= 0.020\n",
      "100 cycles trn_loss: 0.022, val_loss: 0.171, lr=1.045366e-05\n",
      "training set RMSE 1 cycle: 30.467, 10 cycle: 25.299, 100 cycle: 19.698\n",
      "testing set RMSE 1 cycle: 52.470, 10 cycle: 57.581, 100 cycle: 54.551\n",
      "epoch:[473 / 1000] batch:[30 / 134] loss= 0.019\n",
      "epoch:[473 / 1000] batch:[60 / 134] loss= 0.018\n",
      "epoch:[473 / 1000] batch:[90 / 134] loss= 0.060\n",
      "epoch:[473 / 1000] batch:[120 / 134] loss= 0.035\n",
      "100 cycles trn_loss: 0.020, val_loss: 0.182, lr=2.140463e-05\n",
      "training set RMSE 1 cycle: 31.846, 10 cycle: 26.865, 100 cycle: 18.712\n",
      "testing set RMSE 1 cycle: 54.734, 10 cycle: 59.979, 100 cycle: 56.595\n",
      "epoch:[474 / 1000] batch:[30 / 134] loss= 0.054\n",
      "epoch:[474 / 1000] batch:[60 / 134] loss= 0.022\n",
      "epoch:[474 / 1000] batch:[90 / 134] loss= 0.018\n",
      "epoch:[474 / 1000] batch:[120 / 134] loss= 0.039\n",
      "100 cycles trn_loss: 0.019, val_loss: 0.167, lr=3.520366e-05\n",
      "training set RMSE 1 cycle: 35.946, 10 cycle: 28.084, 100 cycle: 18.176\n",
      "testing set RMSE 1 cycle: 55.944, 10 cycle: 59.582, 100 cycle: 54.099\n",
      "epoch:[475 / 1000] batch:[30 / 134] loss= 0.055\n",
      "epoch:[475 / 1000] batch:[60 / 134] loss= 0.045\n",
      "epoch:[475 / 1000] batch:[90 / 134] loss= 0.024\n",
      "epoch:[475 / 1000] batch:[120 / 134] loss= 0.027\n",
      "100 cycles trn_loss: 0.017, val_loss: 0.169, lr=5.050000e-05\n",
      "training set RMSE 1 cycle: 31.811, 10 cycle: 26.706, 100 cycle: 17.181\n",
      "testing set RMSE 1 cycle: 54.306, 10 cycle: 58.718, 100 cycle: 54.326\n",
      "epoch:[476 / 1000] batch:[30 / 134] loss= 0.088\n",
      "epoch:[476 / 1000] batch:[60 / 134] loss= 0.052\n",
      "epoch:[476 / 1000] batch:[90 / 134] loss= 0.045\n",
      "epoch:[476 / 1000] batch:[120 / 134] loss= 0.042\n",
      "100 cycles trn_loss: 0.018, val_loss: 0.159, lr=6.579634e-05\n",
      "training set RMSE 1 cycle: 34.238, 10 cycle: 28.909, 100 cycle: 17.756\n",
      "testing set RMSE 1 cycle: 52.763, 10 cycle: 56.919, 100 cycle: 52.537\n",
      "epoch:[477 / 1000] batch:[30 / 134] loss= 0.065\n",
      "epoch:[477 / 1000] batch:[60 / 134] loss= 0.074\n",
      "epoch:[477 / 1000] batch:[90 / 134] loss= 0.055\n",
      "epoch:[477 / 1000] batch:[120 / 134] loss= 0.093\n",
      "100 cycles trn_loss: 0.028, val_loss: 0.145, lr=7.959537e-05\n",
      "training set RMSE 1 cycle: 41.248, 10 cycle: 32.781, 100 cycle: 21.809\n",
      "testing set RMSE 1 cycle: 60.670, 10 cycle: 58.475, 100 cycle: 50.375\n",
      "epoch:[478 / 1000] batch:[30 / 134] loss= 0.072\n",
      "epoch:[478 / 1000] batch:[60 / 134] loss= 0.209\n",
      "epoch:[478 / 1000] batch:[90 / 134] loss= 0.067\n",
      "epoch:[478 / 1000] batch:[120 / 134] loss= 0.039\n",
      "100 cycles trn_loss: 0.031, val_loss: 0.132, lr=9.054634e-05\n",
      "training set RMSE 1 cycle: 28.794, 10 cycle: 25.358, 100 cycle: 23.048\n",
      "testing set RMSE 1 cycle: 47.613, 10 cycle: 48.175, 100 cycle: 47.771\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:[479 / 1000] batch:[30 / 134] loss= 0.111\n",
      "epoch:[479 / 1000] batch:[60 / 134] loss= 0.043\n",
      "epoch:[479 / 1000] batch:[90 / 134] loss= 0.084\n",
      "epoch:[479 / 1000] batch:[120 / 134] loss= 0.026\n",
      "100 cycles trn_loss: 0.082, val_loss: 0.124, lr=9.757730e-05\n",
      "training set RMSE 1 cycle: 39.013, 10 cycle: 41.189, 100 cycle: 40.299\n",
      "testing set RMSE 1 cycle: 49.427, 10 cycle: 43.691, 100 cycle: 46.434\n",
      "epoch:[480 / 1000] batch:[30 / 134] loss= 0.065\n",
      "epoch:[480 / 1000] batch:[60 / 134] loss= 0.104\n",
      "epoch:[480 / 1000] batch:[90 / 134] loss= 0.034\n",
      "epoch:[480 / 1000] batch:[120 / 134] loss= 0.094\n",
      "100 cycles trn_loss: 0.041, val_loss: 0.138, lr=1.000000e-04\n",
      "training set RMSE 1 cycle: 30.254, 10 cycle: 27.230, 100 cycle: 27.149\n",
      "testing set RMSE 1 cycle: 46.106, 10 cycle: 46.260, 100 cycle: 49.055\n",
      "epoch:[481 / 1000] batch:[30 / 134] loss= 0.093\n",
      "epoch:[481 / 1000] batch:[60 / 134] loss= 0.067\n",
      "epoch:[481 / 1000] batch:[90 / 134] loss= 0.065\n",
      "epoch:[481 / 1000] batch:[120 / 134] loss= 0.022\n",
      "100 cycles trn_loss: 0.057, val_loss: 0.141, lr=9.757730e-05\n",
      "training set RMSE 1 cycle: 33.127, 10 cycle: 32.258, 100 cycle: 32.452\n",
      "testing set RMSE 1 cycle: 51.173, 10 cycle: 50.075, 100 cycle: 49.392\n",
      "epoch:[482 / 1000] batch:[30 / 134] loss= 0.115\n",
      "epoch:[482 / 1000] batch:[60 / 134] loss= 0.100\n",
      "epoch:[482 / 1000] batch:[90 / 134] loss= 0.159\n",
      "epoch:[482 / 1000] batch:[120 / 134] loss= 0.119\n",
      "100 cycles trn_loss: 0.067, val_loss: 0.179, lr=9.054634e-05\n",
      "training set RMSE 1 cycle: 57.933, 10 cycle: 54.625, 100 cycle: 33.994\n",
      "testing set RMSE 1 cycle: 66.221, 10 cycle: 69.033, 100 cycle: 56.667\n",
      "epoch:[483 / 1000] batch:[30 / 134] loss= 0.152\n",
      "epoch:[483 / 1000] batch:[60 / 134] loss= 0.069\n",
      "epoch:[483 / 1000] batch:[90 / 134] loss= 0.037\n",
      "epoch:[483 / 1000] batch:[120 / 134] loss= 0.114\n",
      "100 cycles trn_loss: 0.054, val_loss: 0.220, lr=7.959537e-05\n",
      "training set RMSE 1 cycle: 41.281, 10 cycle: 35.983, 100 cycle: 30.720\n",
      "testing set RMSE 1 cycle: 61.364, 10 cycle: 65.632, 100 cycle: 62.283\n",
      "epoch:[484 / 1000] batch:[30 / 134] loss= 0.075\n",
      "epoch:[484 / 1000] batch:[60 / 134] loss= 0.106\n",
      "epoch:[484 / 1000] batch:[90 / 134] loss= 0.034\n",
      "epoch:[484 / 1000] batch:[120 / 134] loss= 0.056\n",
      "100 cycles trn_loss: 0.121, val_loss: 0.168, lr=6.579634e-05\n",
      "training set RMSE 1 cycle: 74.314, 10 cycle: 70.710, 100 cycle: 46.861\n",
      "testing set RMSE 1 cycle: 79.774, 10 cycle: 70.428, 100 cycle: 57.961\n",
      "epoch:[485 / 1000] batch:[30 / 134] loss= 0.045\n",
      "epoch:[485 / 1000] batch:[60 / 134] loss= 0.038\n",
      "epoch:[485 / 1000] batch:[90 / 134] loss= 0.036\n",
      "epoch:[485 / 1000] batch:[120 / 134] loss= 0.074\n",
      "100 cycles trn_loss: 0.049, val_loss: 0.137, lr=5.050000e-05\n",
      "training set RMSE 1 cycle: 33.184, 10 cycle: 30.295, 100 cycle: 29.864\n",
      "testing set RMSE 1 cycle: 45.078, 10 cycle: 45.976, 100 cycle: 48.642\n",
      "epoch:[486 / 1000] batch:[30 / 134] loss= 0.017\n",
      "epoch:[486 / 1000] batch:[60 / 134] loss= 0.074\n",
      "epoch:[486 / 1000] batch:[90 / 134] loss= 0.044\n",
      "epoch:[486 / 1000] batch:[120 / 134] loss= 0.034\n",
      "100 cycles trn_loss: 0.026, val_loss: 0.160, lr=3.520366e-05\n",
      "training set RMSE 1 cycle: 29.074, 10 cycle: 24.922, 100 cycle: 21.604\n",
      "testing set RMSE 1 cycle: 51.211, 10 cycle: 53.355, 100 cycle: 52.715\n",
      "epoch:[487 / 1000] batch:[30 / 134] loss= 0.022\n",
      "epoch:[487 / 1000] batch:[60 / 134] loss= 0.021\n",
      "epoch:[487 / 1000] batch:[90 / 134] loss= 0.052\n",
      "epoch:[487 / 1000] batch:[120 / 134] loss= 0.022\n",
      "100 cycles trn_loss: 0.023, val_loss: 0.158, lr=2.140463e-05\n",
      "training set RMSE 1 cycle: 30.316, 10 cycle: 25.792, 100 cycle: 20.043\n",
      "testing set RMSE 1 cycle: 54.710, 10 cycle: 55.977, 100 cycle: 52.441\n",
      "epoch:[488 / 1000] batch:[30 / 134] loss= 0.020\n",
      "epoch:[488 / 1000] batch:[60 / 134] loss= 0.022\n",
      "epoch:[488 / 1000] batch:[90 / 134] loss= 0.039\n",
      "epoch:[488 / 1000] batch:[120 / 134] loss= 0.014\n",
      "100 cycles trn_loss: 0.017, val_loss: 0.167, lr=1.045366e-05\n",
      "training set RMSE 1 cycle: 37.299, 10 cycle: 30.426, 100 cycle: 17.135\n",
      "testing set RMSE 1 cycle: 55.778, 10 cycle: 57.946, 100 cycle: 54.041\n",
      "epoch:[489 / 1000] batch:[30 / 134] loss= 0.028\n",
      "epoch:[489 / 1000] batch:[60 / 134] loss= 0.035\n",
      "epoch:[489 / 1000] batch:[90 / 134] loss= 0.016\n",
      "epoch:[489 / 1000] batch:[120 / 134] loss= 0.036\n",
      "100 cycles trn_loss: 0.016, val_loss: 0.164, lr=3.422702e-06\n",
      "training set RMSE 1 cycle: 31.010, 10 cycle: 25.338, 100 cycle: 16.625\n",
      "testing set RMSE 1 cycle: 54.258, 10 cycle: 55.498, 100 cycle: 53.321\n",
      "epoch:[490 / 1000] batch:[30 / 134] loss= 0.016\n",
      "epoch:[490 / 1000] batch:[60 / 134] loss= 0.022\n",
      "epoch:[490 / 1000] batch:[90 / 134] loss= 0.023\n",
      "epoch:[490 / 1000] batch:[120 / 134] loss= 0.042\n",
      "100 cycles trn_loss: 0.015, val_loss: 0.167, lr=1.000000e-06\n",
      "training set RMSE 1 cycle: 30.393, 10 cycle: 25.163, 100 cycle: 16.345\n",
      "testing set RMSE 1 cycle: 53.193, 10 cycle: 55.387, 100 cycle: 53.793\n",
      "epoch:[491 / 1000] batch:[30 / 134] loss= 0.063\n",
      "epoch:[491 / 1000] batch:[60 / 134] loss= 0.028\n",
      "epoch:[491 / 1000] batch:[90 / 134] loss= 0.024\n",
      "epoch:[491 / 1000] batch:[120 / 134] loss= 0.034\n",
      "100 cycles trn_loss: 0.016, val_loss: 0.167, lr=3.422702e-06\n",
      "training set RMSE 1 cycle: 29.994, 10 cycle: 24.868, 100 cycle: 16.492\n",
      "testing set RMSE 1 cycle: 53.702, 10 cycle: 55.338, 100 cycle: 53.735\n",
      "epoch:[492 / 1000] batch:[30 / 134] loss= 0.018\n",
      "epoch:[492 / 1000] batch:[60 / 134] loss= 0.049\n",
      "epoch:[492 / 1000] batch:[90 / 134] loss= 0.020\n",
      "epoch:[492 / 1000] batch:[120 / 134] loss= 0.019\n",
      "100 cycles trn_loss: 0.015, val_loss: 0.168, lr=1.045366e-05\n",
      "training set RMSE 1 cycle: 30.105, 10 cycle: 25.076, 100 cycle: 16.283\n",
      "testing set RMSE 1 cycle: 54.015, 10 cycle: 55.561, 100 cycle: 54.029\n",
      "epoch:[493 / 1000] batch:[30 / 134] loss= 0.026\n",
      "epoch:[493 / 1000] batch:[60 / 134] loss= 0.046\n",
      "epoch:[493 / 1000] batch:[90 / 134] loss= 0.023\n",
      "epoch:[493 / 1000] batch:[120 / 134] loss= 0.026\n",
      "100 cycles trn_loss: 0.023, val_loss: 0.158, lr=2.140463e-05\n",
      "training set RMSE 1 cycle: 27.218, 10 cycle: 23.862, 100 cycle: 19.982\n",
      "testing set RMSE 1 cycle: 52.494, 10 cycle: 53.179, 100 cycle: 52.347\n",
      "epoch:[494 / 1000] batch:[30 / 134] loss= 0.013\n",
      "epoch:[494 / 1000] batch:[60 / 134] loss= 0.023\n",
      "epoch:[494 / 1000] batch:[90 / 134] loss= 0.070\n",
      "epoch:[494 / 1000] batch:[120 / 134] loss= 0.050\n",
      "100 cycles trn_loss: 0.019, val_loss: 0.164, lr=3.520366e-05\n",
      "training set RMSE 1 cycle: 28.053, 10 cycle: 23.746, 100 cycle: 18.127\n",
      "testing set RMSE 1 cycle: 51.644, 10 cycle: 54.076, 100 cycle: 53.224\n",
      "epoch:[495 / 1000] batch:[30 / 134] loss= 0.037\n",
      "epoch:[495 / 1000] batch:[60 / 134] loss= 0.054\n",
      "epoch:[495 / 1000] batch:[90 / 134] loss= 0.040\n",
      "epoch:[495 / 1000] batch:[120 / 134] loss= 0.132\n",
      "100 cycles trn_loss: 0.015, val_loss: 0.168, lr=5.050000e-05\n",
      "training set RMSE 1 cycle: 30.905, 10 cycle: 25.249, 100 cycle: 15.863\n",
      "testing set RMSE 1 cycle: 54.407, 10 cycle: 55.001, 100 cycle: 53.994\n",
      "epoch:[496 / 1000] batch:[30 / 134] loss= 0.070\n",
      "epoch:[496 / 1000] batch:[60 / 134] loss= 0.045\n",
      "epoch:[496 / 1000] batch:[90 / 134] loss= 0.024\n",
      "epoch:[496 / 1000] batch:[120 / 134] loss= 0.038\n",
      "100 cycles trn_loss: 0.020, val_loss: 0.148, lr=6.579634e-05\n",
      "training set RMSE 1 cycle: 32.486, 10 cycle: 25.658, 100 cycle: 18.625\n",
      "testing set RMSE 1 cycle: 48.199, 10 cycle: 49.249, 100 cycle: 50.566\n",
      "epoch:[497 / 1000] batch:[30 / 134] loss= 0.044\n",
      "epoch:[497 / 1000] batch:[60 / 134] loss= 0.066\n",
      "epoch:[497 / 1000] batch:[90 / 134] loss= 0.169\n",
      "epoch:[497 / 1000] batch:[120 / 134] loss= 0.029\n",
      "100 cycles trn_loss: 0.020, val_loss: 0.138, lr=7.959537e-05\n",
      "training set RMSE 1 cycle: 33.141, 10 cycle: 27.486, 100 cycle: 18.367\n",
      "testing set RMSE 1 cycle: 51.256, 10 cycle: 53.742, 100 cycle: 48.769\n",
      "epoch:[498 / 1000] batch:[30 / 134] loss= 0.220\n",
      "epoch:[498 / 1000] batch:[60 / 134] loss= 0.275\n",
      "epoch:[498 / 1000] batch:[90 / 134] loss= 0.220\n",
      "epoch:[498 / 1000] batch:[120 / 134] loss= 0.073\n",
      "100 cycles trn_loss: 0.113, val_loss: 0.146, lr=9.054634e-05\n",
      "training set RMSE 1 cycle: 65.198, 10 cycle: 53.300, 100 cycle: 45.530\n",
      "testing set RMSE 1 cycle: 62.863, 10 cycle: 54.660, 100 cycle: 50.622\n",
      "epoch:[499 / 1000] batch:[30 / 134] loss= 0.128\n",
      "epoch:[499 / 1000] batch:[60 / 134] loss= 0.074\n",
      "epoch:[499 / 1000] batch:[90 / 134] loss= 0.090\n",
      "epoch:[499 / 1000] batch:[120 / 134] loss= 0.184\n",
      "100 cycles trn_loss: 0.091, val_loss: 0.134, lr=9.757730e-05\n",
      "training set RMSE 1 cycle: 51.433, 10 cycle: 45.468, 100 cycle: 42.632\n",
      "testing set RMSE 1 cycle: 49.765, 10 cycle: 49.002, 100 cycle: 48.169\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:[500 / 1000] batch:[30 / 134] loss= 0.197\n",
      "epoch:[500 / 1000] batch:[60 / 134] loss= 0.080\n",
      "epoch:[500 / 1000] batch:[90 / 134] loss= 0.103\n",
      "epoch:[500 / 1000] batch:[120 / 134] loss= 0.036\n",
      "100 cycles trn_loss: 0.084, val_loss: 0.148, lr=1.000000e-04\n",
      "training set RMSE 1 cycle: 46.961, 10 cycle: 42.399, 100 cycle: 41.267\n",
      "testing set RMSE 1 cycle: 50.986, 10 cycle: 51.846, 100 cycle: 50.654\n",
      "epoch:[501 / 1000] batch:[30 / 134] loss= 0.053\n",
      "epoch:[501 / 1000] batch:[60 / 134] loss= 0.162\n",
      "epoch:[501 / 1000] batch:[90 / 134] loss= 0.200\n",
      "epoch:[501 / 1000] batch:[120 / 134] loss= 0.058\n",
      "100 cycles trn_loss: 0.100, val_loss: 0.196, lr=9.757730e-05\n",
      "training set RMSE 1 cycle: 46.420, 10 cycle: 42.874, 100 cycle: 43.953\n",
      "testing set RMSE 1 cycle: 55.155, 10 cycle: 57.327, 100 cycle: 58.840\n",
      "epoch:[502 / 1000] batch:[30 / 134] loss= 0.068\n",
      "epoch:[502 / 1000] batch:[60 / 134] loss= 0.061\n",
      "epoch:[502 / 1000] batch:[90 / 134] loss= 0.110\n",
      "epoch:[502 / 1000] batch:[120 / 134] loss= 0.141\n",
      "100 cycles trn_loss: 0.072, val_loss: 0.111, lr=9.054634e-05\n",
      "training set RMSE 1 cycle: 47.306, 10 cycle: 41.205, 100 cycle: 37.487\n",
      "testing set RMSE 1 cycle: 47.649, 10 cycle: 46.070, 100 cycle: 43.732\n",
      "epoch:[503 / 1000] batch:[30 / 134] loss= 0.089\n",
      "epoch:[503 / 1000] batch:[60 / 134] loss= 0.094\n",
      "epoch:[503 / 1000] batch:[90 / 134] loss= 0.163\n",
      "epoch:[503 / 1000] batch:[120 / 134] loss= 0.051\n",
      "100 cycles trn_loss: 0.074, val_loss: 0.119, lr=7.959537e-05\n",
      "training set RMSE 1 cycle: 47.434, 10 cycle: 41.423, 100 cycle: 37.689\n",
      "testing set RMSE 1 cycle: 51.263, 10 cycle: 48.394, 100 cycle: 45.389\n",
      "epoch:[504 / 1000] batch:[30 / 134] loss= 0.115\n",
      "epoch:[504 / 1000] batch:[60 / 134] loss= 0.075\n",
      "epoch:[504 / 1000] batch:[90 / 134] loss= 0.062\n",
      "epoch:[504 / 1000] batch:[120 / 134] loss= 0.061\n",
      "100 cycles trn_loss: 0.078, val_loss: 0.121, lr=6.579634e-05\n",
      "training set RMSE 1 cycle: 52.712, 10 cycle: 47.016, 100 cycle: 36.995\n",
      "testing set RMSE 1 cycle: 55.451, 10 cycle: 55.835, 100 cycle: 47.712\n",
      "epoch:[505 / 1000] batch:[30 / 134] loss= 0.159\n",
      "epoch:[505 / 1000] batch:[60 / 134] loss= 0.064\n",
      "epoch:[505 / 1000] batch:[90 / 134] loss= 0.054\n",
      "epoch:[505 / 1000] batch:[120 / 134] loss= 0.086\n",
      "100 cycles trn_loss: 0.057, val_loss: 0.116, lr=5.050000e-05\n",
      "training set RMSE 1 cycle: 39.893, 10 cycle: 35.919, 100 cycle: 32.639\n",
      "testing set RMSE 1 cycle: 46.429, 10 cycle: 47.206, 100 cycle: 44.714\n",
      "epoch:[506 / 1000] batch:[30 / 134] loss= 0.026\n",
      "epoch:[506 / 1000] batch:[60 / 134] loss= 0.019\n",
      "epoch:[506 / 1000] batch:[90 / 134] loss= 0.058\n",
      "epoch:[506 / 1000] batch:[120 / 134] loss= 0.039\n",
      "100 cycles trn_loss: 0.057, val_loss: 0.123, lr=3.520366e-05\n",
      "training set RMSE 1 cycle: 39.598, 10 cycle: 35.921, 100 cycle: 32.292\n",
      "testing set RMSE 1 cycle: 47.744, 10 cycle: 49.966, 100 cycle: 46.229\n",
      "epoch:[507 / 1000] batch:[30 / 134] loss= 0.141\n",
      "epoch:[507 / 1000] batch:[60 / 134] loss= 0.079\n",
      "epoch:[507 / 1000] batch:[90 / 134] loss= 0.025\n",
      "epoch:[507 / 1000] batch:[120 / 134] loss= 0.051\n",
      "100 cycles trn_loss: 0.061, val_loss: 0.108, lr=2.140463e-05\n",
      "training set RMSE 1 cycle: 37.007, 10 cycle: 35.370, 100 cycle: 34.261\n",
      "testing set RMSE 1 cycle: 45.147, 10 cycle: 43.657, 100 cycle: 43.261\n",
      "epoch:[508 / 1000] batch:[30 / 134] loss= 0.055\n",
      "epoch:[508 / 1000] batch:[60 / 134] loss= 0.088\n",
      "epoch:[508 / 1000] batch:[90 / 134] loss= 0.015\n",
      "epoch:[508 / 1000] batch:[120 / 134] loss= 0.030\n",
      "100 cycles trn_loss: 0.051, val_loss: 0.105, lr=1.045366e-05\n",
      "training set RMSE 1 cycle: 36.602, 10 cycle: 32.802, 100 cycle: 30.352\n",
      "testing set RMSE 1 cycle: 44.256, 10 cycle: 45.064, 100 cycle: 42.589\n",
      "epoch:[509 / 1000] batch:[30 / 134] loss= 0.049\n",
      "epoch:[509 / 1000] batch:[60 / 134] loss= 0.091\n",
      "epoch:[509 / 1000] batch:[90 / 134] loss= 0.092\n",
      "epoch:[509 / 1000] batch:[120 / 134] loss= 0.050\n",
      "100 cycles trn_loss: 0.046, val_loss: 0.095, lr=3.422702e-06\n",
      "training set RMSE 1 cycle: 39.172, 10 cycle: 33.293, 100 cycle: 28.637\n",
      "testing set RMSE 1 cycle: 43.875, 10 cycle: 45.039, 100 cycle: 40.484\n",
      "epoch:[510 / 1000] batch:[30 / 134] loss= 0.036\n",
      "epoch:[510 / 1000] batch:[60 / 134] loss= 0.043\n",
      "epoch:[510 / 1000] batch:[90 / 134] loss= 0.080\n",
      "epoch:[510 / 1000] batch:[120 / 134] loss= 0.099\n",
      "100 cycles trn_loss: 0.046, val_loss: 0.100, lr=1.000000e-06\n",
      "training set RMSE 1 cycle: 38.068, 10 cycle: 32.886, 100 cycle: 28.768\n",
      "testing set RMSE 1 cycle: 43.688, 10 cycle: 45.567, 100 cycle: 41.525\n",
      "epoch:[511 / 1000] batch:[30 / 134] loss= 0.035\n",
      "epoch:[511 / 1000] batch:[60 / 134] loss= 0.093\n",
      "epoch:[511 / 1000] batch:[90 / 134] loss= 0.061\n",
      "epoch:[511 / 1000] batch:[120 / 134] loss= 0.092\n",
      "100 cycles trn_loss: 0.048, val_loss: 0.099, lr=3.422702e-06\n",
      "training set RMSE 1 cycle: 36.960, 10 cycle: 32.527, 100 cycle: 29.334\n",
      "testing set RMSE 1 cycle: 43.237, 10 cycle: 44.975, 100 cycle: 41.471\n",
      "epoch:[512 / 1000] batch:[30 / 134] loss= 0.044\n",
      "epoch:[512 / 1000] batch:[60 / 134] loss= 0.055\n",
      "epoch:[512 / 1000] batch:[90 / 134] loss= 0.047\n",
      "epoch:[512 / 1000] batch:[120 / 134] loss= 0.056\n",
      "100 cycles trn_loss: 0.048, val_loss: 0.104, lr=1.045366e-05\n",
      "training set RMSE 1 cycle: 36.220, 10 cycle: 32.186, 100 cycle: 29.399\n",
      "testing set RMSE 1 cycle: 43.140, 10 cycle: 45.613, 100 cycle: 42.526\n",
      "epoch:[513 / 1000] batch:[30 / 134] loss= 0.072\n",
      "epoch:[513 / 1000] batch:[60 / 134] loss= 0.052\n",
      "epoch:[513 / 1000] batch:[90 / 134] loss= 0.126\n",
      "epoch:[513 / 1000] batch:[120 / 134] loss= 0.023\n",
      "100 cycles trn_loss: 0.057, val_loss: 0.099, lr=2.140463e-05\n",
      "training set RMSE 1 cycle: 37.394, 10 cycle: 34.238, 100 cycle: 32.771\n",
      "testing set RMSE 1 cycle: 43.091, 10 cycle: 42.853, 100 cycle: 41.493\n",
      "epoch:[514 / 1000] batch:[30 / 134] loss= 0.056\n",
      "epoch:[514 / 1000] batch:[60 / 134] loss= 0.062\n",
      "epoch:[514 / 1000] batch:[90 / 134] loss= 0.023\n",
      "epoch:[514 / 1000] batch:[120 / 134] loss= 0.065\n",
      "100 cycles trn_loss: 0.050, val_loss: 0.098, lr=3.520366e-05\n",
      "training set RMSE 1 cycle: 37.258, 10 cycle: 32.627, 100 cycle: 30.213\n",
      "testing set RMSE 1 cycle: 44.099, 10 cycle: 44.273, 100 cycle: 41.282\n",
      "epoch:[515 / 1000] batch:[30 / 134] loss= 0.060\n",
      "epoch:[515 / 1000] batch:[60 / 134] loss= 0.137\n",
      "epoch:[515 / 1000] batch:[90 / 134] loss= 0.060\n",
      "epoch:[515 / 1000] batch:[120 / 134] loss= 0.053\n",
      "100 cycles trn_loss: 0.063, val_loss: 0.089, lr=5.050000e-05\n",
      "training set RMSE 1 cycle: 39.090, 10 cycle: 36.185, 100 cycle: 34.807\n",
      "testing set RMSE 1 cycle: 42.640, 10 cycle: 40.982, 100 cycle: 39.242\n",
      "epoch:[516 / 1000] batch:[30 / 134] loss= 0.037\n",
      "epoch:[516 / 1000] batch:[60 / 134] loss= 0.054\n",
      "epoch:[516 / 1000] batch:[90 / 134] loss= 0.091\n",
      "epoch:[516 / 1000] batch:[120 / 134] loss= 0.074\n",
      "100 cycles trn_loss: 0.071, val_loss: 0.129, lr=6.579634e-05\n",
      "training set RMSE 1 cycle: 35.968, 10 cycle: 35.636, 100 cycle: 36.575\n",
      "testing set RMSE 1 cycle: 46.064, 10 cycle: 46.361, 100 cycle: 47.352\n",
      "epoch:[517 / 1000] batch:[30 / 134] loss= 0.090\n",
      "epoch:[517 / 1000] batch:[60 / 134] loss= 0.075\n",
      "epoch:[517 / 1000] batch:[90 / 134] loss= 0.055\n",
      "epoch:[517 / 1000] batch:[120 / 134] loss= 0.072\n",
      "100 cycles trn_loss: 0.068, val_loss: 0.088, lr=7.959537e-05\n",
      "training set RMSE 1 cycle: 45.971, 10 cycle: 39.233, 100 cycle: 35.764\n",
      "testing set RMSE 1 cycle: 47.589, 10 cycle: 43.537, 100 cycle: 39.178\n",
      "epoch:[518 / 1000] batch:[30 / 134] loss= 0.089\n",
      "epoch:[518 / 1000] batch:[60 / 134] loss= 0.079\n",
      "epoch:[518 / 1000] batch:[90 / 134] loss= 0.242\n",
      "epoch:[518 / 1000] batch:[120 / 134] loss= 0.077\n",
      "100 cycles trn_loss: 0.070, val_loss: 0.119, lr=9.054634e-05\n",
      "training set RMSE 1 cycle: 37.554, 10 cycle: 37.023, 100 cycle: 37.100\n",
      "testing set RMSE 1 cycle: 44.613, 10 cycle: 43.744, 100 cycle: 45.488\n",
      "epoch:[519 / 1000] batch:[30 / 134] loss= 0.037\n",
      "epoch:[519 / 1000] batch:[60 / 134] loss= 0.090\n",
      "epoch:[519 / 1000] batch:[90 / 134] loss= 0.061\n",
      "epoch:[519 / 1000] batch:[120 / 134] loss= 0.058\n",
      "100 cycles trn_loss: 0.055, val_loss: 0.092, lr=9.757730e-05\n",
      "training set RMSE 1 cycle: 36.716, 10 cycle: 34.306, 100 cycle: 32.354\n",
      "testing set RMSE 1 cycle: 45.065, 10 cycle: 42.568, 100 cycle: 40.030\n",
      "epoch:[520 / 1000] batch:[30 / 134] loss= 0.070\n",
      "epoch:[520 / 1000] batch:[60 / 134] loss= 0.075\n",
      "epoch:[520 / 1000] batch:[90 / 134] loss= 0.066\n",
      "epoch:[520 / 1000] batch:[120 / 134] loss= 0.084\n",
      "100 cycles trn_loss: 0.071, val_loss: 0.091, lr=1.000000e-04\n",
      "training set RMSE 1 cycle: 48.807, 10 cycle: 40.823, 100 cycle: 36.580\n",
      "testing set RMSE 1 cycle: 44.680, 10 cycle: 44.500, 100 cycle: 39.622\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:[521 / 1000] batch:[30 / 134] loss= 0.107\n",
      "epoch:[521 / 1000] batch:[60 / 134] loss= 0.145\n",
      "epoch:[521 / 1000] batch:[90 / 134] loss= 0.035\n",
      "epoch:[521 / 1000] batch:[120 / 134] loss= 0.115\n",
      "100 cycles trn_loss: 0.092, val_loss: 0.137, lr=9.757730e-05\n",
      "training set RMSE 1 cycle: 50.373, 10 cycle: 41.973, 100 cycle: 42.650\n",
      "testing set RMSE 1 cycle: 45.667, 10 cycle: 45.309, 100 cycle: 48.726\n",
      "epoch:[522 / 1000] batch:[30 / 134] loss= 0.021\n",
      "epoch:[522 / 1000] batch:[60 / 134] loss= 0.175\n",
      "epoch:[522 / 1000] batch:[90 / 134] loss= 0.063\n",
      "epoch:[522 / 1000] batch:[120 / 134] loss= 0.073\n",
      "100 cycles trn_loss: 0.056, val_loss: 0.101, lr=9.054634e-05\n",
      "training set RMSE 1 cycle: 51.150, 10 cycle: 38.609, 100 cycle: 31.051\n",
      "testing set RMSE 1 cycle: 50.380, 10 cycle: 49.414, 100 cycle: 42.002\n",
      "epoch:[523 / 1000] batch:[30 / 134] loss= 0.100\n",
      "epoch:[523 / 1000] batch:[60 / 134] loss= 0.025\n",
      "epoch:[523 / 1000] batch:[90 / 134] loss= 0.062\n",
      "epoch:[523 / 1000] batch:[120 / 134] loss= 0.072\n",
      "100 cycles trn_loss: 0.103, val_loss: 0.133, lr=7.959537e-05\n",
      "training set RMSE 1 cycle: 44.271, 10 cycle: 46.078, 100 cycle: 46.494\n",
      "testing set RMSE 1 cycle: 51.368, 10 cycle: 46.013, 100 cycle: 48.153\n",
      "epoch:[524 / 1000] batch:[30 / 134] loss= 0.107\n",
      "epoch:[524 / 1000] batch:[60 / 134] loss= 0.055\n",
      "epoch:[524 / 1000] batch:[90 / 134] loss= 0.074\n",
      "epoch:[524 / 1000] batch:[120 / 134] loss= 0.030\n",
      "100 cycles trn_loss: 0.043, val_loss: 0.119, lr=6.579634e-05\n",
      "training set RMSE 1 cycle: 33.458, 10 cycle: 30.316, 100 cycle: 27.567\n",
      "testing set RMSE 1 cycle: 48.337, 10 cycle: 50.543, 100 cycle: 45.553\n",
      "epoch:[525 / 1000] batch:[30 / 134] loss= 0.136\n",
      "epoch:[525 / 1000] batch:[60 / 134] loss= 0.045\n",
      "epoch:[525 / 1000] batch:[90 / 134] loss= 0.034\n",
      "epoch:[525 / 1000] batch:[120 / 134] loss= 0.049\n",
      "100 cycles trn_loss: 0.057, val_loss: 0.123, lr=5.050000e-05\n",
      "training set RMSE 1 cycle: 52.040, 10 cycle: 46.295, 100 cycle: 31.410\n",
      "testing set RMSE 1 cycle: 57.744, 10 cycle: 57.518, 100 cycle: 47.225\n",
      "epoch:[526 / 1000] batch:[30 / 134] loss= 0.055\n",
      "epoch:[526 / 1000] batch:[60 / 134] loss= 0.060\n",
      "epoch:[526 / 1000] batch:[90 / 134] loss= 0.088\n",
      "epoch:[526 / 1000] batch:[120 / 134] loss= 0.081\n",
      "100 cycles trn_loss: 0.031, val_loss: 0.106, lr=3.520366e-05\n",
      "training set RMSE 1 cycle: 38.417, 10 cycle: 30.305, 100 cycle: 23.305\n",
      "testing set RMSE 1 cycle: 46.970, 10 cycle: 50.317, 100 cycle: 43.467\n",
      "epoch:[527 / 1000] batch:[30 / 134] loss= 0.027\n",
      "epoch:[527 / 1000] batch:[60 / 134] loss= 0.092\n",
      "epoch:[527 / 1000] batch:[90 / 134] loss= 0.035\n",
      "epoch:[527 / 1000] batch:[120 / 134] loss= 0.038\n",
      "100 cycles trn_loss: 0.030, val_loss: 0.123, lr=2.140463e-05\n",
      "training set RMSE 1 cycle: 32.332, 10 cycle: 27.729, 100 cycle: 22.700\n",
      "testing set RMSE 1 cycle: 51.430, 10 cycle: 52.307, 100 cycle: 46.712\n",
      "epoch:[528 / 1000] batch:[30 / 134] loss= 0.049\n",
      "epoch:[528 / 1000] batch:[60 / 134] loss= 0.055\n",
      "epoch:[528 / 1000] batch:[90 / 134] loss= 0.026\n",
      "epoch:[528 / 1000] batch:[120 / 134] loss= 0.031\n",
      "100 cycles trn_loss: 0.024, val_loss: 0.111, lr=1.045366e-05\n",
      "training set RMSE 1 cycle: 35.245, 10 cycle: 26.863, 100 cycle: 20.261\n",
      "testing set RMSE 1 cycle: 50.465, 10 cycle: 50.325, 100 cycle: 44.126\n",
      "epoch:[529 / 1000] batch:[30 / 134] loss= 0.024\n",
      "epoch:[529 / 1000] batch:[60 / 134] loss= 0.069\n",
      "epoch:[529 / 1000] batch:[90 / 134] loss= 0.050\n",
      "epoch:[529 / 1000] batch:[120 / 134] loss= 0.036\n",
      "100 cycles trn_loss: 0.024, val_loss: 0.113, lr=3.422702e-06\n",
      "training set RMSE 1 cycle: 31.380, 10 cycle: 24.694, 100 cycle: 20.465\n",
      "testing set RMSE 1 cycle: 49.297, 10 cycle: 49.742, 100 cycle: 44.325\n",
      "epoch:[530 / 1000] batch:[30 / 134] loss= 0.021\n",
      "epoch:[530 / 1000] batch:[60 / 134] loss= 0.024\n",
      "epoch:[530 / 1000] batch:[90 / 134] loss= 0.038\n",
      "epoch:[530 / 1000] batch:[120 / 134] loss= 0.022\n",
      "100 cycles trn_loss: 0.023, val_loss: 0.111, lr=1.000000e-06\n",
      "training set RMSE 1 cycle: 31.823, 10 cycle: 24.693, 100 cycle: 20.011\n",
      "testing set RMSE 1 cycle: 49.083, 10 cycle: 49.790, 100 cycle: 43.984\n",
      "epoch:[531 / 1000] batch:[30 / 134] loss= 0.016\n",
      "epoch:[531 / 1000] batch:[60 / 134] loss= 0.038\n",
      "epoch:[531 / 1000] batch:[90 / 134] loss= 0.020\n",
      "epoch:[531 / 1000] batch:[120 / 134] loss= 0.030\n",
      "100 cycles trn_loss: 0.024, val_loss: 0.109, lr=3.422702e-06\n",
      "training set RMSE 1 cycle: 31.393, 10 cycle: 24.403, 100 cycle: 20.546\n",
      "testing set RMSE 1 cycle: 48.464, 10 cycle: 48.534, 100 cycle: 43.419\n",
      "epoch:[532 / 1000] batch:[30 / 134] loss= 0.013\n",
      "epoch:[532 / 1000] batch:[60 / 134] loss= 0.041\n",
      "epoch:[532 / 1000] batch:[90 / 134] loss= 0.085\n",
      "epoch:[532 / 1000] batch:[120 / 134] loss= 0.019\n",
      "100 cycles trn_loss: 0.022, val_loss: 0.112, lr=1.045366e-05\n",
      "training set RMSE 1 cycle: 32.693, 10 cycle: 24.785, 100 cycle: 19.729\n",
      "testing set RMSE 1 cycle: 49.265, 10 cycle: 50.076, 100 cycle: 44.052\n",
      "epoch:[533 / 1000] batch:[30 / 134] loss= 0.032\n",
      "epoch:[533 / 1000] batch:[60 / 134] loss= 0.038\n",
      "epoch:[533 / 1000] batch:[90 / 134] loss= 0.024\n",
      "epoch:[533 / 1000] batch:[120 / 134] loss= 0.039\n",
      "100 cycles trn_loss: 0.027, val_loss: 0.115, lr=2.140463e-05\n",
      "training set RMSE 1 cycle: 30.517, 10 cycle: 23.806, 100 cycle: 21.614\n",
      "testing set RMSE 1 cycle: 47.770, 10 cycle: 49.223, 100 cycle: 44.512\n",
      "epoch:[534 / 1000] batch:[30 / 134] loss= 0.056\n",
      "epoch:[534 / 1000] batch:[60 / 134] loss= 0.038\n",
      "epoch:[534 / 1000] batch:[90 / 134] loss= 0.051\n",
      "epoch:[534 / 1000] batch:[120 / 134] loss= 0.035\n",
      "100 cycles trn_loss: 0.026, val_loss: 0.118, lr=3.520366e-05\n",
      "training set RMSE 1 cycle: 29.768, 10 cycle: 23.651, 100 cycle: 21.243\n",
      "testing set RMSE 1 cycle: 48.453, 10 cycle: 50.237, 100 cycle: 45.170\n",
      "epoch:[535 / 1000] batch:[30 / 134] loss= 0.018\n",
      "epoch:[535 / 1000] batch:[60 / 134] loss= 0.074\n",
      "epoch:[535 / 1000] batch:[90 / 134] loss= 0.053\n",
      "epoch:[535 / 1000] batch:[120 / 134] loss= 0.040\n",
      "100 cycles trn_loss: 0.050, val_loss: 0.100, lr=5.050000e-05\n",
      "training set RMSE 1 cycle: 31.826, 10 cycle: 30.699, 100 cycle: 30.359\n",
      "testing set RMSE 1 cycle: 42.503, 10 cycle: 42.100, 100 cycle: 41.582\n",
      "epoch:[536 / 1000] batch:[30 / 134] loss= 0.046\n",
      "epoch:[536 / 1000] batch:[60 / 134] loss= 0.081\n",
      "epoch:[536 / 1000] batch:[90 / 134] loss= 0.030\n",
      "epoch:[536 / 1000] batch:[120 / 134] loss= 0.043\n",
      "100 cycles trn_loss: 0.029, val_loss: 0.144, lr=6.579634e-05\n",
      "training set RMSE 1 cycle: 37.197, 10 cycle: 30.899, 100 cycle: 22.379\n",
      "testing set RMSE 1 cycle: 54.495, 10 cycle: 57.007, 100 cycle: 50.384\n",
      "epoch:[537 / 1000] batch:[30 / 134] loss= 0.041\n",
      "epoch:[537 / 1000] batch:[60 / 134] loss= 0.057\n",
      "epoch:[537 / 1000] batch:[90 / 134] loss= 0.064\n",
      "epoch:[537 / 1000] batch:[120 / 134] loss= 0.030\n",
      "100 cycles trn_loss: 0.045, val_loss: 0.161, lr=7.959537e-05\n",
      "training set RMSE 1 cycle: 41.251, 10 cycle: 36.889, 100 cycle: 27.960\n",
      "testing set RMSE 1 cycle: 55.893, 10 cycle: 58.614, 100 cycle: 53.283\n",
      "epoch:[538 / 1000] batch:[30 / 134] loss= 0.029\n",
      "epoch:[538 / 1000] batch:[60 / 134] loss= 0.022\n",
      "epoch:[538 / 1000] batch:[90 / 134] loss= 0.055\n",
      "epoch:[538 / 1000] batch:[120 / 134] loss= 0.021\n",
      "100 cycles trn_loss: 0.059, val_loss: 0.194, lr=9.054634e-05\n",
      "training set RMSE 1 cycle: 38.706, 10 cycle: 34.303, 100 cycle: 32.292\n",
      "testing set RMSE 1 cycle: 58.037, 10 cycle: 62.560, 100 cycle: 58.288\n",
      "epoch:[539 / 1000] batch:[30 / 134] loss= 0.107\n",
      "epoch:[539 / 1000] batch:[60 / 134] loss= 0.073\n",
      "epoch:[539 / 1000] batch:[90 / 134] loss= 0.101\n",
      "epoch:[539 / 1000] batch:[120 / 134] loss= 0.066\n",
      "100 cycles trn_loss: 0.049, val_loss: 0.092, lr=9.757730e-05\n",
      "training set RMSE 1 cycle: 42.436, 10 cycle: 35.107, 100 cycle: 29.908\n",
      "testing set RMSE 1 cycle: 45.886, 10 cycle: 45.417, 100 cycle: 39.964\n",
      "epoch:[540 / 1000] batch:[30 / 134] loss= 0.074\n",
      "epoch:[540 / 1000] batch:[60 / 134] loss= 0.055\n",
      "epoch:[540 / 1000] batch:[90 / 134] loss= 0.022\n",
      "epoch:[540 / 1000] batch:[120 / 134] loss= 0.050\n",
      "100 cycles trn_loss: 0.039, val_loss: 0.151, lr=1.000000e-04\n",
      "training set RMSE 1 cycle: 37.582, 10 cycle: 32.348, 100 cycle: 25.994\n",
      "testing set RMSE 1 cycle: 54.566, 10 cycle: 57.432, 100 cycle: 52.327\n",
      "epoch:[541 / 1000] batch:[30 / 134] loss= 0.106\n",
      "epoch:[541 / 1000] batch:[60 / 134] loss= 0.197\n",
      "epoch:[541 / 1000] batch:[90 / 134] loss= 0.181\n",
      "epoch:[541 / 1000] batch:[120 / 134] loss= 0.063\n",
      "100 cycles trn_loss: 0.040, val_loss: 0.094, lr=9.757730e-05\n",
      "training set RMSE 1 cycle: 42.023, 10 cycle: 33.263, 100 cycle: 26.542\n",
      "testing set RMSE 1 cycle: 49.957, 10 cycle: 48.265, 100 cycle: 40.350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:[542 / 1000] batch:[30 / 134] loss= 0.044\n",
      "epoch:[542 / 1000] batch:[60 / 134] loss= 0.077\n",
      "epoch:[542 / 1000] batch:[90 / 134] loss= 0.097\n",
      "epoch:[542 / 1000] batch:[120 / 134] loss= 0.070\n",
      "100 cycles trn_loss: 0.108, val_loss: 0.124, lr=9.054634e-05\n",
      "training set RMSE 1 cycle: 46.732, 10 cycle: 47.813, 100 cycle: 47.702\n",
      "testing set RMSE 1 cycle: 51.283, 10 cycle: 44.780, 100 cycle: 46.523\n",
      "epoch:[543 / 1000] batch:[30 / 134] loss= 0.020\n",
      "epoch:[543 / 1000] batch:[60 / 134] loss= 0.072\n",
      "epoch:[543 / 1000] batch:[90 / 134] loss= 0.061\n",
      "epoch:[543 / 1000] batch:[120 / 134] loss= 0.247\n",
      "100 cycles trn_loss: 0.110, val_loss: 0.192, lr=7.959537e-05\n",
      "training set RMSE 1 cycle: 44.798, 10 cycle: 45.116, 100 cycle: 45.852\n",
      "testing set RMSE 1 cycle: 54.668, 10 cycle: 57.406, 100 cycle: 57.944\n",
      "epoch:[544 / 1000] batch:[30 / 134] loss= 0.036\n",
      "epoch:[544 / 1000] batch:[60 / 134] loss= 0.043\n",
      "epoch:[544 / 1000] batch:[90 / 134] loss= 0.024\n",
      "epoch:[544 / 1000] batch:[120 / 134] loss= 0.054\n",
      "100 cycles trn_loss: 0.047, val_loss: 0.173, lr=6.579634e-05\n",
      "training set RMSE 1 cycle: 37.224, 10 cycle: 33.800, 100 cycle: 28.684\n",
      "testing set RMSE 1 cycle: 58.464, 10 cycle: 60.619, 100 cycle: 55.510\n",
      "epoch:[545 / 1000] batch:[30 / 134] loss= 0.075\n",
      "epoch:[545 / 1000] batch:[60 / 134] loss= 0.047\n",
      "epoch:[545 / 1000] batch:[90 / 134] loss= 0.070\n",
      "epoch:[545 / 1000] batch:[120 / 134] loss= 0.172\n",
      "100 cycles trn_loss: 0.045, val_loss: 0.111, lr=5.050000e-05\n",
      "training set RMSE 1 cycle: 50.405, 10 cycle: 38.689, 100 cycle: 27.850\n",
      "testing set RMSE 1 cycle: 50.625, 10 cycle: 51.758, 100 cycle: 43.870\n",
      "epoch:[546 / 1000] batch:[30 / 134] loss= 0.080\n",
      "epoch:[546 / 1000] batch:[60 / 134] loss= 0.045\n",
      "epoch:[546 / 1000] batch:[90 / 134] loss= 0.084\n",
      "epoch:[546 / 1000] batch:[120 / 134] loss= 0.029\n",
      "100 cycles trn_loss: 0.031, val_loss: 0.109, lr=3.520366e-05\n",
      "training set RMSE 1 cycle: 30.436, 10 cycle: 24.336, 100 cycle: 23.525\n",
      "testing set RMSE 1 cycle: 46.121, 10 cycle: 46.407, 100 cycle: 43.493\n",
      "epoch:[547 / 1000] batch:[30 / 134] loss= 0.060\n",
      "epoch:[547 / 1000] batch:[60 / 134] loss= 0.016\n",
      "epoch:[547 / 1000] batch:[90 / 134] loss= 0.066\n",
      "epoch:[547 / 1000] batch:[120 / 134] loss= 0.080\n",
      "100 cycles trn_loss: 0.019, val_loss: 0.133, lr=2.140463e-05\n",
      "training set RMSE 1 cycle: 34.346, 10 cycle: 25.086, 100 cycle: 18.228\n",
      "testing set RMSE 1 cycle: 53.525, 10 cycle: 54.690, 100 cycle: 48.352\n",
      "epoch:[548 / 1000] batch:[30 / 134] loss= 0.033\n",
      "epoch:[548 / 1000] batch:[60 / 134] loss= 0.058\n",
      "epoch:[548 / 1000] batch:[90 / 134] loss= 0.029\n",
      "epoch:[548 / 1000] batch:[120 / 134] loss= 0.024\n",
      "100 cycles trn_loss: 0.018, val_loss: 0.123, lr=1.045366e-05\n",
      "training set RMSE 1 cycle: 33.370, 10 cycle: 24.113, 100 cycle: 17.505\n",
      "testing set RMSE 1 cycle: 53.963, 10 cycle: 52.338, 100 cycle: 46.257\n",
      "epoch:[549 / 1000] batch:[30 / 134] loss= 0.034\n",
      "epoch:[549 / 1000] batch:[60 / 134] loss= 0.021\n",
      "epoch:[549 / 1000] batch:[90 / 134] loss= 0.043\n",
      "epoch:[549 / 1000] batch:[120 / 134] loss= 0.036\n",
      "100 cycles trn_loss: 0.018, val_loss: 0.121, lr=3.422702e-06\n",
      "training set RMSE 1 cycle: 31.079, 10 cycle: 22.278, 100 cycle: 17.843\n",
      "testing set RMSE 1 cycle: 52.896, 10 cycle: 51.110, 100 cycle: 45.694\n",
      "epoch:[550 / 1000] batch:[30 / 134] loss= 0.039\n",
      "epoch:[550 / 1000] batch:[60 / 134] loss= 0.022\n",
      "epoch:[550 / 1000] batch:[90 / 134] loss= 0.021\n",
      "epoch:[550 / 1000] batch:[120 / 134] loss= 0.030\n",
      "100 cycles trn_loss: 0.020, val_loss: 0.119, lr=1.000000e-06\n",
      "training set RMSE 1 cycle: 28.289, 10 cycle: 21.165, 100 cycle: 18.732\n",
      "testing set RMSE 1 cycle: 51.988, 10 cycle: 49.948, 100 cycle: 45.434\n",
      "epoch:[551 / 1000] batch:[30 / 134] loss= 0.014\n",
      "epoch:[551 / 1000] batch:[60 / 134] loss= 0.015\n",
      "epoch:[551 / 1000] batch:[90 / 134] loss= 0.028\n",
      "epoch:[551 / 1000] batch:[120 / 134] loss= 0.019\n",
      "100 cycles trn_loss: 0.019, val_loss: 0.122, lr=3.422702e-06\n",
      "training set RMSE 1 cycle: 28.677, 10 cycle: 21.199, 100 cycle: 17.976\n",
      "testing set RMSE 1 cycle: 52.862, 10 cycle: 50.756, 100 cycle: 45.924\n",
      "epoch:[552 / 1000] batch:[30 / 134] loss= 0.025\n",
      "epoch:[552 / 1000] batch:[60 / 134] loss= 0.038\n",
      "epoch:[552 / 1000] batch:[90 / 134] loss= 0.046\n",
      "epoch:[552 / 1000] batch:[120 / 134] loss= 0.055\n",
      "100 cycles trn_loss: 0.018, val_loss: 0.125, lr=1.045366e-05\n",
      "training set RMSE 1 cycle: 30.570, 10 cycle: 21.762, 100 cycle: 17.565\n",
      "testing set RMSE 1 cycle: 53.796, 10 cycle: 51.831, 100 cycle: 46.480\n",
      "epoch:[553 / 1000] batch:[30 / 134] loss= 0.033\n",
      "epoch:[553 / 1000] batch:[60 / 134] loss= 0.014\n",
      "epoch:[553 / 1000] batch:[90 / 134] loss= 0.040\n",
      "epoch:[553 / 1000] batch:[120 / 134] loss= 0.020\n",
      "100 cycles trn_loss: 0.023, val_loss: 0.111, lr=2.140463e-05\n",
      "training set RMSE 1 cycle: 28.199, 10 cycle: 21.955, 100 cycle: 19.925\n",
      "testing set RMSE 1 cycle: 51.095, 10 cycle: 48.440, 100 cycle: 43.870\n",
      "epoch:[554 / 1000] batch:[30 / 134] loss= 0.015\n",
      "epoch:[554 / 1000] batch:[60 / 134] loss= 0.044\n",
      "epoch:[554 / 1000] batch:[90 / 134] loss= 0.081\n",
      "epoch:[554 / 1000] batch:[120 / 134] loss= 0.047\n",
      "100 cycles trn_loss: 0.026, val_loss: 0.119, lr=3.520366e-05\n",
      "training set RMSE 1 cycle: 30.357, 10 cycle: 22.994, 100 cycle: 21.124\n",
      "testing set RMSE 1 cycle: 51.173, 10 cycle: 48.942, 100 cycle: 45.414\n",
      "epoch:[555 / 1000] batch:[30 / 134] loss= 0.060\n",
      "epoch:[555 / 1000] batch:[60 / 134] loss= 0.060\n",
      "epoch:[555 / 1000] batch:[90 / 134] loss= 0.047\n",
      "epoch:[555 / 1000] batch:[120 / 134] loss= 0.046\n",
      "100 cycles trn_loss: 0.029, val_loss: 0.115, lr=5.050000e-05\n",
      "training set RMSE 1 cycle: 31.194, 10 cycle: 23.969, 100 cycle: 22.553\n",
      "testing set RMSE 1 cycle: 48.254, 10 cycle: 47.764, 100 cycle: 44.641\n",
      "epoch:[556 / 1000] batch:[30 / 134] loss= 0.028\n",
      "epoch:[556 / 1000] batch:[60 / 134] loss= 0.080\n",
      "epoch:[556 / 1000] batch:[90 / 134] loss= 0.037\n",
      "epoch:[556 / 1000] batch:[120 / 134] loss= 0.015\n",
      "100 cycles trn_loss: 0.027, val_loss: 0.121, lr=6.579634e-05\n",
      "training set RMSE 1 cycle: 46.862, 10 cycle: 37.195, 100 cycle: 21.620\n",
      "testing set RMSE 1 cycle: 57.180, 10 cycle: 55.893, 100 cycle: 46.817\n",
      "epoch:[557 / 1000] batch:[30 / 134] loss= 0.032\n",
      "epoch:[557 / 1000] batch:[60 / 134] loss= 0.040\n",
      "epoch:[557 / 1000] batch:[90 / 134] loss= 0.027\n",
      "epoch:[557 / 1000] batch:[120 / 134] loss= 0.030\n",
      "100 cycles trn_loss: 0.063, val_loss: 0.099, lr=7.959537e-05\n",
      "training set RMSE 1 cycle: 31.252, 10 cycle: 34.993, 100 cycle: 34.154\n",
      "testing set RMSE 1 cycle: 43.173, 10 cycle: 42.092, 100 cycle: 41.369\n",
      "epoch:[558 / 1000] batch:[30 / 134] loss= 0.039\n",
      "epoch:[558 / 1000] batch:[60 / 134] loss= 0.087\n",
      "epoch:[558 / 1000] batch:[90 / 134] loss= 0.028\n",
      "epoch:[558 / 1000] batch:[120 / 134] loss= 0.032\n",
      "100 cycles trn_loss: 0.060, val_loss: 0.106, lr=9.054634e-05\n",
      "training set RMSE 1 cycle: 38.896, 10 cycle: 32.777, 100 cycle: 33.139\n",
      "testing set RMSE 1 cycle: 45.675, 10 cycle: 44.024, 100 cycle: 42.815\n",
      "epoch:[559 / 1000] batch:[30 / 134] loss= 0.067\n",
      "epoch:[559 / 1000] batch:[60 / 134] loss= 0.079\n",
      "epoch:[559 / 1000] batch:[90 / 134] loss= 0.036\n",
      "epoch:[559 / 1000] batch:[120 / 134] loss= 0.248\n",
      "100 cycles trn_loss: 0.093, val_loss: 0.107, lr=9.757730e-05\n",
      "training set RMSE 1 cycle: 54.993, 10 cycle: 50.162, 100 cycle: 41.973\n",
      "testing set RMSE 1 cycle: 54.328, 10 cycle: 47.437, 100 cycle: 43.087\n",
      "epoch:[560 / 1000] batch:[30 / 134] loss= 0.206\n",
      "epoch:[560 / 1000] batch:[60 / 134] loss= 0.030\n",
      "epoch:[560 / 1000] batch:[90 / 134] loss= 0.110\n",
      "epoch:[560 / 1000] batch:[120 / 134] loss= 0.062\n",
      "100 cycles trn_loss: 0.045, val_loss: 0.125, lr=1.000000e-04\n",
      "training set RMSE 1 cycle: 32.836, 10 cycle: 30.614, 100 cycle: 28.668\n",
      "testing set RMSE 1 cycle: 50.915, 10 cycle: 48.789, 100 cycle: 46.719\n",
      "epoch:[561 / 1000] batch:[30 / 134] loss= 0.052\n",
      "epoch:[561 / 1000] batch:[60 / 134] loss= 0.018\n",
      "epoch:[561 / 1000] batch:[90 / 134] loss= 0.059\n",
      "epoch:[561 / 1000] batch:[120 / 134] loss= 0.037\n",
      "100 cycles trn_loss: 0.038, val_loss: 0.123, lr=9.757730e-05\n",
      "training set RMSE 1 cycle: 47.097, 10 cycle: 41.789, 100 cycle: 25.487\n",
      "testing set RMSE 1 cycle: 56.819, 10 cycle: 57.365, 100 cycle: 48.707\n",
      "epoch:[562 / 1000] batch:[30 / 134] loss= 0.068\n",
      "epoch:[562 / 1000] batch:[60 / 134] loss= 0.032\n",
      "epoch:[562 / 1000] batch:[90 / 134] loss= 0.022\n",
      "epoch:[562 / 1000] batch:[120 / 134] loss= 0.148\n",
      "100 cycles trn_loss: 0.148, val_loss: 0.154, lr=9.054634e-05\n",
      "training set RMSE 1 cycle: 74.798, 10 cycle: 70.904, 100 cycle: 52.447\n",
      "testing set RMSE 1 cycle: 70.054, 10 cycle: 67.117, 100 cycle: 56.395\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:[563 / 1000] batch:[30 / 134] loss= 0.103\n",
      "epoch:[563 / 1000] batch:[60 / 134] loss= 0.032\n",
      "epoch:[563 / 1000] batch:[90 / 134] loss= 0.037\n",
      "epoch:[563 / 1000] batch:[120 / 134] loss= 0.020\n",
      "100 cycles trn_loss: 0.040, val_loss: 0.086, lr=7.959537e-05\n",
      "training set RMSE 1 cycle: 30.237, 10 cycle: 28.994, 100 cycle: 26.732\n",
      "testing set RMSE 1 cycle: 44.271, 10 cycle: 42.607, 100 cycle: 38.672\n",
      "epoch:[564 / 1000] batch:[30 / 134] loss= 0.047\n",
      "epoch:[564 / 1000] batch:[60 / 134] loss= 0.026\n",
      "epoch:[564 / 1000] batch:[90 / 134] loss= 0.034\n",
      "epoch:[564 / 1000] batch:[120 / 134] loss= 0.030\n",
      "100 cycles trn_loss: 0.017, val_loss: 0.131, lr=6.579634e-05\n",
      "training set RMSE 1 cycle: 29.301, 10 cycle: 20.074, 100 cycle: 17.319\n",
      "testing set RMSE 1 cycle: 54.989, 10 cycle: 52.378, 100 cycle: 47.578\n",
      "epoch:[565 / 1000] batch:[30 / 134] loss= 0.026\n",
      "epoch:[565 / 1000] batch:[60 / 134] loss= 0.032\n",
      "epoch:[565 / 1000] batch:[90 / 134] loss= 0.049\n",
      "epoch:[565 / 1000] batch:[120 / 134] loss= 0.047\n",
      "100 cycles trn_loss: 0.015, val_loss: 0.140, lr=5.050000e-05\n",
      "training set RMSE 1 cycle: 33.546, 10 cycle: 23.793, 100 cycle: 16.000\n",
      "testing set RMSE 1 cycle: 57.167, 10 cycle: 55.708, 100 cycle: 49.816\n",
      "epoch:[566 / 1000] batch:[30 / 134] loss= 0.023\n",
      "epoch:[566 / 1000] batch:[60 / 134] loss= 0.020\n",
      "epoch:[566 / 1000] batch:[90 / 134] loss= 0.018\n",
      "epoch:[566 / 1000] batch:[120 / 134] loss= 0.021\n",
      "100 cycles trn_loss: 0.014, val_loss: 0.132, lr=3.520366e-05\n",
      "training set RMSE 1 cycle: 31.698, 10 cycle: 21.626, 100 cycle: 15.681\n",
      "testing set RMSE 1 cycle: 58.124, 10 cycle: 53.587, 100 cycle: 48.405\n",
      "epoch:[567 / 1000] batch:[30 / 134] loss= 0.022\n",
      "epoch:[567 / 1000] batch:[60 / 134] loss= 0.032\n",
      "epoch:[567 / 1000] batch:[90 / 134] loss= 0.028\n",
      "epoch:[567 / 1000] batch:[120 / 134] loss= 0.011\n",
      "100 cycles trn_loss: 0.014, val_loss: 0.128, lr=2.140463e-05\n",
      "training set RMSE 1 cycle: 35.330, 10 cycle: 26.180, 100 cycle: 15.705\n",
      "testing set RMSE 1 cycle: 56.338, 10 cycle: 54.465, 100 cycle: 47.587\n",
      "epoch:[568 / 1000] batch:[30 / 134] loss= 0.073\n",
      "epoch:[568 / 1000] batch:[60 / 134] loss= 0.012\n",
      "epoch:[568 / 1000] batch:[90 / 134] loss= 0.034\n",
      "epoch:[568 / 1000] batch:[120 / 134] loss= 0.023\n",
      "100 cycles trn_loss: 0.013, val_loss: 0.128, lr=1.045366e-05\n",
      "training set RMSE 1 cycle: 25.781, 10 cycle: 18.158, 100 cycle: 14.767\n",
      "testing set RMSE 1 cycle: 54.328, 10 cycle: 52.882, 100 cycle: 47.186\n",
      "epoch:[569 / 1000] batch:[30 / 134] loss= 0.038\n",
      "epoch:[569 / 1000] batch:[60 / 134] loss= 0.027\n",
      "epoch:[569 / 1000] batch:[90 / 134] loss= 0.031\n",
      "epoch:[569 / 1000] batch:[120 / 134] loss= 0.035\n",
      "100 cycles trn_loss: 0.013, val_loss: 0.129, lr=3.422702e-06\n",
      "training set RMSE 1 cycle: 25.389, 10 cycle: 17.973, 100 cycle: 14.863\n",
      "testing set RMSE 1 cycle: 54.346, 10 cycle: 52.778, 100 cycle: 47.526\n",
      "epoch:[570 / 1000] batch:[30 / 134] loss= 0.013\n",
      "epoch:[570 / 1000] batch:[60 / 134] loss= 0.035\n",
      "epoch:[570 / 1000] batch:[90 / 134] loss= 0.023\n",
      "epoch:[570 / 1000] batch:[120 / 134] loss= 0.032\n",
      "100 cycles trn_loss: 0.014, val_loss: 0.126, lr=1.000000e-06\n",
      "training set RMSE 1 cycle: 25.630, 10 cycle: 16.925, 100 cycle: 15.551\n",
      "testing set RMSE 1 cycle: 53.649, 10 cycle: 51.714, 100 cycle: 46.733\n",
      "epoch:[571 / 1000] batch:[30 / 134] loss= 0.018\n",
      "epoch:[571 / 1000] batch:[60 / 134] loss= 0.023\n",
      "epoch:[571 / 1000] batch:[90 / 134] loss= 0.021\n",
      "epoch:[571 / 1000] batch:[120 / 134] loss= 0.015\n",
      "100 cycles trn_loss: 0.014, val_loss: 0.125, lr=3.422702e-06\n",
      "training set RMSE 1 cycle: 25.218, 10 cycle: 16.977, 100 cycle: 15.346\n",
      "testing set RMSE 1 cycle: 53.835, 10 cycle: 51.614, 100 cycle: 46.572\n",
      "epoch:[572 / 1000] batch:[30 / 134] loss= 0.031\n",
      "epoch:[572 / 1000] batch:[60 / 134] loss= 0.021\n",
      "epoch:[572 / 1000] batch:[90 / 134] loss= 0.015\n",
      "epoch:[572 / 1000] batch:[120 / 134] loss= 0.016\n",
      "100 cycles trn_loss: 0.012, val_loss: 0.128, lr=1.045366e-05\n",
      "training set RMSE 1 cycle: 26.220, 10 cycle: 17.446, 100 cycle: 14.577\n",
      "testing set RMSE 1 cycle: 54.675, 10 cycle: 52.509, 100 cycle: 47.178\n",
      "epoch:[573 / 1000] batch:[30 / 134] loss= 0.035\n",
      "epoch:[573 / 1000] batch:[60 / 134] loss= 0.012\n",
      "epoch:[573 / 1000] batch:[90 / 134] loss= 0.014\n",
      "epoch:[573 / 1000] batch:[120 / 134] loss= 0.032\n",
      "100 cycles trn_loss: 0.015, val_loss: 0.123, lr=2.140463e-05\n",
      "training set RMSE 1 cycle: 26.668, 10 cycle: 17.484, 100 cycle: 16.145\n",
      "testing set RMSE 1 cycle: 53.864, 10 cycle: 50.629, 100 cycle: 46.178\n",
      "epoch:[574 / 1000] batch:[30 / 134] loss= 0.022\n",
      "epoch:[574 / 1000] batch:[60 / 134] loss= 0.029\n",
      "epoch:[574 / 1000] batch:[90 / 134] loss= 0.020\n",
      "epoch:[574 / 1000] batch:[120 / 134] loss= 0.043\n",
      "100 cycles trn_loss: 0.029, val_loss: 0.106, lr=3.520366e-05\n",
      "training set RMSE 1 cycle: 25.122, 10 cycle: 22.374, 100 cycle: 22.586\n",
      "testing set RMSE 1 cycle: 47.779, 10 cycle: 46.280, 100 cycle: 42.923\n",
      "epoch:[575 / 1000] batch:[30 / 134] loss= 0.021\n",
      "epoch:[575 / 1000] batch:[60 / 134] loss= 0.014\n",
      "epoch:[575 / 1000] batch:[90 / 134] loss= 0.037\n",
      "epoch:[575 / 1000] batch:[120 / 134] loss= 0.027\n",
      "100 cycles trn_loss: 0.020, val_loss: 0.119, lr=5.050000e-05\n",
      "training set RMSE 1 cycle: 25.161, 10 cycle: 18.631, 100 cycle: 18.961\n",
      "testing set RMSE 1 cycle: 52.440, 10 cycle: 48.899, 100 cycle: 45.471\n",
      "epoch:[576 / 1000] batch:[30 / 134] loss= 0.041\n",
      "epoch:[576 / 1000] batch:[60 / 134] loss= 0.037\n",
      "epoch:[576 / 1000] batch:[90 / 134] loss= 0.017\n",
      "epoch:[576 / 1000] batch:[120 / 134] loss= 0.018\n",
      "100 cycles trn_loss: 0.035, val_loss: 0.147, lr=6.579634e-05\n",
      "training set RMSE 1 cycle: 23.212, 10 cycle: 23.882, 100 cycle: 24.551\n",
      "testing set RMSE 1 cycle: 52.059, 10 cycle: 52.173, 100 cycle: 50.668\n",
      "epoch:[577 / 1000] batch:[30 / 134] loss= 0.058\n",
      "epoch:[577 / 1000] batch:[60 / 134] loss= 0.072\n",
      "epoch:[577 / 1000] batch:[90 / 134] loss= 0.071\n",
      "epoch:[577 / 1000] batch:[120 / 134] loss= 0.099\n",
      "100 cycles trn_loss: 0.069, val_loss: 0.110, lr=7.959537e-05\n",
      "training set RMSE 1 cycle: 37.243, 10 cycle: 37.692, 100 cycle: 36.278\n",
      "testing set RMSE 1 cycle: 39.898, 10 cycle: 42.342, 100 cycle: 43.681\n",
      "epoch:[578 / 1000] batch:[30 / 134] loss= 0.116\n",
      "epoch:[578 / 1000] batch:[60 / 134] loss= 0.195\n",
      "epoch:[578 / 1000] batch:[90 / 134] loss= 0.053\n",
      "epoch:[578 / 1000] batch:[120 / 134] loss= 0.132\n",
      "100 cycles trn_loss: 0.126, val_loss: 0.124, lr=9.054634e-05\n",
      "training set RMSE 1 cycle: 55.153, 10 cycle: 54.131, 100 cycle: 49.695\n",
      "testing set RMSE 1 cycle: 55.167, 10 cycle: 49.357, 100 cycle: 46.552\n",
      "epoch:[579 / 1000] batch:[30 / 134] loss= 0.120\n",
      "epoch:[579 / 1000] batch:[60 / 134] loss= 0.039\n",
      "epoch:[579 / 1000] batch:[90 / 134] loss= 0.062\n",
      "epoch:[579 / 1000] batch:[120 / 134] loss= 0.135\n",
      "100 cycles trn_loss: 0.105, val_loss: 0.126, lr=9.757730e-05\n",
      "training set RMSE 1 cycle: 48.467, 10 cycle: 48.737, 100 cycle: 45.781\n",
      "testing set RMSE 1 cycle: 46.310, 10 cycle: 48.505, 100 cycle: 46.785\n",
      "epoch:[580 / 1000] batch:[30 / 134] loss= 0.046\n",
      "epoch:[580 / 1000] batch:[60 / 134] loss= 0.121\n",
      "epoch:[580 / 1000] batch:[90 / 134] loss= 0.026\n",
      "epoch:[580 / 1000] batch:[120 / 134] loss= 0.064\n",
      "100 cycles trn_loss: 0.071, val_loss: 0.120, lr=1.000000e-04\n",
      "training set RMSE 1 cycle: 45.255, 10 cycle: 43.103, 100 cycle: 36.775\n",
      "testing set RMSE 1 cycle: 52.374, 10 cycle: 51.090, 100 cycle: 46.163\n",
      "epoch:[581 / 1000] batch:[30 / 134] loss= 0.149\n",
      "epoch:[581 / 1000] batch:[60 / 134] loss= 0.029\n",
      "epoch:[581 / 1000] batch:[90 / 134] loss= 0.036\n",
      "epoch:[581 / 1000] batch:[120 / 134] loss= 0.126\n",
      "100 cycles trn_loss: 0.046, val_loss: 0.098, lr=9.757730e-05\n",
      "training set RMSE 1 cycle: 41.966, 10 cycle: 35.955, 100 cycle: 28.729\n",
      "testing set RMSE 1 cycle: 51.353, 10 cycle: 47.019, 100 cycle: 41.205\n",
      "epoch:[582 / 1000] batch:[30 / 134] loss= 0.068\n",
      "epoch:[582 / 1000] batch:[60 / 134] loss= 0.066\n",
      "epoch:[582 / 1000] batch:[90 / 134] loss= 0.052\n",
      "epoch:[582 / 1000] batch:[120 / 134] loss= 0.070\n",
      "100 cycles trn_loss: 0.054, val_loss: 0.162, lr=9.054634e-05\n",
      "training set RMSE 1 cycle: 42.491, 10 cycle: 39.972, 100 cycle: 30.885\n",
      "testing set RMSE 1 cycle: 56.376, 10 cycle: 58.745, 100 cycle: 54.174\n",
      "epoch:[583 / 1000] batch:[30 / 134] loss= 0.063\n",
      "epoch:[583 / 1000] batch:[60 / 134] loss= 0.049\n",
      "epoch:[583 / 1000] batch:[90 / 134] loss= 0.090\n",
      "epoch:[583 / 1000] batch:[120 / 134] loss= 0.084\n",
      "100 cycles trn_loss: 0.051, val_loss: 0.131, lr=7.959537e-05\n",
      "training set RMSE 1 cycle: 33.688, 10 cycle: 32.437, 100 cycle: 30.393\n",
      "testing set RMSE 1 cycle: 47.409, 10 cycle: 49.194, 100 cycle: 47.747\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:[584 / 1000] batch:[30 / 134] loss= 0.070\n",
      "epoch:[584 / 1000] batch:[60 / 134] loss= 0.045\n",
      "epoch:[584 / 1000] batch:[90 / 134] loss= 0.028\n",
      "epoch:[584 / 1000] batch:[120 / 134] loss= 0.074\n",
      "100 cycles trn_loss: 0.033, val_loss: 0.104, lr=6.579634e-05\n",
      "training set RMSE 1 cycle: 38.108, 10 cycle: 33.535, 100 cycle: 24.115\n",
      "testing set RMSE 1 cycle: 53.649, 10 cycle: 49.671, 100 cycle: 43.057\n",
      "epoch:[585 / 1000] batch:[30 / 134] loss= 0.073\n",
      "epoch:[585 / 1000] batch:[60 / 134] loss= 0.054\n",
      "epoch:[585 / 1000] batch:[90 / 134] loss= 0.020\n",
      "epoch:[585 / 1000] batch:[120 / 134] loss= 0.038\n",
      "100 cycles trn_loss: 0.032, val_loss: 0.120, lr=5.050000e-05\n",
      "training set RMSE 1 cycle: 40.193, 10 cycle: 31.239, 100 cycle: 23.729\n",
      "testing set RMSE 1 cycle: 54.425, 10 cycle: 50.098, 100 cycle: 45.817\n",
      "epoch:[586 / 1000] batch:[30 / 134] loss= 0.089\n",
      "epoch:[586 / 1000] batch:[60 / 134] loss= 0.052\n",
      "epoch:[586 / 1000] batch:[90 / 134] loss= 0.069\n",
      "epoch:[586 / 1000] batch:[120 / 134] loss= 0.071\n",
      "100 cycles trn_loss: 0.025, val_loss: 0.121, lr=3.520366e-05\n",
      "training set RMSE 1 cycle: 35.326, 10 cycle: 29.224, 100 cycle: 20.969\n",
      "testing set RMSE 1 cycle: 52.566, 10 cycle: 49.956, 100 cycle: 46.193\n",
      "epoch:[587 / 1000] batch:[30 / 134] loss= 0.062\n",
      "epoch:[587 / 1000] batch:[60 / 134] loss= 0.031\n",
      "epoch:[587 / 1000] batch:[90 / 134] loss= 0.053\n",
      "epoch:[587 / 1000] batch:[120 / 134] loss= 0.026\n",
      "100 cycles trn_loss: 0.026, val_loss: 0.125, lr=2.140463e-05\n",
      "training set RMSE 1 cycle: 30.086, 10 cycle: 24.554, 100 cycle: 21.219\n",
      "testing set RMSE 1 cycle: 48.595, 10 cycle: 48.711, 100 cycle: 46.493\n",
      "epoch:[588 / 1000] batch:[30 / 134] loss= 0.018\n",
      "epoch:[588 / 1000] batch:[60 / 134] loss= 0.025\n",
      "epoch:[588 / 1000] batch:[90 / 134] loss= 0.081\n",
      "epoch:[588 / 1000] batch:[120 / 134] loss= 0.043\n",
      "100 cycles trn_loss: 0.026, val_loss: 0.119, lr=1.045366e-05\n",
      "training set RMSE 1 cycle: 30.679, 10 cycle: 23.533, 100 cycle: 21.485\n",
      "testing set RMSE 1 cycle: 50.002, 10 cycle: 46.504, 100 cycle: 45.402\n",
      "epoch:[589 / 1000] batch:[30 / 134] loss= 0.052\n",
      "epoch:[589 / 1000] batch:[60 / 134] loss= 0.051\n",
      "epoch:[589 / 1000] batch:[90 / 134] loss= 0.034\n",
      "epoch:[589 / 1000] batch:[120 / 134] loss= 0.040\n",
      "100 cycles trn_loss: 0.020, val_loss: 0.121, lr=3.422702e-06\n",
      "training set RMSE 1 cycle: 32.347, 10 cycle: 24.154, 100 cycle: 18.402\n",
      "testing set RMSE 1 cycle: 51.679, 10 cycle: 47.759, 100 cycle: 46.010\n",
      "epoch:[590 / 1000] batch:[30 / 134] loss= 0.019\n",
      "epoch:[590 / 1000] batch:[60 / 134] loss= 0.024\n",
      "epoch:[590 / 1000] batch:[90 / 134] loss= 0.025\n",
      "epoch:[590 / 1000] batch:[120 / 134] loss= 0.011\n",
      "100 cycles trn_loss: 0.021, val_loss: 0.123, lr=1.000000e-06\n",
      "training set RMSE 1 cycle: 29.842, 10 cycle: 22.635, 100 cycle: 19.288\n",
      "testing set RMSE 1 cycle: 50.260, 10 cycle: 47.293, 100 cycle: 46.231\n",
      "epoch:[591 / 1000] batch:[30 / 134] loss= 0.039\n",
      "epoch:[591 / 1000] batch:[60 / 134] loss= 0.022\n",
      "epoch:[591 / 1000] batch:[90 / 134] loss= 0.022\n",
      "epoch:[591 / 1000] batch:[120 / 134] loss= 0.053\n",
      "100 cycles trn_loss: 0.021, val_loss: 0.122, lr=3.422702e-06\n",
      "training set RMSE 1 cycle: 30.837, 10 cycle: 22.981, 100 cycle: 19.084\n",
      "testing set RMSE 1 cycle: 50.949, 10 cycle: 47.330, 100 cycle: 46.035\n",
      "epoch:[592 / 1000] batch:[30 / 134] loss= 0.011\n",
      "epoch:[592 / 1000] batch:[60 / 134] loss= 0.054\n",
      "epoch:[592 / 1000] batch:[90 / 134] loss= 0.079\n",
      "epoch:[592 / 1000] batch:[120 / 134] loss= 0.017\n",
      "100 cycles trn_loss: 0.019, val_loss: 0.121, lr=1.045366e-05\n",
      "training set RMSE 1 cycle: 31.552, 10 cycle: 23.660, 100 cycle: 18.126\n",
      "testing set RMSE 1 cycle: 51.055, 10 cycle: 47.580, 100 cycle: 45.885\n",
      "epoch:[593 / 1000] batch:[30 / 134] loss= 0.007\n",
      "epoch:[593 / 1000] batch:[60 / 134] loss= 0.039\n",
      "epoch:[593 / 1000] batch:[90 / 134] loss= 0.012\n",
      "epoch:[593 / 1000] batch:[120 / 134] loss= 0.058\n",
      "100 cycles trn_loss: 0.024, val_loss: 0.124, lr=2.140463e-05\n",
      "training set RMSE 1 cycle: 30.309, 10 cycle: 22.748, 100 cycle: 20.592\n",
      "testing set RMSE 1 cycle: 49.687, 10 cycle: 47.632, 100 cycle: 46.314\n",
      "epoch:[594 / 1000] batch:[30 / 134] loss= 0.026\n",
      "epoch:[594 / 1000] batch:[60 / 134] loss= 0.044\n",
      "epoch:[594 / 1000] batch:[90 / 134] loss= 0.015\n",
      "epoch:[594 / 1000] batch:[120 / 134] loss= 0.024\n",
      "100 cycles trn_loss: 0.031, val_loss: 0.129, lr=3.520366e-05\n",
      "training set RMSE 1 cycle: 31.782, 10 cycle: 24.543, 100 cycle: 23.525\n",
      "testing set RMSE 1 cycle: 49.890, 10 cycle: 47.121, 100 cycle: 47.382\n",
      "epoch:[595 / 1000] batch:[30 / 134] loss= 0.026\n",
      "epoch:[595 / 1000] batch:[60 / 134] loss= 0.043\n",
      "epoch:[595 / 1000] batch:[90 / 134] loss= 0.019\n",
      "epoch:[595 / 1000] batch:[120 / 134] loss= 0.036\n",
      "100 cycles trn_loss: 0.032, val_loss: 0.136, lr=5.050000e-05\n",
      "training set RMSE 1 cycle: 27.724, 10 cycle: 23.375, 100 cycle: 23.653\n",
      "testing set RMSE 1 cycle: 46.401, 10 cycle: 48.110, 100 cycle: 48.736\n",
      "epoch:[596 / 1000] batch:[30 / 134] loss= 0.074\n",
      "epoch:[596 / 1000] batch:[60 / 134] loss= 0.024\n",
      "epoch:[596 / 1000] batch:[90 / 134] loss= 0.020\n",
      "epoch:[596 / 1000] batch:[120 / 134] loss= 0.067\n",
      "100 cycles trn_loss: 0.023, val_loss: 0.131, lr=6.579634e-05\n",
      "training set RMSE 1 cycle: 36.004, 10 cycle: 28.694, 100 cycle: 20.084\n",
      "testing set RMSE 1 cycle: 53.188, 10 cycle: 51.920, 100 cycle: 48.220\n",
      "epoch:[597 / 1000] batch:[30 / 134] loss= 0.016\n",
      "epoch:[597 / 1000] batch:[60 / 134] loss= 0.086\n",
      "epoch:[597 / 1000] batch:[90 / 134] loss= 0.039\n",
      "epoch:[597 / 1000] batch:[120 / 134] loss= 0.018\n",
      "100 cycles trn_loss: 0.025, val_loss: 0.116, lr=7.959537e-05\n",
      "training set RMSE 1 cycle: 31.876, 10 cycle: 24.277, 100 cycle: 21.306\n",
      "testing set RMSE 1 cycle: 47.566, 10 cycle: 45.222, 100 cycle: 45.293\n",
      "epoch:[598 / 1000] batch:[30 / 134] loss= 0.216\n",
      "epoch:[598 / 1000] batch:[60 / 134] loss= 0.096\n",
      "epoch:[598 / 1000] batch:[90 / 134] loss= 0.062\n",
      "epoch:[598 / 1000] batch:[120 / 134] loss= 0.034\n",
      "100 cycles trn_loss: 0.038, val_loss: 0.151, lr=9.054634e-05\n",
      "training set RMSE 1 cycle: 40.524, 10 cycle: 36.538, 100 cycle: 25.574\n",
      "testing set RMSE 1 cycle: 53.031, 10 cycle: 56.110, 100 cycle: 52.414\n",
      "epoch:[599 / 1000] batch:[30 / 134] loss= 0.137\n",
      "epoch:[599 / 1000] batch:[60 / 134] loss= 0.110\n",
      "epoch:[599 / 1000] batch:[90 / 134] loss= 0.097\n",
      "epoch:[599 / 1000] batch:[120 / 134] loss= 0.016\n",
      "100 cycles trn_loss: 0.079, val_loss: 0.163, lr=9.757730e-05\n",
      "training set RMSE 1 cycle: 37.536, 10 cycle: 36.799, 100 cycle: 37.679\n",
      "testing set RMSE 1 cycle: 48.654, 10 cycle: 53.444, 100 cycle: 53.451\n",
      "epoch:[600 / 1000] batch:[30 / 134] loss= 0.065\n",
      "epoch:[600 / 1000] batch:[60 / 134] loss= 0.038\n",
      "epoch:[600 / 1000] batch:[90 / 134] loss= 0.061\n",
      "epoch:[600 / 1000] batch:[120 / 134] loss= 0.115\n",
      "100 cycles trn_loss: 0.157, val_loss: 0.265, lr=1.000000e-04\n",
      "training set RMSE 1 cycle: 71.660, 10 cycle: 68.282, 100 cycle: 58.848\n",
      "testing set RMSE 1 cycle: 71.098, 10 cycle: 76.566, 100 cycle: 74.600\n",
      "epoch:[601 / 1000] batch:[30 / 134] loss= 0.224\n",
      "epoch:[601 / 1000] batch:[60 / 134] loss= 0.082\n",
      "epoch:[601 / 1000] batch:[90 / 134] loss= 0.094\n",
      "epoch:[601 / 1000] batch:[120 / 134] loss= 0.066\n",
      "100 cycles trn_loss: 0.039, val_loss: 0.104, lr=9.757730e-05\n",
      "training set RMSE 1 cycle: 29.912, 10 cycle: 27.268, 100 cycle: 26.662\n",
      "testing set RMSE 1 cycle: 46.326, 10 cycle: 44.059, 100 cycle: 42.404\n",
      "epoch:[602 / 1000] batch:[30 / 134] loss= 0.073\n",
      "epoch:[602 / 1000] batch:[60 / 134] loss= 0.094\n",
      "epoch:[602 / 1000] batch:[90 / 134] loss= 0.097\n",
      "epoch:[602 / 1000] batch:[120 / 134] loss= 0.040\n",
      "100 cycles trn_loss: 0.044, val_loss: 0.111, lr=9.054634e-05\n",
      "training set RMSE 1 cycle: 34.868, 10 cycle: 29.447, 100 cycle: 27.735\n",
      "testing set RMSE 1 cycle: 43.030, 10 cycle: 47.148, 100 cycle: 43.913\n",
      "epoch:[603 / 1000] batch:[30 / 134] loss= 0.035\n",
      "epoch:[603 / 1000] batch:[60 / 134] loss= 0.048\n",
      "epoch:[603 / 1000] batch:[90 / 134] loss= 0.029\n",
      "epoch:[603 / 1000] batch:[120 / 134] loss= 0.043\n",
      "100 cycles trn_loss: 0.041, val_loss: 0.136, lr=7.959537e-05\n",
      "training set RMSE 1 cycle: 48.643, 10 cycle: 43.731, 100 cycle: 26.600\n",
      "testing set RMSE 1 cycle: 58.505, 10 cycle: 58.067, 100 cycle: 50.555\n",
      "epoch:[604 / 1000] batch:[30 / 134] loss= 0.024\n",
      "epoch:[604 / 1000] batch:[60 / 134] loss= 0.039\n",
      "epoch:[604 / 1000] batch:[90 / 134] loss= 0.053\n",
      "epoch:[604 / 1000] batch:[120 / 134] loss= 0.094\n",
      "100 cycles trn_loss: 0.048, val_loss: 0.123, lr=6.579634e-05\n",
      "training set RMSE 1 cycle: 40.675, 10 cycle: 34.449, 100 cycle: 29.323\n",
      "testing set RMSE 1 cycle: 46.713, 10 cycle: 49.321, 100 cycle: 46.170\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:[605 / 1000] batch:[30 / 134] loss= 0.022\n",
      "epoch:[605 / 1000] batch:[60 / 134] loss= 0.026\n",
      "epoch:[605 / 1000] batch:[90 / 134] loss= 0.030\n",
      "epoch:[605 / 1000] batch:[120 / 134] loss= 0.090\n",
      "100 cycles trn_loss: 0.028, val_loss: 0.114, lr=5.050000e-05\n",
      "training set RMSE 1 cycle: 32.372, 10 cycle: 27.336, 100 cycle: 22.230\n",
      "testing set RMSE 1 cycle: 50.589, 10 cycle: 47.139, 100 cycle: 44.885\n",
      "epoch:[606 / 1000] batch:[30 / 134] loss= 0.031\n",
      "epoch:[606 / 1000] batch:[60 / 134] loss= 0.020\n",
      "epoch:[606 / 1000] batch:[90 / 134] loss= 0.019\n",
      "epoch:[606 / 1000] batch:[120 / 134] loss= 0.041\n",
      "100 cycles trn_loss: 0.103, val_loss: 0.096, lr=3.520366e-05\n",
      "training set RMSE 1 cycle: 43.777, 10 cycle: 45.998, 100 cycle: 46.422\n",
      "testing set RMSE 1 cycle: 49.700, 10 cycle: 41.239, 100 cycle: 41.107\n",
      "epoch:[607 / 1000] batch:[30 / 134] loss= 0.022\n",
      "epoch:[607 / 1000] batch:[60 / 134] loss= 0.030\n",
      "epoch:[607 / 1000] batch:[90 / 134] loss= 0.017\n",
      "epoch:[607 / 1000] batch:[120 / 134] loss= 0.101\n",
      "100 cycles trn_loss: 0.026, val_loss: 0.130, lr=2.140463e-05\n",
      "training set RMSE 1 cycle: 25.466, 10 cycle: 20.793, 100 cycle: 21.286\n",
      "testing set RMSE 1 cycle: 44.656, 10 cycle: 48.900, 100 cycle: 47.498\n",
      "epoch:[608 / 1000] batch:[30 / 134] loss= 0.018\n",
      "epoch:[608 / 1000] batch:[60 / 134] loss= 0.042\n",
      "epoch:[608 / 1000] batch:[90 / 134] loss= 0.042\n",
      "epoch:[608 / 1000] batch:[120 / 134] loss= 0.017\n",
      "100 cycles trn_loss: 0.016, val_loss: 0.131, lr=1.045366e-05\n",
      "training set RMSE 1 cycle: 26.530, 10 cycle: 20.507, 100 cycle: 16.530\n",
      "testing set RMSE 1 cycle: 49.817, 10 cycle: 49.728, 100 cycle: 47.991\n",
      "epoch:[609 / 1000] batch:[30 / 134] loss= 0.017\n",
      "epoch:[609 / 1000] batch:[60 / 134] loss= 0.029\n",
      "epoch:[609 / 1000] batch:[90 / 134] loss= 0.011\n",
      "epoch:[609 / 1000] batch:[120 / 134] loss= 0.028\n",
      "100 cycles trn_loss: 0.016, val_loss: 0.128, lr=3.422702e-06\n",
      "training set RMSE 1 cycle: 24.853, 10 cycle: 17.502, 100 cycle: 16.673\n",
      "testing set RMSE 1 cycle: 48.005, 10 cycle: 47.679, 100 cycle: 47.133\n",
      "epoch:[610 / 1000] batch:[30 / 134] loss= 0.022\n",
      "epoch:[610 / 1000] batch:[60 / 134] loss= 0.020\n",
      "epoch:[610 / 1000] batch:[90 / 134] loss= 0.024\n",
      "epoch:[610 / 1000] batch:[120 / 134] loss= 0.023\n",
      "100 cycles trn_loss: 0.014, val_loss: 0.125, lr=1.000000e-06\n",
      "training set RMSE 1 cycle: 26.166, 10 cycle: 17.972, 100 cycle: 15.487\n",
      "testing set RMSE 1 cycle: 48.658, 10 cycle: 47.270, 100 cycle: 46.674\n",
      "epoch:[611 / 1000] batch:[30 / 134] loss= 0.013\n",
      "epoch:[611 / 1000] batch:[60 / 134] loss= 0.019\n",
      "epoch:[611 / 1000] batch:[90 / 134] loss= 0.015\n",
      "epoch:[611 / 1000] batch:[120 / 134] loss= 0.025\n",
      "100 cycles trn_loss: 0.014, val_loss: 0.125, lr=3.422702e-06\n",
      "training set RMSE 1 cycle: 25.581, 10 cycle: 17.604, 100 cycle: 15.813\n",
      "testing set RMSE 1 cycle: 48.689, 10 cycle: 47.100, 100 cycle: 46.681\n",
      "epoch:[612 / 1000] batch:[30 / 134] loss= 0.033\n",
      "epoch:[612 / 1000] batch:[60 / 134] loss= 0.027\n",
      "epoch:[612 / 1000] batch:[90 / 134] loss= 0.013\n",
      "epoch:[612 / 1000] batch:[120 / 134] loss= 0.018\n",
      "100 cycles trn_loss: 0.016, val_loss: 0.126, lr=1.045366e-05\n",
      "training set RMSE 1 cycle: 25.280, 10 cycle: 17.415, 100 cycle: 16.426\n",
      "testing set RMSE 1 cycle: 48.270, 10 cycle: 47.141, 100 cycle: 46.725\n",
      "epoch:[613 / 1000] batch:[30 / 134] loss= 0.022\n",
      "epoch:[613 / 1000] batch:[60 / 134] loss= 0.014\n",
      "epoch:[613 / 1000] batch:[90 / 134] loss= 0.027\n",
      "epoch:[613 / 1000] batch:[120 / 134] loss= 0.017\n",
      "100 cycles trn_loss: 0.012, val_loss: 0.125, lr=2.140463e-05\n",
      "training set RMSE 1 cycle: 26.978, 10 cycle: 18.443, 100 cycle: 14.640\n",
      "testing set RMSE 1 cycle: 49.050, 10 cycle: 47.332, 100 cycle: 46.589\n",
      "epoch:[614 / 1000] batch:[30 / 134] loss= 0.016\n",
      "epoch:[614 / 1000] batch:[60 / 134] loss= 0.013\n",
      "epoch:[614 / 1000] batch:[90 / 134] loss= 0.023\n",
      "epoch:[614 / 1000] batch:[120 / 134] loss= 0.021\n",
      "100 cycles trn_loss: 0.012, val_loss: 0.123, lr=3.520366e-05\n",
      "training set RMSE 1 cycle: 27.822, 10 cycle: 19.384, 100 cycle: 14.634\n",
      "testing set RMSE 1 cycle: 48.365, 10 cycle: 46.968, 100 cycle: 46.219\n",
      "epoch:[615 / 1000] batch:[30 / 134] loss= 0.021\n",
      "epoch:[615 / 1000] batch:[60 / 134] loss= 0.014\n",
      "epoch:[615 / 1000] batch:[90 / 134] loss= 0.037\n",
      "epoch:[615 / 1000] batch:[120 / 134] loss= 0.073\n",
      "100 cycles trn_loss: 0.016, val_loss: 0.130, lr=5.050000e-05\n",
      "training set RMSE 1 cycle: 25.840, 10 cycle: 16.928, 100 cycle: 16.734\n",
      "testing set RMSE 1 cycle: 47.973, 10 cycle: 47.349, 100 cycle: 47.403\n",
      "epoch:[616 / 1000] batch:[30 / 134] loss= 0.026\n",
      "epoch:[616 / 1000] batch:[60 / 134] loss= 0.018\n",
      "epoch:[616 / 1000] batch:[90 / 134] loss= 0.025\n",
      "epoch:[616 / 1000] batch:[120 / 134] loss= 0.033\n",
      "100 cycles trn_loss: 0.016, val_loss: 0.131, lr=6.579634e-05\n",
      "training set RMSE 1 cycle: 33.960, 10 cycle: 27.379, 100 cycle: 16.791\n",
      "testing set RMSE 1 cycle: 53.182, 10 cycle: 51.671, 100 cycle: 48.712\n",
      "epoch:[617 / 1000] batch:[30 / 134] loss= 0.030\n",
      "epoch:[617 / 1000] batch:[60 / 134] loss= 0.027\n",
      "epoch:[617 / 1000] batch:[90 / 134] loss= 0.029\n",
      "epoch:[617 / 1000] batch:[120 / 134] loss= 0.035\n",
      "100 cycles trn_loss: 0.059, val_loss: 0.145, lr=7.959537e-05\n",
      "training set RMSE 1 cycle: 28.730, 10 cycle: 31.334, 100 cycle: 33.055\n",
      "testing set RMSE 1 cycle: 45.929, 10 cycle: 49.315, 100 cycle: 50.373\n",
      "epoch:[618 / 1000] batch:[30 / 134] loss= 0.038\n",
      "epoch:[618 / 1000] batch:[60 / 134] loss= 0.053\n",
      "epoch:[618 / 1000] batch:[90 / 134] loss= 0.162\n",
      "epoch:[618 / 1000] batch:[120 / 134] loss= 0.062\n",
      "100 cycles trn_loss: 0.128, val_loss: 0.144, lr=9.054634e-05\n",
      "training set RMSE 1 cycle: 72.639, 10 cycle: 61.091, 100 cycle: 47.746\n",
      "testing set RMSE 1 cycle: 59.893, 10 cycle: 62.739, 100 cycle: 50.385\n",
      "epoch:[619 / 1000] batch:[30 / 134] loss= 0.049\n",
      "epoch:[619 / 1000] batch:[60 / 134] loss= 0.041\n",
      "epoch:[619 / 1000] batch:[90 / 134] loss= 0.042\n",
      "epoch:[619 / 1000] batch:[120 / 134] loss= 0.044\n",
      "100 cycles trn_loss: 0.028, val_loss: 0.134, lr=9.757730e-05\n",
      "training set RMSE 1 cycle: 23.983, 10 cycle: 21.429, 100 cycle: 22.141\n",
      "testing set RMSE 1 cycle: 48.402, 10 cycle: 49.699, 100 cycle: 48.214\n",
      "epoch:[620 / 1000] batch:[30 / 134] loss= 0.166\n",
      "epoch:[620 / 1000] batch:[60 / 134] loss= 0.093\n",
      "epoch:[620 / 1000] batch:[90 / 134] loss= 0.058\n",
      "epoch:[620 / 1000] batch:[120 / 134] loss= 0.117\n",
      "100 cycles trn_loss: 0.037, val_loss: 0.159, lr=1.000000e-04\n",
      "training set RMSE 1 cycle: 31.365, 10 cycle: 28.757, 100 cycle: 25.596\n",
      "testing set RMSE 1 cycle: 52.835, 10 cycle: 52.738, 100 cycle: 52.684\n",
      "epoch:[621 / 1000] batch:[30 / 134] loss= 0.087\n",
      "epoch:[621 / 1000] batch:[60 / 134] loss= 0.066\n",
      "epoch:[621 / 1000] batch:[90 / 134] loss= 0.045\n",
      "epoch:[621 / 1000] batch:[120 / 134] loss= 0.031\n",
      "100 cycles trn_loss: 0.044, val_loss: 0.133, lr=9.757730e-05\n",
      "training set RMSE 1 cycle: 54.103, 10 cycle: 48.302, 100 cycle: 27.471\n",
      "testing set RMSE 1 cycle: 63.561, 10 cycle: 61.154, 100 cycle: 50.812\n",
      "epoch:[622 / 1000] batch:[30 / 134] loss= 0.147\n",
      "epoch:[622 / 1000] batch:[60 / 134] loss= 0.170\n",
      "epoch:[622 / 1000] batch:[90 / 134] loss= 0.050\n",
      "epoch:[622 / 1000] batch:[120 / 134] loss= 0.137\n",
      "100 cycles trn_loss: 0.070, val_loss: 0.097, lr=9.054634e-05\n",
      "training set RMSE 1 cycle: 44.026, 10 cycle: 40.755, 100 cycle: 35.913\n",
      "testing set RMSE 1 cycle: 42.798, 10 cycle: 44.804, 100 cycle: 40.924\n",
      "epoch:[623 / 1000] batch:[30 / 134] loss= 0.117\n",
      "epoch:[623 / 1000] batch:[60 / 134] loss= 0.033\n",
      "epoch:[623 / 1000] batch:[90 / 134] loss= 0.064\n",
      "epoch:[623 / 1000] batch:[120 / 134] loss= 0.024\n",
      "100 cycles trn_loss: 0.182, val_loss: 0.253, lr=7.959537e-05\n",
      "training set RMSE 1 cycle: 69.504, 10 cycle: 65.981, 100 cycle: 64.245\n",
      "testing set RMSE 1 cycle: 77.300, 10 cycle: 72.140, 100 cycle: 72.712\n",
      "epoch:[624 / 1000] batch:[30 / 134] loss= 0.083\n",
      "epoch:[624 / 1000] batch:[60 / 134] loss= 0.066\n",
      "epoch:[624 / 1000] batch:[90 / 134] loss= 0.155\n",
      "epoch:[624 / 1000] batch:[120 / 134] loss= 0.112\n",
      "100 cycles trn_loss: 0.050, val_loss: 0.115, lr=6.579634e-05\n",
      "training set RMSE 1 cycle: 41.136, 10 cycle: 37.051, 100 cycle: 30.126\n",
      "testing set RMSE 1 cycle: 46.789, 10 cycle: 49.914, 100 cycle: 45.058\n",
      "epoch:[625 / 1000] batch:[30 / 134] loss= 0.025\n",
      "epoch:[625 / 1000] batch:[60 / 134] loss= 0.173\n",
      "epoch:[625 / 1000] batch:[90 / 134] loss= 0.063\n",
      "epoch:[625 / 1000] batch:[120 / 134] loss= 0.066\n",
      "100 cycles trn_loss: 0.048, val_loss: 0.122, lr=5.050000e-05\n",
      "training set RMSE 1 cycle: 36.389, 10 cycle: 33.734, 100 cycle: 29.179\n",
      "testing set RMSE 1 cycle: 48.499, 10 cycle: 49.395, 100 cycle: 46.104\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:[626 / 1000] batch:[30 / 134] loss= 0.057\n",
      "epoch:[626 / 1000] batch:[60 / 134] loss= 0.057\n",
      "epoch:[626 / 1000] batch:[90 / 134] loss= 0.099\n",
      "epoch:[626 / 1000] batch:[120 / 134] loss= 0.020\n",
      "100 cycles trn_loss: 0.041, val_loss: 0.114, lr=3.520366e-05\n",
      "training set RMSE 1 cycle: 37.218, 10 cycle: 30.270, 100 cycle: 26.901\n",
      "testing set RMSE 1 cycle: 47.499, 10 cycle: 47.683, 100 cycle: 44.825\n",
      "epoch:[627 / 1000] batch:[30 / 134] loss= 0.122\n",
      "epoch:[627 / 1000] batch:[60 / 134] loss= 0.039\n",
      "epoch:[627 / 1000] batch:[90 / 134] loss= 0.036\n",
      "epoch:[627 / 1000] batch:[120 / 134] loss= 0.045\n",
      "100 cycles trn_loss: 0.037, val_loss: 0.103, lr=2.140463e-05\n",
      "training set RMSE 1 cycle: 36.004, 10 cycle: 29.957, 100 cycle: 25.443\n",
      "testing set RMSE 1 cycle: 44.768, 10 cycle: 46.180, 100 cycle: 42.225\n",
      "epoch:[628 / 1000] batch:[30 / 134] loss= 0.050\n",
      "epoch:[628 / 1000] batch:[60 / 134] loss= 0.039\n",
      "epoch:[628 / 1000] batch:[90 / 134] loss= 0.015\n",
      "epoch:[628 / 1000] batch:[120 / 134] loss= 0.051\n",
      "100 cycles trn_loss: 0.033, val_loss: 0.098, lr=1.045366e-05\n",
      "training set RMSE 1 cycle: 37.281, 10 cycle: 29.888, 100 cycle: 23.921\n",
      "testing set RMSE 1 cycle: 48.226, 10 cycle: 45.695, 100 cycle: 41.741\n",
      "epoch:[629 / 1000] batch:[30 / 134] loss= 0.022\n",
      "epoch:[629 / 1000] batch:[60 / 134] loss= 0.039\n",
      "epoch:[629 / 1000] batch:[90 / 134] loss= 0.023\n",
      "epoch:[629 / 1000] batch:[120 / 134] loss= 0.037\n",
      "100 cycles trn_loss: 0.032, val_loss: 0.101, lr=3.422702e-06\n",
      "training set RMSE 1 cycle: 34.365, 10 cycle: 28.258, 100 cycle: 23.738\n",
      "testing set RMSE 1 cycle: 46.497, 10 cycle: 45.227, 100 cycle: 42.155\n",
      "epoch:[630 / 1000] batch:[30 / 134] loss= 0.069\n",
      "epoch:[630 / 1000] batch:[60 / 134] loss= 0.108\n",
      "epoch:[630 / 1000] batch:[90 / 134] loss= 0.051\n",
      "epoch:[630 / 1000] batch:[120 / 134] loss= 0.071\n",
      "100 cycles trn_loss: 0.032, val_loss: 0.104, lr=1.000000e-06\n",
      "training set RMSE 1 cycle: 33.554, 10 cycle: 27.561, 100 cycle: 23.696\n",
      "testing set RMSE 1 cycle: 46.942, 10 cycle: 45.499, 100 cycle: 42.796\n",
      "epoch:[631 / 1000] batch:[30 / 134] loss= 0.049\n",
      "epoch:[631 / 1000] batch:[60 / 134] loss= 0.045\n",
      "epoch:[631 / 1000] batch:[90 / 134] loss= 0.062\n",
      "epoch:[631 / 1000] batch:[120 / 134] loss= 0.034\n",
      "100 cycles trn_loss: 0.031, val_loss: 0.104, lr=3.422702e-06\n",
      "training set RMSE 1 cycle: 34.192, 10 cycle: 27.661, 100 cycle: 23.336\n",
      "testing set RMSE 1 cycle: 47.567, 10 cycle: 45.847, 100 cycle: 42.854\n",
      "epoch:[632 / 1000] batch:[30 / 134] loss= 0.072\n",
      "epoch:[632 / 1000] batch:[60 / 134] loss= 0.058\n",
      "epoch:[632 / 1000] batch:[90 / 134] loss= 0.038\n",
      "epoch:[632 / 1000] batch:[120 / 134] loss= 0.029\n",
      "100 cycles trn_loss: 0.031, val_loss: 0.103, lr=1.045366e-05\n",
      "training set RMSE 1 cycle: 34.585, 10 cycle: 27.706, 100 cycle: 23.048\n",
      "testing set RMSE 1 cycle: 46.754, 10 cycle: 45.837, 100 cycle: 42.457\n",
      "epoch:[633 / 1000] batch:[30 / 134] loss= 0.055\n",
      "epoch:[633 / 1000] batch:[60 / 134] loss= 0.076\n",
      "epoch:[633 / 1000] batch:[90 / 134] loss= 0.048\n",
      "epoch:[633 / 1000] batch:[120 / 134] loss= 0.023\n",
      "100 cycles trn_loss: 0.031, val_loss: 0.101, lr=2.140463e-05\n",
      "training set RMSE 1 cycle: 33.384, 10 cycle: 27.337, 100 cycle: 23.305\n",
      "testing set RMSE 1 cycle: 47.349, 10 cycle: 44.827, 100 cycle: 42.251\n",
      "epoch:[634 / 1000] batch:[30 / 134] loss= 0.045\n",
      "epoch:[634 / 1000] batch:[60 / 134] loss= 0.035\n",
      "epoch:[634 / 1000] batch:[90 / 134] loss= 0.028\n",
      "epoch:[634 / 1000] batch:[120 / 134] loss= 0.041\n",
      "100 cycles trn_loss: 0.030, val_loss: 0.107, lr=3.520366e-05\n",
      "training set RMSE 1 cycle: 33.317, 10 cycle: 26.334, 100 cycle: 22.784\n",
      "testing set RMSE 1 cycle: 47.491, 10 cycle: 45.813, 100 cycle: 43.239\n",
      "epoch:[635 / 1000] batch:[30 / 134] loss= 0.077\n",
      "epoch:[635 / 1000] batch:[60 / 134] loss= 0.067\n",
      "epoch:[635 / 1000] batch:[90 / 134] loss= 0.074\n",
      "epoch:[635 / 1000] batch:[120 / 134] loss= 0.092\n",
      "100 cycles trn_loss: 0.030, val_loss: 0.129, lr=5.050000e-05\n",
      "training set RMSE 1 cycle: 37.344, 10 cycle: 31.124, 100 cycle: 22.893\n",
      "testing set RMSE 1 cycle: 55.960, 10 cycle: 53.940, 100 cycle: 48.748\n",
      "epoch:[636 / 1000] batch:[30 / 134] loss= 0.069\n",
      "epoch:[636 / 1000] batch:[60 / 134] loss= 0.072\n",
      "epoch:[636 / 1000] batch:[90 / 134] loss= 0.044\n",
      "epoch:[636 / 1000] batch:[120 / 134] loss= 0.033\n",
      "100 cycles trn_loss: 0.061, val_loss: 0.094, lr=6.579634e-05\n",
      "training set RMSE 1 cycle: 35.421, 10 cycle: 33.685, 100 cycle: 33.678\n",
      "testing set RMSE 1 cycle: 41.901, 10 cycle: 40.671, 100 cycle: 40.406\n",
      "epoch:[637 / 1000] batch:[30 / 134] loss= 0.111\n",
      "epoch:[637 / 1000] batch:[60 / 134] loss= 0.072\n",
      "epoch:[637 / 1000] batch:[90 / 134] loss= 0.034\n",
      "epoch:[637 / 1000] batch:[120 / 134] loss= 0.089\n",
      "100 cycles trn_loss: 0.041, val_loss: 0.096, lr=7.959537e-05\n",
      "training set RMSE 1 cycle: 31.635, 10 cycle: 28.153, 100 cycle: 26.938\n",
      "testing set RMSE 1 cycle: 45.017, 10 cycle: 42.296, 100 cycle: 40.698\n",
      "epoch:[638 / 1000] batch:[30 / 134] loss= 0.052\n",
      "epoch:[638 / 1000] batch:[60 / 134] loss= 0.026\n",
      "epoch:[638 / 1000] batch:[90 / 134] loss= 0.075\n",
      "epoch:[638 / 1000] batch:[120 / 134] loss= 0.108\n",
      "100 cycles trn_loss: 0.074, val_loss: 0.111, lr=9.054634e-05\n",
      "training set RMSE 1 cycle: 39.795, 10 cycle: 39.459, 100 cycle: 37.472\n",
      "testing set RMSE 1 cycle: 42.735, 10 cycle: 44.678, 100 cycle: 43.809\n",
      "epoch:[639 / 1000] batch:[30 / 134] loss= 0.117\n",
      "epoch:[639 / 1000] batch:[60 / 134] loss= 0.080\n",
      "epoch:[639 / 1000] batch:[90 / 134] loss= 0.208\n",
      "epoch:[639 / 1000] batch:[120 / 134] loss= 0.081\n",
      "100 cycles trn_loss: 0.056, val_loss: 0.107, lr=9.757730e-05\n",
      "training set RMSE 1 cycle: 42.412, 10 cycle: 36.231, 100 cycle: 31.786\n",
      "testing set RMSE 1 cycle: 47.126, 10 cycle: 46.315, 100 cycle: 43.005\n",
      "epoch:[640 / 1000] batch:[30 / 134] loss= 0.041\n",
      "epoch:[640 / 1000] batch:[60 / 134] loss= 0.145\n",
      "epoch:[640 / 1000] batch:[90 / 134] loss= 0.135\n",
      "epoch:[640 / 1000] batch:[120 / 134] loss= 0.059\n",
      "100 cycles trn_loss: 0.032, val_loss: 0.110, lr=1.000000e-04\n",
      "training set RMSE 1 cycle: 30.633, 10 cycle: 25.842, 100 cycle: 23.583\n",
      "testing set RMSE 1 cycle: 50.420, 10 cycle: 44.613, 100 cycle: 43.639\n",
      "epoch:[641 / 1000] batch:[30 / 134] loss= 0.055\n",
      "epoch:[641 / 1000] batch:[60 / 134] loss= 0.036\n",
      "epoch:[641 / 1000] batch:[90 / 134] loss= 0.026\n",
      "epoch:[641 / 1000] batch:[120 / 134] loss= 0.082\n",
      "100 cycles trn_loss: 0.045, val_loss: 0.155, lr=9.757730e-05\n",
      "training set RMSE 1 cycle: 48.478, 10 cycle: 40.688, 100 cycle: 27.900\n",
      "testing set RMSE 1 cycle: 61.905, 10 cycle: 60.797, 100 cycle: 52.948\n",
      "epoch:[642 / 1000] batch:[30 / 134] loss= 0.087\n",
      "epoch:[642 / 1000] batch:[60 / 134] loss= 0.119\n",
      "epoch:[642 / 1000] batch:[90 / 134] loss= 0.109\n",
      "epoch:[642 / 1000] batch:[120 / 134] loss= 0.094\n",
      "100 cycles trn_loss: 0.051, val_loss: 0.142, lr=9.054634e-05\n",
      "training set RMSE 1 cycle: 53.326, 10 cycle: 44.725, 100 cycle: 29.824\n",
      "testing set RMSE 1 cycle: 62.005, 10 cycle: 64.845, 100 cycle: 51.945\n",
      "epoch:[643 / 1000] batch:[30 / 134] loss= 0.125\n",
      "epoch:[643 / 1000] batch:[60 / 134] loss= 0.116\n",
      "epoch:[643 / 1000] batch:[90 / 134] loss= 0.038\n",
      "epoch:[643 / 1000] batch:[120 / 134] loss= 0.020\n",
      "100 cycles trn_loss: 0.034, val_loss: 0.107, lr=7.959537e-05\n",
      "training set RMSE 1 cycle: 30.364, 10 cycle: 27.080, 100 cycle: 24.600\n",
      "testing set RMSE 1 cycle: 50.029, 10 cycle: 44.514, 100 cycle: 42.937\n",
      "epoch:[644 / 1000] batch:[30 / 134] loss= 0.051\n",
      "epoch:[644 / 1000] batch:[60 / 134] loss= 0.047\n",
      "epoch:[644 / 1000] batch:[90 / 134] loss= 0.073\n",
      "epoch:[644 / 1000] batch:[120 / 134] loss= 0.040\n",
      "100 cycles trn_loss: 0.028, val_loss: 0.143, lr=6.579634e-05\n",
      "training set RMSE 1 cycle: 33.111, 10 cycle: 26.427, 100 cycle: 22.162\n",
      "testing set RMSE 1 cycle: 53.979, 10 cycle: 53.535, 100 cycle: 50.287\n",
      "epoch:[645 / 1000] batch:[30 / 134] loss= 0.018\n",
      "epoch:[645 / 1000] batch:[60 / 134] loss= 0.031\n",
      "epoch:[645 / 1000] batch:[90 / 134] loss= 0.020\n",
      "epoch:[645 / 1000] batch:[120 / 134] loss= 0.099\n",
      "100 cycles trn_loss: 0.021, val_loss: 0.111, lr=5.050000e-05\n",
      "training set RMSE 1 cycle: 30.280, 10 cycle: 23.719, 100 cycle: 19.207\n",
      "testing set RMSE 1 cycle: 52.225, 10 cycle: 46.114, 100 cycle: 44.015\n",
      "epoch:[646 / 1000] batch:[30 / 134] loss= 0.020\n",
      "epoch:[646 / 1000] batch:[60 / 134] loss= 0.026\n",
      "epoch:[646 / 1000] batch:[90 / 134] loss= 0.014\n",
      "epoch:[646 / 1000] batch:[120 / 134] loss= 0.047\n",
      "100 cycles trn_loss: 0.022, val_loss: 0.152, lr=3.520366e-05\n",
      "training set RMSE 1 cycle: 29.112, 10 cycle: 24.149, 100 cycle: 19.298\n",
      "testing set RMSE 1 cycle: 58.711, 10 cycle: 54.359, 100 cycle: 51.788\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:[647 / 1000] batch:[30 / 134] loss= 0.033\n",
      "epoch:[647 / 1000] batch:[60 / 134] loss= 0.054\n",
      "epoch:[647 / 1000] batch:[90 / 134] loss= 0.034\n",
      "epoch:[647 / 1000] batch:[120 / 134] loss= 0.028\n",
      "100 cycles trn_loss: 0.022, val_loss: 0.117, lr=2.140463e-05\n",
      "training set RMSE 1 cycle: 28.353, 10 cycle: 22.138, 100 cycle: 19.711\n",
      "testing set RMSE 1 cycle: 51.198, 10 cycle: 46.465, 100 cycle: 45.038\n",
      "epoch:[648 / 1000] batch:[30 / 134] loss= 0.041\n",
      "epoch:[648 / 1000] batch:[60 / 134] loss= 0.030\n",
      "epoch:[648 / 1000] batch:[90 / 134] loss= 0.046\n",
      "epoch:[648 / 1000] batch:[120 / 134] loss= 0.023\n",
      "100 cycles trn_loss: 0.018, val_loss: 0.129, lr=1.045366e-05\n",
      "training set RMSE 1 cycle: 26.254, 10 cycle: 19.735, 100 cycle: 17.405\n",
      "testing set RMSE 1 cycle: 53.591, 10 cycle: 48.904, 100 cycle: 47.370\n",
      "epoch:[649 / 1000] batch:[30 / 134] loss= 0.021\n",
      "epoch:[649 / 1000] batch:[60 / 134] loss= 0.018\n",
      "epoch:[649 / 1000] batch:[90 / 134] loss= 0.027\n",
      "epoch:[649 / 1000] batch:[120 / 134] loss= 0.032\n",
      "100 cycles trn_loss: 0.019, val_loss: 0.127, lr=3.422702e-06\n",
      "training set RMSE 1 cycle: 25.426, 10 cycle: 19.850, 100 cycle: 18.127\n",
      "testing set RMSE 1 cycle: 52.765, 10 cycle: 48.265, 100 cycle: 46.909\n",
      "epoch:[650 / 1000] batch:[30 / 134] loss= 0.034\n",
      "epoch:[650 / 1000] batch:[60 / 134] loss= 0.023\n",
      "epoch:[650 / 1000] batch:[90 / 134] loss= 0.037\n",
      "epoch:[650 / 1000] batch:[120 / 134] loss= 0.015\n",
      "100 cycles trn_loss: 0.016, val_loss: 0.129, lr=1.000000e-06\n",
      "training set RMSE 1 cycle: 26.465, 10 cycle: 19.745, 100 cycle: 16.620\n",
      "testing set RMSE 1 cycle: 53.971, 10 cycle: 49.090, 100 cycle: 47.517\n",
      "epoch:[651 / 1000] batch:[30 / 134] loss= 0.028\n",
      "epoch:[651 / 1000] batch:[60 / 134] loss= 0.028\n",
      "epoch:[651 / 1000] batch:[90 / 134] loss= 0.009\n",
      "epoch:[651 / 1000] batch:[120 / 134] loss= 0.029\n",
      "100 cycles trn_loss: 0.014, val_loss: 0.130, lr=3.422702e-06\n",
      "training set RMSE 1 cycle: 27.867, 10 cycle: 20.424, 100 cycle: 15.638\n",
      "testing set RMSE 1 cycle: 54.869, 10 cycle: 49.623, 100 cycle: 47.876\n",
      "epoch:[652 / 1000] batch:[30 / 134] loss= 0.019\n",
      "epoch:[652 / 1000] batch:[60 / 134] loss= 0.026\n",
      "epoch:[652 / 1000] batch:[90 / 134] loss= 0.017\n",
      "epoch:[652 / 1000] batch:[120 / 134] loss= 0.021\n",
      "100 cycles trn_loss: 0.015, val_loss: 0.129, lr=1.045366e-05\n",
      "training set RMSE 1 cycle: 27.577, 10 cycle: 20.095, 100 cycle: 15.891\n",
      "testing set RMSE 1 cycle: 54.635, 10 cycle: 49.095, 100 cycle: 47.543\n",
      "epoch:[653 / 1000] batch:[30 / 134] loss= 0.013\n",
      "epoch:[653 / 1000] batch:[60 / 134] loss= 0.019\n",
      "epoch:[653 / 1000] batch:[90 / 134] loss= 0.025\n",
      "epoch:[653 / 1000] batch:[120 / 134] loss= 0.015\n",
      "100 cycles trn_loss: 0.014, val_loss: 0.130, lr=2.140463e-05\n",
      "training set RMSE 1 cycle: 28.800, 10 cycle: 21.360, 100 cycle: 15.443\n",
      "testing set RMSE 1 cycle: 56.484, 10 cycle: 49.884, 100 cycle: 48.071\n",
      "epoch:[654 / 1000] batch:[30 / 134] loss= 0.050\n",
      "epoch:[654 / 1000] batch:[60 / 134] loss= 0.017\n",
      "epoch:[654 / 1000] batch:[90 / 134] loss= 0.028\n",
      "epoch:[654 / 1000] batch:[120 / 134] loss= 0.020\n",
      "100 cycles trn_loss: 0.031, val_loss: 0.118, lr=3.520366e-05\n",
      "training set RMSE 1 cycle: 25.726, 10 cycle: 23.264, 100 cycle: 23.660\n",
      "testing set RMSE 1 cycle: 50.188, 10 cycle: 45.654, 100 cycle: 45.247\n",
      "epoch:[655 / 1000] batch:[30 / 134] loss= 0.031\n",
      "epoch:[655 / 1000] batch:[60 / 134] loss= 0.023\n",
      "epoch:[655 / 1000] batch:[90 / 134] loss= 0.042\n",
      "epoch:[655 / 1000] batch:[120 / 134] loss= 0.020\n",
      "100 cycles trn_loss: 0.018, val_loss: 0.151, lr=5.050000e-05\n",
      "training set RMSE 1 cycle: 31.472, 10 cycle: 24.306, 100 cycle: 17.882\n",
      "testing set RMSE 1 cycle: 58.322, 10 cycle: 54.260, 100 cycle: 51.836\n",
      "epoch:[656 / 1000] batch:[30 / 134] loss= 0.048\n",
      "epoch:[656 / 1000] batch:[60 / 134] loss= 0.034\n",
      "epoch:[656 / 1000] batch:[90 / 134] loss= 0.021\n",
      "epoch:[656 / 1000] batch:[120 / 134] loss= 0.050\n",
      "100 cycles trn_loss: 0.015, val_loss: 0.151, lr=6.579634e-05\n",
      "training set RMSE 1 cycle: 32.072, 10 cycle: 23.715, 100 cycle: 16.247\n",
      "testing set RMSE 1 cycle: 56.544, 10 cycle: 54.732, 100 cycle: 51.797\n",
      "epoch:[657 / 1000] batch:[30 / 134] loss= 0.069\n",
      "epoch:[657 / 1000] batch:[60 / 134] loss= 0.067\n",
      "epoch:[657 / 1000] batch:[90 / 134] loss= 0.103\n",
      "epoch:[657 / 1000] batch:[120 / 134] loss= 0.099\n",
      "100 cycles trn_loss: 0.121, val_loss: 0.136, lr=7.959537e-05\n",
      "training set RMSE 1 cycle: 44.533, 10 cycle: 48.913, 100 cycle: 49.693\n",
      "testing set RMSE 1 cycle: 44.833, 10 cycle: 46.836, 100 cycle: 49.295\n",
      "epoch:[658 / 1000] batch:[30 / 134] loss= 0.111\n",
      "epoch:[658 / 1000] batch:[60 / 134] loss= 0.064\n",
      "epoch:[658 / 1000] batch:[90 / 134] loss= 0.065\n",
      "epoch:[658 / 1000] batch:[120 / 134] loss= 0.017\n",
      "100 cycles trn_loss: 0.031, val_loss: 0.108, lr=9.054634e-05\n",
      "training set RMSE 1 cycle: 47.260, 10 cycle: 36.946, 100 cycle: 23.054\n",
      "testing set RMSE 1 cycle: 53.660, 10 cycle: 52.183, 100 cycle: 44.662\n",
      "epoch:[659 / 1000] batch:[30 / 134] loss= 0.019\n",
      "epoch:[659 / 1000] batch:[60 / 134] loss= 0.186\n",
      "epoch:[659 / 1000] batch:[90 / 134] loss= 0.164\n",
      "epoch:[659 / 1000] batch:[120 / 134] loss= 0.093\n",
      "100 cycles trn_loss: 0.058, val_loss: 0.166, lr=9.757730e-05\n",
      "training set RMSE 1 cycle: 45.898, 10 cycle: 42.351, 100 cycle: 31.801\n",
      "testing set RMSE 1 cycle: 63.194, 10 cycle: 58.817, 100 cycle: 55.665\n",
      "epoch:[660 / 1000] batch:[30 / 134] loss= 0.091\n",
      "epoch:[660 / 1000] batch:[60 / 134] loss= 0.024\n",
      "epoch:[660 / 1000] batch:[90 / 134] loss= 0.126\n",
      "epoch:[660 / 1000] batch:[120 / 134] loss= 0.087\n",
      "100 cycles trn_loss: 0.090, val_loss: 0.128, lr=1.000000e-04\n",
      "training set RMSE 1 cycle: 41.789, 10 cycle: 41.637, 100 cycle: 42.660\n",
      "testing set RMSE 1 cycle: 45.180, 10 cycle: 44.674, 100 cycle: 47.730\n",
      "epoch:[661 / 1000] batch:[30 / 134] loss= 0.068\n",
      "epoch:[661 / 1000] batch:[60 / 134] loss= 0.028\n",
      "epoch:[661 / 1000] batch:[90 / 134] loss= 0.062\n",
      "epoch:[661 / 1000] batch:[120 / 134] loss= 0.121\n",
      "100 cycles trn_loss: 0.037, val_loss: 0.141, lr=9.757730e-05\n",
      "training set RMSE 1 cycle: 42.772, 10 cycle: 31.062, 100 cycle: 25.502\n",
      "testing set RMSE 1 cycle: 55.696, 10 cycle: 50.910, 100 cycle: 50.219\n",
      "epoch:[662 / 1000] batch:[30 / 134] loss= 0.035\n",
      "epoch:[662 / 1000] batch:[60 / 134] loss= 0.159\n",
      "epoch:[662 / 1000] batch:[90 / 134] loss= 0.037\n",
      "epoch:[662 / 1000] batch:[120 / 134] loss= 0.029\n",
      "100 cycles trn_loss: 0.049, val_loss: 0.166, lr=9.054634e-05\n",
      "training set RMSE 1 cycle: 49.495, 10 cycle: 44.151, 100 cycle: 29.231\n",
      "testing set RMSE 1 cycle: 61.584, 10 cycle: 63.045, 100 cycle: 56.686\n",
      "epoch:[663 / 1000] batch:[30 / 134] loss= 0.238\n",
      "epoch:[663 / 1000] batch:[60 / 134] loss= 0.269\n",
      "epoch:[663 / 1000] batch:[90 / 134] loss= 0.063\n",
      "epoch:[663 / 1000] batch:[120 / 134] loss= 0.194\n",
      "100 cycles trn_loss: 0.059, val_loss: 0.191, lr=7.959537e-05\n",
      "training set RMSE 1 cycle: 43.760, 10 cycle: 34.586, 100 cycle: 32.449\n",
      "testing set RMSE 1 cycle: 57.635, 10 cycle: 59.073, 100 cycle: 57.633\n",
      "epoch:[664 / 1000] batch:[30 / 134] loss= 0.057\n",
      "epoch:[664 / 1000] batch:[60 / 134] loss= 0.047\n",
      "epoch:[664 / 1000] batch:[90 / 134] loss= 0.070\n",
      "epoch:[664 / 1000] batch:[120 / 134] loss= 0.078\n",
      "100 cycles trn_loss: 0.030, val_loss: 0.131, lr=6.579634e-05\n",
      "training set RMSE 1 cycle: 44.937, 10 cycle: 36.479, 100 cycle: 22.681\n",
      "testing set RMSE 1 cycle: 56.681, 10 cycle: 55.992, 100 cycle: 48.477\n",
      "epoch:[665 / 1000] batch:[30 / 134] loss= 0.023\n",
      "epoch:[665 / 1000] batch:[60 / 134] loss= 0.080\n",
      "epoch:[665 / 1000] batch:[90 / 134] loss= 0.085\n",
      "epoch:[665 / 1000] batch:[120 / 134] loss= 0.045\n",
      "100 cycles trn_loss: 0.018, val_loss: 0.148, lr=5.050000e-05\n",
      "training set RMSE 1 cycle: 31.886, 10 cycle: 24.916, 100 cycle: 17.486\n",
      "testing set RMSE 1 cycle: 55.908, 10 cycle: 54.393, 100 cycle: 51.203\n",
      "epoch:[666 / 1000] batch:[30 / 134] loss= 0.029\n",
      "epoch:[666 / 1000] batch:[60 / 134] loss= 0.036\n",
      "epoch:[666 / 1000] batch:[90 / 134] loss= 0.019\n",
      "epoch:[666 / 1000] batch:[120 / 134] loss= 0.023\n",
      "100 cycles trn_loss: 0.018, val_loss: 0.148, lr=3.520366e-05\n",
      "training set RMSE 1 cycle: 43.449, 10 cycle: 31.531, 100 cycle: 17.476\n",
      "testing set RMSE 1 cycle: 59.109, 10 cycle: 56.058, 100 cycle: 52.203\n",
      "epoch:[667 / 1000] batch:[30 / 134] loss= 0.025\n",
      "epoch:[667 / 1000] batch:[60 / 134] loss= 0.028\n",
      "epoch:[667 / 1000] batch:[90 / 134] loss= 0.011\n",
      "epoch:[667 / 1000] batch:[120 / 134] loss= 0.021\n",
      "100 cycles trn_loss: 0.013, val_loss: 0.138, lr=2.140463e-05\n",
      "training set RMSE 1 cycle: 32.110, 10 cycle: 22.179, 100 cycle: 14.821\n",
      "testing set RMSE 1 cycle: 53.837, 10 cycle: 52.126, 100 cycle: 49.348\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:[668 / 1000] batch:[30 / 134] loss= 0.041\n",
      "epoch:[668 / 1000] batch:[60 / 134] loss= 0.018\n",
      "epoch:[668 / 1000] batch:[90 / 134] loss= 0.023\n",
      "epoch:[668 / 1000] batch:[120 / 134] loss= 0.015\n",
      "100 cycles trn_loss: 0.014, val_loss: 0.138, lr=1.045366e-05\n",
      "training set RMSE 1 cycle: 26.270, 10 cycle: 17.958, 100 cycle: 15.339\n",
      "testing set RMSE 1 cycle: 53.778, 10 cycle: 51.277, 100 cycle: 49.306\n",
      "epoch:[669 / 1000] batch:[30 / 134] loss= 0.016\n",
      "epoch:[669 / 1000] batch:[60 / 134] loss= 0.023\n",
      "epoch:[669 / 1000] batch:[90 / 134] loss= 0.037\n",
      "epoch:[669 / 1000] batch:[120 / 134] loss= 0.019\n",
      "100 cycles trn_loss: 0.011, val_loss: 0.141, lr=3.422702e-06\n",
      "training set RMSE 1 cycle: 27.970, 10 cycle: 18.529, 100 cycle: 14.044\n",
      "testing set RMSE 1 cycle: 53.950, 10 cycle: 52.021, 100 cycle: 49.971\n",
      "epoch:[670 / 1000] batch:[30 / 134] loss= 0.023\n",
      "epoch:[670 / 1000] batch:[60 / 134] loss= 0.015\n",
      "epoch:[670 / 1000] batch:[90 / 134] loss= 0.015\n",
      "epoch:[670 / 1000] batch:[120 / 134] loss= 0.010\n",
      "100 cycles trn_loss: 0.013, val_loss: 0.139, lr=1.000000e-06\n",
      "training set RMSE 1 cycle: 26.012, 10 cycle: 16.973, 100 cycle: 14.982\n",
      "testing set RMSE 1 cycle: 53.385, 10 cycle: 51.269, 100 cycle: 49.451\n",
      "epoch:[671 / 1000] batch:[30 / 134] loss= 0.023\n",
      "epoch:[671 / 1000] batch:[60 / 134] loss= 0.006\n",
      "epoch:[671 / 1000] batch:[90 / 134] loss= 0.031\n",
      "epoch:[671 / 1000] batch:[120 / 134] loss= 0.012\n",
      "100 cycles trn_loss: 0.012, val_loss: 0.141, lr=3.422702e-06\n",
      "training set RMSE 1 cycle: 26.434, 10 cycle: 17.364, 100 cycle: 14.294\n",
      "testing set RMSE 1 cycle: 54.262, 10 cycle: 51.609, 100 cycle: 49.772\n",
      "epoch:[672 / 1000] batch:[30 / 134] loss= 0.034\n",
      "epoch:[672 / 1000] batch:[60 / 134] loss= 0.018\n",
      "epoch:[672 / 1000] batch:[90 / 134] loss= 0.021\n",
      "epoch:[672 / 1000] batch:[120 / 134] loss= 0.025\n",
      "100 cycles trn_loss: 0.014, val_loss: 0.136, lr=1.045366e-05\n",
      "training set RMSE 1 cycle: 25.178, 10 cycle: 16.948, 100 cycle: 15.706\n",
      "testing set RMSE 1 cycle: 53.505, 10 cycle: 50.402, 100 cycle: 48.699\n",
      "epoch:[673 / 1000] batch:[30 / 134] loss= 0.026\n",
      "epoch:[673 / 1000] batch:[60 / 134] loss= 0.013\n",
      "epoch:[673 / 1000] batch:[90 / 134] loss= 0.019\n",
      "epoch:[673 / 1000] batch:[120 / 134] loss= 0.013\n",
      "100 cycles trn_loss: 0.013, val_loss: 0.142, lr=2.140463e-05\n",
      "training set RMSE 1 cycle: 25.043, 10 cycle: 16.744, 100 cycle: 14.832\n",
      "testing set RMSE 1 cycle: 54.315, 10 cycle: 51.909, 100 cycle: 49.910\n",
      "epoch:[674 / 1000] batch:[30 / 134] loss= 0.033\n",
      "epoch:[674 / 1000] batch:[60 / 134] loss= 0.017\n",
      "epoch:[674 / 1000] batch:[90 / 134] loss= 0.038\n",
      "epoch:[674 / 1000] batch:[120 / 134] loss= 0.020\n",
      "100 cycles trn_loss: 0.017, val_loss: 0.139, lr=3.520366e-05\n",
      "training set RMSE 1 cycle: 27.659, 10 cycle: 18.198, 100 cycle: 17.199\n",
      "testing set RMSE 1 cycle: 52.820, 10 cycle: 50.951, 100 cycle: 49.201\n",
      "epoch:[675 / 1000] batch:[30 / 134] loss= 0.015\n",
      "epoch:[675 / 1000] batch:[60 / 134] loss= 0.017\n",
      "epoch:[675 / 1000] batch:[90 / 134] loss= 0.021\n",
      "epoch:[675 / 1000] batch:[120 / 134] loss= 0.028\n",
      "100 cycles trn_loss: 0.017, val_loss: 0.155, lr=5.050000e-05\n",
      "training set RMSE 1 cycle: 25.198, 10 cycle: 19.002, 100 cycle: 16.906\n",
      "testing set RMSE 1 cycle: 55.452, 10 cycle: 54.801, 100 cycle: 52.160\n",
      "epoch:[676 / 1000] batch:[30 / 134] loss= 0.009\n",
      "epoch:[676 / 1000] batch:[60 / 134] loss= 0.048\n",
      "epoch:[676 / 1000] batch:[90 / 134] loss= 0.042\n",
      "epoch:[676 / 1000] batch:[120 / 134] loss= 0.018\n",
      "100 cycles trn_loss: 0.045, val_loss: 0.105, lr=6.579634e-05\n",
      "training set RMSE 1 cycle: 29.992, 10 cycle: 28.573, 100 cycle: 28.895\n",
      "testing set RMSE 1 cycle: 43.924, 10 cycle: 43.486, 100 cycle: 42.780\n",
      "epoch:[677 / 1000] batch:[30 / 134] loss= 0.044\n",
      "epoch:[677 / 1000] batch:[60 / 134] loss= 0.020\n",
      "epoch:[677 / 1000] batch:[90 / 134] loss= 0.069\n",
      "epoch:[677 / 1000] batch:[120 / 134] loss= 0.036\n",
      "100 cycles trn_loss: 0.113, val_loss: 0.145, lr=7.959537e-05\n",
      "training set RMSE 1 cycle: 40.997, 10 cycle: 47.722, 100 cycle: 47.380\n",
      "testing set RMSE 1 cycle: 47.309, 10 cycle: 48.613, 100 cycle: 50.449\n",
      "epoch:[678 / 1000] batch:[30 / 134] loss= 0.182\n",
      "epoch:[678 / 1000] batch:[60 / 134] loss= 0.033\n",
      "epoch:[678 / 1000] batch:[90 / 134] loss= 0.124\n",
      "epoch:[678 / 1000] batch:[120 / 134] loss= 0.074\n",
      "100 cycles trn_loss: 0.087, val_loss: 0.142, lr=9.054634e-05\n",
      "training set RMSE 1 cycle: 48.343, 10 cycle: 43.294, 100 cycle: 41.453\n",
      "testing set RMSE 1 cycle: 51.499, 10 cycle: 47.450, 100 cycle: 49.630\n",
      "epoch:[679 / 1000] batch:[30 / 134] loss= 0.086\n",
      "epoch:[679 / 1000] batch:[60 / 134] loss= 0.030\n",
      "epoch:[679 / 1000] batch:[90 / 134] loss= 0.229\n",
      "epoch:[679 / 1000] batch:[120 / 134] loss= 0.054\n",
      "100 cycles trn_loss: 0.068, val_loss: 0.116, lr=9.757730e-05\n",
      "training set RMSE 1 cycle: 43.991, 10 cycle: 41.230, 100 cycle: 36.769\n",
      "testing set RMSE 1 cycle: 53.134, 10 cycle: 44.165, 100 cycle: 44.750\n",
      "epoch:[680 / 1000] batch:[30 / 134] loss= 0.102\n",
      "epoch:[680 / 1000] batch:[60 / 134] loss= 0.034\n",
      "epoch:[680 / 1000] batch:[90 / 134] loss= 0.148\n",
      "epoch:[680 / 1000] batch:[120 / 134] loss= 0.074\n",
      "100 cycles trn_loss: 0.090, val_loss: 0.146, lr=1.000000e-04\n",
      "training set RMSE 1 cycle: 41.410, 10 cycle: 42.742, 100 cycle: 42.285\n",
      "testing set RMSE 1 cycle: 54.469, 10 cycle: 47.245, 100 cycle: 50.274\n",
      "epoch:[681 / 1000] batch:[30 / 134] loss= 0.174\n",
      "epoch:[681 / 1000] batch:[60 / 134] loss= 0.057\n",
      "epoch:[681 / 1000] batch:[90 / 134] loss= 0.076\n",
      "epoch:[681 / 1000] batch:[120 / 134] loss= 0.064\n",
      "100 cycles trn_loss: 0.066, val_loss: 0.088, lr=9.757730e-05\n",
      "training set RMSE 1 cycle: 40.786, 10 cycle: 37.513, 100 cycle: 35.866\n",
      "testing set RMSE 1 cycle: 41.794, 10 cycle: 39.452, 100 cycle: 39.091\n",
      "epoch:[682 / 1000] batch:[30 / 134] loss= 0.045\n",
      "epoch:[682 / 1000] batch:[60 / 134] loss= 0.077\n",
      "epoch:[682 / 1000] batch:[90 / 134] loss= 0.088\n",
      "epoch:[682 / 1000] batch:[120 / 134] loss= 0.069\n",
      "100 cycles trn_loss: 0.046, val_loss: 0.071, lr=9.054634e-05\n",
      "training set RMSE 1 cycle: 43.067, 10 cycle: 35.162, 100 cycle: 29.138\n",
      "testing set RMSE 1 cycle: 40.631, 10 cycle: 40.067, 100 cycle: 35.017\n",
      "epoch:[683 / 1000] batch:[30 / 134] loss= 0.030\n",
      "epoch:[683 / 1000] batch:[60 / 134] loss= 0.038\n",
      "epoch:[683 / 1000] batch:[90 / 134] loss= 0.100\n",
      "epoch:[683 / 1000] batch:[120 / 134] loss= 0.056\n",
      "100 cycles trn_loss: 0.043, val_loss: 0.090, lr=7.959537e-05\n",
      "training set RMSE 1 cycle: 35.672, 10 cycle: 32.331, 100 cycle: 27.789\n",
      "testing set RMSE 1 cycle: 42.312, 10 cycle: 43.694, 100 cycle: 39.580\n",
      "epoch:[684 / 1000] batch:[30 / 134] loss= 0.025\n",
      "epoch:[684 / 1000] batch:[60 / 134] loss= 0.076\n",
      "epoch:[684 / 1000] batch:[90 / 134] loss= 0.064\n",
      "epoch:[684 / 1000] batch:[120 / 134] loss= 0.031\n",
      "100 cycles trn_loss: 0.061, val_loss: 0.087, lr=6.579634e-05\n",
      "training set RMSE 1 cycle: 35.559, 10 cycle: 33.476, 100 cycle: 33.928\n",
      "testing set RMSE 1 cycle: 43.038, 10 cycle: 37.232, 100 cycle: 39.095\n",
      "epoch:[685 / 1000] batch:[30 / 134] loss= 0.058\n",
      "epoch:[685 / 1000] batch:[60 / 134] loss= 0.145\n",
      "epoch:[685 / 1000] batch:[90 / 134] loss= 0.023\n",
      "epoch:[685 / 1000] batch:[120 / 134] loss= 0.064\n",
      "100 cycles trn_loss: 0.042, val_loss: 0.100, lr=5.050000e-05\n",
      "training set RMSE 1 cycle: 46.732, 10 cycle: 42.333, 100 cycle: 26.806\n",
      "testing set RMSE 1 cycle: 57.978, 10 cycle: 53.057, 100 cycle: 41.831\n",
      "epoch:[686 / 1000] batch:[30 / 134] loss= 0.047\n",
      "epoch:[686 / 1000] batch:[60 / 134] loss= 0.075\n",
      "epoch:[686 / 1000] batch:[90 / 134] loss= 0.082\n",
      "epoch:[686 / 1000] batch:[120 / 134] loss= 0.062\n",
      "100 cycles trn_loss: 0.032, val_loss: 0.076, lr=3.520366e-05\n",
      "training set RMSE 1 cycle: 38.680, 10 cycle: 32.566, 100 cycle: 23.577\n",
      "testing set RMSE 1 cycle: 42.686, 10 cycle: 43.586, 100 cycle: 36.292\n",
      "epoch:[687 / 1000] batch:[30 / 134] loss= 0.034\n",
      "epoch:[687 / 1000] batch:[60 / 134] loss= 0.021\n",
      "epoch:[687 / 1000] batch:[90 / 134] loss= 0.030\n",
      "epoch:[687 / 1000] batch:[120 / 134] loss= 0.035\n",
      "100 cycles trn_loss: 0.028, val_loss: 0.087, lr=2.140463e-05\n",
      "training set RMSE 1 cycle: 29.591, 10 cycle: 26.708, 100 cycle: 22.105\n",
      "testing set RMSE 1 cycle: 39.701, 10 cycle: 41.470, 100 cycle: 38.923\n",
      "epoch:[688 / 1000] batch:[30 / 134] loss= 0.039\n",
      "epoch:[688 / 1000] batch:[60 / 134] loss= 0.042\n",
      "epoch:[688 / 1000] batch:[90 / 134] loss= 0.047\n",
      "epoch:[688 / 1000] batch:[120 / 134] loss= 0.035\n",
      "100 cycles trn_loss: 0.022, val_loss: 0.089, lr=1.045366e-05\n",
      "training set RMSE 1 cycle: 33.458, 10 cycle: 29.346, 100 cycle: 19.480\n",
      "testing set RMSE 1 cycle: 47.720, 10 cycle: 45.272, 100 cycle: 39.309\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:[689 / 1000] batch:[30 / 134] loss= 0.036\n",
      "epoch:[689 / 1000] batch:[60 / 134] loss= 0.022\n",
      "epoch:[689 / 1000] batch:[90 / 134] loss= 0.035\n",
      "epoch:[689 / 1000] batch:[120 / 134] loss= 0.046\n",
      "100 cycles trn_loss: 0.022, val_loss: 0.086, lr=3.422702e-06\n",
      "training set RMSE 1 cycle: 29.249, 10 cycle: 25.766, 100 cycle: 19.358\n",
      "testing set RMSE 1 cycle: 43.238, 10 cycle: 42.457, 100 cycle: 38.574\n",
      "epoch:[690 / 1000] batch:[30 / 134] loss= 0.043\n",
      "epoch:[690 / 1000] batch:[60 / 134] loss= 0.062\n",
      "epoch:[690 / 1000] batch:[90 / 134] loss= 0.026\n",
      "epoch:[690 / 1000] batch:[120 / 134] loss= 0.042\n",
      "100 cycles trn_loss: 0.022, val_loss: 0.080, lr=1.000000e-06\n",
      "training set RMSE 1 cycle: 29.565, 10 cycle: 25.021, 100 cycle: 19.401\n",
      "testing set RMSE 1 cycle: 41.963, 10 cycle: 40.444, 100 cycle: 37.163\n",
      "epoch:[691 / 1000] batch:[30 / 134] loss= 0.042\n",
      "epoch:[691 / 1000] batch:[60 / 134] loss= 0.018\n",
      "epoch:[691 / 1000] batch:[90 / 134] loss= 0.027\n",
      "epoch:[691 / 1000] batch:[120 / 134] loss= 0.033\n",
      "100 cycles trn_loss: 0.020, val_loss: 0.081, lr=3.422702e-06\n",
      "training set RMSE 1 cycle: 30.374, 10 cycle: 25.604, 100 cycle: 18.809\n",
      "testing set RMSE 1 cycle: 43.762, 10 cycle: 41.386, 100 cycle: 37.527\n",
      "epoch:[692 / 1000] batch:[30 / 134] loss= 0.015\n",
      "epoch:[692 / 1000] batch:[60 / 134] loss= 0.041\n",
      "epoch:[692 / 1000] batch:[90 / 134] loss= 0.057\n",
      "epoch:[692 / 1000] batch:[120 / 134] loss= 0.049\n",
      "100 cycles trn_loss: 0.021, val_loss: 0.081, lr=1.045366e-05\n",
      "training set RMSE 1 cycle: 29.216, 10 cycle: 25.049, 100 cycle: 18.972\n",
      "testing set RMSE 1 cycle: 42.624, 10 cycle: 41.071, 100 cycle: 37.533\n",
      "epoch:[693 / 1000] batch:[30 / 134] loss= 0.026\n",
      "epoch:[693 / 1000] batch:[60 / 134] loss= 0.024\n",
      "epoch:[693 / 1000] batch:[90 / 134] loss= 0.029\n",
      "epoch:[693 / 1000] batch:[120 / 134] loss= 0.040\n",
      "100 cycles trn_loss: 0.020, val_loss: 0.082, lr=2.140463e-05\n",
      "training set RMSE 1 cycle: 29.088, 10 cycle: 24.555, 100 cycle: 18.579\n",
      "testing set RMSE 1 cycle: 42.569, 10 cycle: 40.753, 100 cycle: 37.588\n",
      "epoch:[694 / 1000] batch:[30 / 134] loss= 0.040\n",
      "epoch:[694 / 1000] batch:[60 / 134] loss= 0.041\n",
      "epoch:[694 / 1000] batch:[90 / 134] loss= 0.021\n",
      "epoch:[694 / 1000] batch:[120 / 134] loss= 0.030\n",
      "100 cycles trn_loss: 0.026, val_loss: 0.081, lr=3.520366e-05\n",
      "training set RMSE 1 cycle: 26.245, 10 cycle: 23.790, 100 cycle: 21.271\n",
      "testing set RMSE 1 cycle: 38.771, 10 cycle: 38.570, 100 cycle: 37.437\n",
      "epoch:[695 / 1000] batch:[30 / 134] loss= 0.083\n",
      "epoch:[695 / 1000] batch:[60 / 134] loss= 0.038\n",
      "epoch:[695 / 1000] batch:[90 / 134] loss= 0.045\n",
      "epoch:[695 / 1000] batch:[120 / 134] loss= 0.055\n",
      "100 cycles trn_loss: 0.034, val_loss: 0.084, lr=5.050000e-05\n",
      "training set RMSE 1 cycle: 26.984, 10 cycle: 26.111, 100 cycle: 24.653\n",
      "testing set RMSE 1 cycle: 37.003, 10 cycle: 37.563, 100 cycle: 38.079\n",
      "epoch:[696 / 1000] batch:[30 / 134] loss= 0.044\n",
      "epoch:[696 / 1000] batch:[60 / 134] loss= 0.029\n",
      "epoch:[696 / 1000] batch:[90 / 134] loss= 0.124\n",
      "epoch:[696 / 1000] batch:[120 / 134] loss= 0.040\n",
      "100 cycles trn_loss: 0.058, val_loss: 0.115, lr=6.579634e-05\n",
      "training set RMSE 1 cycle: 30.585, 10 cycle: 30.465, 100 cycle: 32.476\n",
      "testing set RMSE 1 cycle: 42.363, 10 cycle: 44.880, 100 cycle: 44.824\n",
      "epoch:[697 / 1000] batch:[30 / 134] loss= 0.075\n",
      "epoch:[697 / 1000] batch:[60 / 134] loss= 0.014\n",
      "epoch:[697 / 1000] batch:[90 / 134] loss= 0.085\n",
      "epoch:[697 / 1000] batch:[120 / 134] loss= 0.022\n",
      "100 cycles trn_loss: 0.034, val_loss: 0.100, lr=7.959537e-05\n",
      "training set RMSE 1 cycle: 24.504, 10 cycle: 24.306, 100 cycle: 24.566\n",
      "testing set RMSE 1 cycle: 41.159, 10 cycle: 40.913, 100 cycle: 41.676\n",
      "epoch:[698 / 1000] batch:[30 / 134] loss= 0.028\n",
      "epoch:[698 / 1000] batch:[60 / 134] loss= 0.175\n",
      "epoch:[698 / 1000] batch:[90 / 134] loss= 0.232\n",
      "epoch:[698 / 1000] batch:[120 / 134] loss= 0.115\n",
      "100 cycles trn_loss: 0.102, val_loss: 0.144, lr=9.054634e-05\n",
      "training set RMSE 1 cycle: 49.513, 10 cycle: 50.014, 100 cycle: 45.987\n",
      "testing set RMSE 1 cycle: 51.143, 10 cycle: 47.870, 100 cycle: 49.960\n",
      "epoch:[699 / 1000] batch:[30 / 134] loss= 0.071\n",
      "epoch:[699 / 1000] batch:[60 / 134] loss= 0.083\n",
      "epoch:[699 / 1000] batch:[90 / 134] loss= 0.074\n",
      "epoch:[699 / 1000] batch:[120 / 134] loss= 0.037\n",
      "100 cycles trn_loss: 0.086, val_loss: 0.130, lr=9.757730e-05\n",
      "training set RMSE 1 cycle: 39.856, 10 cycle: 39.434, 100 cycle: 41.004\n",
      "testing set RMSE 1 cycle: 48.024, 10 cycle: 46.426, 100 cycle: 47.529\n",
      "epoch:[700 / 1000] batch:[30 / 134] loss= 0.056\n",
      "epoch:[700 / 1000] batch:[60 / 134] loss= 0.151\n",
      "epoch:[700 / 1000] batch:[90 / 134] loss= 0.058\n",
      "epoch:[700 / 1000] batch:[120 / 134] loss= 0.047\n",
      "100 cycles trn_loss: 0.047, val_loss: 0.102, lr=1.000000e-04\n",
      "training set RMSE 1 cycle: 47.482, 10 cycle: 38.522, 100 cycle: 28.736\n",
      "testing set RMSE 1 cycle: 51.414, 10 cycle: 48.728, 100 cycle: 42.016\n",
      "epoch:[701 / 1000] batch:[30 / 134] loss= 0.067\n",
      "epoch:[701 / 1000] batch:[60 / 134] loss= 0.077\n",
      "epoch:[701 / 1000] batch:[90 / 134] loss= 0.058\n",
      "epoch:[701 / 1000] batch:[120 / 134] loss= 0.131\n",
      "100 cycles trn_loss: 0.045, val_loss: 0.089, lr=9.757730e-05\n",
      "training set RMSE 1 cycle: 43.620, 10 cycle: 35.153, 100 cycle: 28.124\n",
      "testing set RMSE 1 cycle: 45.894, 10 cycle: 44.879, 100 cycle: 39.317\n",
      "epoch:[702 / 1000] batch:[30 / 134] loss= 0.035\n",
      "epoch:[702 / 1000] batch:[60 / 134] loss= 0.091\n",
      "epoch:[702 / 1000] batch:[90 / 134] loss= 0.048\n",
      "epoch:[702 / 1000] batch:[120 / 134] loss= 0.095\n",
      "100 cycles trn_loss: 0.090, val_loss: 0.155, lr=9.054634e-05\n",
      "training set RMSE 1 cycle: 47.951, 10 cycle: 40.301, 100 cycle: 41.391\n",
      "testing set RMSE 1 cycle: 58.718, 10 cycle: 51.054, 100 cycle: 51.912\n",
      "epoch:[703 / 1000] batch:[30 / 134] loss= 0.045\n",
      "epoch:[703 / 1000] batch:[60 / 134] loss= 0.068\n",
      "epoch:[703 / 1000] batch:[90 / 134] loss= 0.056\n",
      "epoch:[703 / 1000] batch:[120 / 134] loss= 0.059\n",
      "100 cycles trn_loss: 0.057, val_loss: 0.125, lr=7.959537e-05\n",
      "training set RMSE 1 cycle: 29.980, 10 cycle: 31.355, 100 cycle: 32.803\n",
      "testing set RMSE 1 cycle: 48.361, 10 cycle: 48.226, 100 cycle: 46.726\n",
      "epoch:[704 / 1000] batch:[30 / 134] loss= 0.090\n",
      "epoch:[704 / 1000] batch:[60 / 134] loss= 0.060\n",
      "epoch:[704 / 1000] batch:[90 / 134] loss= 0.034\n",
      "epoch:[704 / 1000] batch:[120 / 134] loss= 0.062\n",
      "100 cycles trn_loss: 0.036, val_loss: 0.083, lr=6.579634e-05\n",
      "training set RMSE 1 cycle: 36.996, 10 cycle: 29.960, 100 cycle: 25.253\n",
      "testing set RMSE 1 cycle: 45.404, 10 cycle: 42.418, 100 cycle: 37.890\n",
      "epoch:[705 / 1000] batch:[30 / 134] loss= 0.027\n",
      "epoch:[705 / 1000] batch:[60 / 134] loss= 0.032\n",
      "epoch:[705 / 1000] batch:[90 / 134] loss= 0.042\n",
      "epoch:[705 / 1000] batch:[120 / 134] loss= 0.040\n",
      "100 cycles trn_loss: 0.040, val_loss: 0.102, lr=5.050000e-05\n",
      "training set RMSE 1 cycle: 29.117, 10 cycle: 27.726, 100 cycle: 26.541\n",
      "testing set RMSE 1 cycle: 46.662, 10 cycle: 47.534, 100 cycle: 42.123\n",
      "epoch:[706 / 1000] batch:[30 / 134] loss= 0.075\n",
      "epoch:[706 / 1000] batch:[60 / 134] loss= 0.037\n",
      "epoch:[706 / 1000] batch:[90 / 134] loss= 0.064\n",
      "epoch:[706 / 1000] batch:[120 / 134] loss= 0.119\n",
      "100 cycles trn_loss: 0.029, val_loss: 0.140, lr=3.520366e-05\n",
      "training set RMSE 1 cycle: 37.756, 10 cycle: 33.102, 100 cycle: 22.366\n",
      "testing set RMSE 1 cycle: 54.500, 10 cycle: 58.123, 100 cycle: 49.520\n",
      "epoch:[707 / 1000] batch:[30 / 134] loss= 0.102\n",
      "epoch:[707 / 1000] batch:[60 / 134] loss= 0.012\n",
      "epoch:[707 / 1000] batch:[90 / 134] loss= 0.024\n",
      "epoch:[707 / 1000] batch:[120 / 134] loss= 0.054\n",
      "100 cycles trn_loss: 0.021, val_loss: 0.104, lr=2.140463e-05\n",
      "training set RMSE 1 cycle: 35.635, 10 cycle: 27.631, 100 cycle: 19.011\n",
      "testing set RMSE 1 cycle: 48.364, 10 cycle: 50.588, 100 cycle: 42.417\n",
      "epoch:[708 / 1000] batch:[30 / 134] loss= 0.039\n",
      "epoch:[708 / 1000] batch:[60 / 134] loss= 0.037\n",
      "epoch:[708 / 1000] batch:[90 / 134] loss= 0.038\n",
      "epoch:[708 / 1000] batch:[120 / 134] loss= 0.029\n",
      "100 cycles trn_loss: 0.021, val_loss: 0.096, lr=1.045366e-05\n",
      "training set RMSE 1 cycle: 26.990, 10 cycle: 21.422, 100 cycle: 19.268\n",
      "testing set RMSE 1 cycle: 45.175, 10 cycle: 45.903, 100 cycle: 40.798\n",
      "epoch:[709 / 1000] batch:[30 / 134] loss= 0.066\n",
      "epoch:[709 / 1000] batch:[60 / 134] loss= 0.066\n",
      "epoch:[709 / 1000] batch:[90 / 134] loss= 0.037\n",
      "epoch:[709 / 1000] batch:[120 / 134] loss= 0.025\n",
      "100 cycles trn_loss: 0.019, val_loss: 0.096, lr=3.422702e-06\n",
      "training set RMSE 1 cycle: 26.552, 10 cycle: 21.181, 100 cycle: 18.050\n",
      "testing set RMSE 1 cycle: 46.118, 10 cycle: 46.629, 100 cycle: 40.795\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:[710 / 1000] batch:[30 / 134] loss= 0.044\n",
      "epoch:[710 / 1000] batch:[60 / 134] loss= 0.056\n",
      "epoch:[710 / 1000] batch:[90 / 134] loss= 0.024\n",
      "epoch:[710 / 1000] batch:[120 / 134] loss= 0.025\n",
      "100 cycles trn_loss: 0.018, val_loss: 0.100, lr=1.000000e-06\n",
      "training set RMSE 1 cycle: 27.411, 10 cycle: 21.012, 100 cycle: 17.606\n",
      "testing set RMSE 1 cycle: 46.861, 10 cycle: 47.137, 100 cycle: 41.685\n",
      "epoch:[711 / 1000] batch:[30 / 134] loss= 0.029\n",
      "epoch:[711 / 1000] batch:[60 / 134] loss= 0.028\n",
      "epoch:[711 / 1000] batch:[90 / 134] loss= 0.060\n",
      "epoch:[711 / 1000] batch:[120 / 134] loss= 0.015\n",
      "100 cycles trn_loss: 0.019, val_loss: 0.100, lr=3.422702e-06\n",
      "training set RMSE 1 cycle: 26.423, 10 cycle: 20.611, 100 cycle: 18.182\n",
      "testing set RMSE 1 cycle: 46.718, 10 cycle: 46.591, 100 cycle: 41.728\n",
      "epoch:[712 / 1000] batch:[30 / 134] loss= 0.019\n",
      "epoch:[712 / 1000] batch:[60 / 134] loss= 0.025\n",
      "epoch:[712 / 1000] batch:[90 / 134] loss= 0.044\n",
      "epoch:[712 / 1000] batch:[120 / 134] loss= 0.013\n",
      "100 cycles trn_loss: 0.023, val_loss: 0.104, lr=1.045366e-05\n",
      "training set RMSE 1 cycle: 24.654, 10 cycle: 20.302, 100 cycle: 19.893\n",
      "testing set RMSE 1 cycle: 47.304, 10 cycle: 46.238, 100 cycle: 42.543\n",
      "epoch:[713 / 1000] batch:[30 / 134] loss= 0.058\n",
      "epoch:[713 / 1000] batch:[60 / 134] loss= 0.038\n",
      "epoch:[713 / 1000] batch:[90 / 134] loss= 0.023\n",
      "epoch:[713 / 1000] batch:[120 / 134] loss= 0.027\n",
      "100 cycles trn_loss: 0.016, val_loss: 0.103, lr=2.140463e-05\n",
      "training set RMSE 1 cycle: 31.048, 10 cycle: 23.563, 100 cycle: 16.673\n",
      "testing set RMSE 1 cycle: 48.055, 10 cycle: 48.914, 100 cycle: 42.333\n",
      "epoch:[714 / 1000] batch:[30 / 134] loss= 0.013\n",
      "epoch:[714 / 1000] batch:[60 / 134] loss= 0.030\n",
      "epoch:[714 / 1000] batch:[90 / 134] loss= 0.027\n",
      "epoch:[714 / 1000] batch:[120 / 134] loss= 0.050\n",
      "100 cycles trn_loss: 0.017, val_loss: 0.101, lr=3.520366e-05\n",
      "training set RMSE 1 cycle: 31.443, 10 cycle: 23.423, 100 cycle: 17.325\n",
      "testing set RMSE 1 cycle: 46.370, 10 cycle: 47.094, 100 cycle: 41.802\n",
      "epoch:[715 / 1000] batch:[30 / 134] loss= 0.026\n",
      "epoch:[715 / 1000] batch:[60 / 134] loss= 0.069\n",
      "epoch:[715 / 1000] batch:[90 / 134] loss= 0.020\n",
      "epoch:[715 / 1000] batch:[120 / 134] loss= 0.027\n",
      "100 cycles trn_loss: 0.015, val_loss: 0.096, lr=5.050000e-05\n",
      "training set RMSE 1 cycle: 28.741, 10 cycle: 21.593, 100 cycle: 15.845\n",
      "testing set RMSE 1 cycle: 45.990, 10 cycle: 46.889, 100 cycle: 40.677\n",
      "epoch:[716 / 1000] batch:[30 / 134] loss= 0.053\n",
      "epoch:[716 / 1000] batch:[60 / 134] loss= 0.036\n",
      "epoch:[716 / 1000] batch:[90 / 134] loss= 0.057\n",
      "epoch:[716 / 1000] batch:[120 / 134] loss= 0.045\n",
      "100 cycles trn_loss: 0.029, val_loss: 0.110, lr=6.579634e-05\n",
      "training set RMSE 1 cycle: 23.806, 10 cycle: 21.791, 100 cycle: 22.609\n",
      "testing set RMSE 1 cycle: 49.824, 10 cycle: 47.963, 100 cycle: 43.732\n",
      "epoch:[717 / 1000] batch:[30 / 134] loss= 0.034\n",
      "epoch:[717 / 1000] batch:[60 / 134] loss= 0.028\n",
      "epoch:[717 / 1000] batch:[90 / 134] loss= 0.072\n",
      "epoch:[717 / 1000] batch:[120 / 134] loss= 0.028\n",
      "100 cycles trn_loss: 0.058, val_loss: 0.110, lr=7.959537e-05\n",
      "training set RMSE 1 cycle: 27.417, 10 cycle: 31.295, 100 cycle: 32.771\n",
      "testing set RMSE 1 cycle: 55.205, 10 cycle: 45.382, 100 cycle: 43.853\n",
      "epoch:[718 / 1000] batch:[30 / 134] loss= 0.030\n",
      "epoch:[718 / 1000] batch:[60 / 134] loss= 0.030\n",
      "epoch:[718 / 1000] batch:[90 / 134] loss= 0.138\n",
      "epoch:[718 / 1000] batch:[120 / 134] loss= 0.036\n",
      "100 cycles trn_loss: 0.098, val_loss: 0.130, lr=9.054634e-05\n",
      "training set RMSE 1 cycle: 46.618, 10 cycle: 43.132, 100 cycle: 43.788\n",
      "testing set RMSE 1 cycle: 47.978, 10 cycle: 46.252, 100 cycle: 47.792\n",
      "epoch:[719 / 1000] batch:[30 / 134] loss= 0.143\n",
      "epoch:[719 / 1000] batch:[60 / 134] loss= 0.082\n",
      "epoch:[719 / 1000] batch:[90 / 134] loss= 0.115\n",
      "epoch:[719 / 1000] batch:[120 / 134] loss= 0.051\n",
      "100 cycles trn_loss: 0.080, val_loss: 0.116, lr=9.757730e-05\n",
      "training set RMSE 1 cycle: 46.847, 10 cycle: 43.172, 100 cycle: 39.614\n",
      "testing set RMSE 1 cycle: 42.974, 10 cycle: 44.146, 100 cycle: 44.716\n",
      "epoch:[720 / 1000] batch:[30 / 134] loss= 0.139\n",
      "epoch:[720 / 1000] batch:[60 / 134] loss= 0.057\n",
      "epoch:[720 / 1000] batch:[90 / 134] loss= 0.043\n",
      "epoch:[720 / 1000] batch:[120 / 134] loss= 0.101\n",
      "100 cycles trn_loss: 0.065, val_loss: 0.115, lr=1.000000e-04\n",
      "training set RMSE 1 cycle: 49.139, 10 cycle: 42.558, 100 cycle: 33.870\n",
      "testing set RMSE 1 cycle: 47.226, 10 cycle: 47.802, 100 cycle: 44.591\n",
      "epoch:[721 / 1000] batch:[30 / 134] loss= 0.085\n",
      "epoch:[721 / 1000] batch:[60 / 134] loss= 0.072\n",
      "epoch:[721 / 1000] batch:[90 / 134] loss= 0.114\n",
      "epoch:[721 / 1000] batch:[120 / 134] loss= 0.152\n",
      "100 cycles trn_loss: 0.078, val_loss: 0.130, lr=9.757730e-05\n",
      "training set RMSE 1 cycle: 45.271, 10 cycle: 43.749, 100 cycle: 40.559\n",
      "testing set RMSE 1 cycle: 47.205, 10 cycle: 47.863, 100 cycle: 47.622\n",
      "epoch:[722 / 1000] batch:[30 / 134] loss= 0.072\n",
      "epoch:[722 / 1000] batch:[60 / 134] loss= 0.082\n",
      "epoch:[722 / 1000] batch:[90 / 134] loss= 0.052\n",
      "epoch:[722 / 1000] batch:[120 / 134] loss= 0.156\n",
      "100 cycles trn_loss: 0.089, val_loss: 0.122, lr=9.054634e-05\n",
      "training set RMSE 1 cycle: 48.469, 10 cycle: 45.813, 100 cycle: 42.481\n",
      "testing set RMSE 1 cycle: 46.223, 10 cycle: 45.568, 100 cycle: 46.024\n",
      "epoch:[723 / 1000] batch:[30 / 134] loss= 0.086\n",
      "epoch:[723 / 1000] batch:[60 / 134] loss= 0.094\n",
      "epoch:[723 / 1000] batch:[90 / 134] loss= 0.105\n",
      "epoch:[723 / 1000] batch:[120 / 134] loss= 0.061\n",
      "100 cycles trn_loss: 0.052, val_loss: 0.120, lr=7.959537e-05\n",
      "training set RMSE 1 cycle: 43.457, 10 cycle: 39.372, 100 cycle: 30.510\n",
      "testing set RMSE 1 cycle: 53.897, 10 cycle: 50.969, 100 cycle: 45.764\n",
      "epoch:[724 / 1000] batch:[30 / 134] loss= 0.111\n",
      "epoch:[724 / 1000] batch:[60 / 134] loss= 0.068\n",
      "epoch:[724 / 1000] batch:[90 / 134] loss= 0.106\n",
      "epoch:[724 / 1000] batch:[120 / 134] loss= 0.035\n",
      "100 cycles trn_loss: 0.062, val_loss: 0.122, lr=6.579634e-05\n",
      "training set RMSE 1 cycle: 35.278, 10 cycle: 34.766, 100 cycle: 34.272\n",
      "testing set RMSE 1 cycle: 45.982, 10 cycle: 47.179, 100 cycle: 46.139\n",
      "epoch:[725 / 1000] batch:[30 / 134] loss= 0.040\n",
      "epoch:[725 / 1000] batch:[60 / 134] loss= 0.077\n",
      "epoch:[725 / 1000] batch:[90 / 134] loss= 0.136\n",
      "epoch:[725 / 1000] batch:[120 / 134] loss= 0.092\n",
      "100 cycles trn_loss: 0.046, val_loss: 0.110, lr=5.050000e-05\n",
      "training set RMSE 1 cycle: 36.655, 10 cycle: 32.338, 100 cycle: 29.045\n",
      "testing set RMSE 1 cycle: 51.601, 10 cycle: 46.170, 100 cycle: 43.723\n",
      "epoch:[726 / 1000] batch:[30 / 134] loss= 0.115\n",
      "epoch:[726 / 1000] batch:[60 / 134] loss= 0.046\n",
      "epoch:[726 / 1000] batch:[90 / 134] loss= 0.047\n",
      "epoch:[726 / 1000] batch:[120 / 134] loss= 0.062\n",
      "100 cycles trn_loss: 0.057, val_loss: 0.152, lr=3.520366e-05\n",
      "training set RMSE 1 cycle: 34.272, 10 cycle: 34.319, 100 cycle: 32.395\n",
      "testing set RMSE 1 cycle: 49.277, 10 cycle: 53.487, 100 cycle: 51.349\n",
      "epoch:[727 / 1000] batch:[30 / 134] loss= 0.048\n",
      "epoch:[727 / 1000] batch:[60 / 134] loss= 0.065\n",
      "epoch:[727 / 1000] batch:[90 / 134] loss= 0.035\n",
      "epoch:[727 / 1000] batch:[120 / 134] loss= 0.020\n",
      "100 cycles trn_loss: 0.056, val_loss: 0.119, lr=2.140463e-05\n",
      "training set RMSE 1 cycle: 31.057, 10 cycle: 32.444, 100 cycle: 32.491\n",
      "testing set RMSE 1 cycle: 46.477, 10 cycle: 47.249, 100 cycle: 45.523\n",
      "epoch:[728 / 1000] batch:[30 / 134] loss= 0.068\n",
      "epoch:[728 / 1000] batch:[60 / 134] loss= 0.016\n",
      "epoch:[728 / 1000] batch:[90 / 134] loss= 0.018\n",
      "epoch:[728 / 1000] batch:[120 / 134] loss= 0.034\n",
      "100 cycles trn_loss: 0.034, val_loss: 0.138, lr=1.045366e-05\n",
      "training set RMSE 1 cycle: 29.104, 10 cycle: 27.220, 100 cycle: 24.535\n",
      "testing set RMSE 1 cycle: 51.406, 10 cycle: 52.202, 100 cycle: 48.858\n",
      "epoch:[729 / 1000] batch:[30 / 134] loss= 0.024\n",
      "epoch:[729 / 1000] batch:[60 / 134] loss= 0.077\n",
      "epoch:[729 / 1000] batch:[90 / 134] loss= 0.029\n",
      "epoch:[729 / 1000] batch:[120 / 134] loss= 0.052\n",
      "100 cycles trn_loss: 0.026, val_loss: 0.133, lr=3.422702e-06\n",
      "training set RMSE 1 cycle: 36.009, 10 cycle: 27.228, 100 cycle: 21.267\n",
      "testing set RMSE 1 cycle: 59.694, 10 cycle: 51.325, 100 cycle: 47.914\n",
      "epoch:[730 / 1000] batch:[30 / 134] loss= 0.012\n",
      "epoch:[730 / 1000] batch:[60 / 134] loss= 0.037\n",
      "epoch:[730 / 1000] batch:[90 / 134] loss= 0.061\n",
      "epoch:[730 / 1000] batch:[120 / 134] loss= 0.019\n",
      "100 cycles trn_loss: 0.029, val_loss: 0.135, lr=1.000000e-06\n",
      "training set RMSE 1 cycle: 28.495, 10 cycle: 24.599, 100 cycle: 22.856\n",
      "testing set RMSE 1 cycle: 52.342, 10 cycle: 51.404, 100 cycle: 48.301\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:[731 / 1000] batch:[30 / 134] loss= 0.035\n",
      "epoch:[731 / 1000] batch:[60 / 134] loss= 0.050\n",
      "epoch:[731 / 1000] batch:[90 / 134] loss= 0.021\n",
      "epoch:[731 / 1000] batch:[120 / 134] loss= 0.016\n",
      "100 cycles trn_loss: 0.026, val_loss: 0.133, lr=3.422702e-06\n",
      "training set RMSE 1 cycle: 30.789, 10 cycle: 24.506, 100 cycle: 21.554\n",
      "testing set RMSE 1 cycle: 55.398, 10 cycle: 50.985, 100 cycle: 47.940\n",
      "epoch:[732 / 1000] batch:[30 / 134] loss= 0.104\n",
      "epoch:[732 / 1000] batch:[60 / 134] loss= 0.019\n",
      "epoch:[732 / 1000] batch:[90 / 134] loss= 0.038\n",
      "epoch:[732 / 1000] batch:[120 / 134] loss= 0.020\n",
      "100 cycles trn_loss: 0.028, val_loss: 0.129, lr=1.045366e-05\n",
      "training set RMSE 1 cycle: 29.927, 10 cycle: 24.215, 100 cycle: 22.350\n",
      "testing set RMSE 1 cycle: 54.008, 10 cycle: 50.145, 100 cycle: 47.293\n",
      "epoch:[733 / 1000] batch:[30 / 134] loss= 0.022\n",
      "epoch:[733 / 1000] batch:[60 / 134] loss= 0.085\n",
      "epoch:[733 / 1000] batch:[90 / 134] loss= 0.026\n",
      "epoch:[733 / 1000] batch:[120 / 134] loss= 0.013\n",
      "100 cycles trn_loss: 0.027, val_loss: 0.137, lr=2.140463e-05\n",
      "training set RMSE 1 cycle: 29.228, 10 cycle: 23.326, 100 cycle: 21.921\n",
      "testing set RMSE 1 cycle: 54.442, 10 cycle: 51.508, 100 cycle: 48.710\n",
      "epoch:[734 / 1000] batch:[30 / 134] loss= 0.020\n",
      "epoch:[734 / 1000] batch:[60 / 134] loss= 0.032\n",
      "epoch:[734 / 1000] batch:[90 / 134] loss= 0.046\n",
      "epoch:[734 / 1000] batch:[120 / 134] loss= 0.032\n",
      "100 cycles trn_loss: 0.028, val_loss: 0.132, lr=3.520366e-05\n",
      "training set RMSE 1 cycle: 27.606, 10 cycle: 22.622, 100 cycle: 22.530\n",
      "testing set RMSE 1 cycle: 53.682, 10 cycle: 50.649, 100 cycle: 47.775\n",
      "epoch:[735 / 1000] batch:[30 / 134] loss= 0.028\n",
      "epoch:[735 / 1000] batch:[60 / 134] loss= 0.022\n",
      "epoch:[735 / 1000] batch:[90 / 134] loss= 0.029\n",
      "epoch:[735 / 1000] batch:[120 / 134] loss= 0.017\n",
      "100 cycles trn_loss: 0.028, val_loss: 0.128, lr=5.050000e-05\n",
      "training set RMSE 1 cycle: 31.059, 10 cycle: 24.030, 100 cycle: 22.350\n",
      "testing set RMSE 1 cycle: 54.894, 10 cycle: 49.189, 100 cycle: 47.136\n",
      "epoch:[736 / 1000] batch:[30 / 134] loss= 0.050\n",
      "epoch:[736 / 1000] batch:[60 / 134] loss= 0.024\n",
      "epoch:[736 / 1000] batch:[90 / 134] loss= 0.033\n",
      "epoch:[736 / 1000] batch:[120 / 134] loss= 0.016\n",
      "100 cycles trn_loss: 0.042, val_loss: 0.152, lr=6.579634e-05\n",
      "training set RMSE 1 cycle: 46.795, 10 cycle: 37.393, 100 cycle: 27.102\n",
      "testing set RMSE 1 cycle: 64.299, 10 cycle: 58.753, 100 cycle: 52.249\n",
      "epoch:[737 / 1000] batch:[30 / 134] loss= 0.204\n",
      "epoch:[737 / 1000] batch:[60 / 134] loss= 0.086\n",
      "epoch:[737 / 1000] batch:[90 / 134] loss= 0.094\n",
      "epoch:[737 / 1000] batch:[120 / 134] loss= 0.099\n",
      "100 cycles trn_loss: 0.075, val_loss: 0.123, lr=7.959537e-05\n",
      "training set RMSE 1 cycle: 46.873, 10 cycle: 39.735, 100 cycle: 37.767\n",
      "testing set RMSE 1 cycle: 48.833, 10 cycle: 48.855, 100 cycle: 46.164\n",
      "epoch:[738 / 1000] batch:[30 / 134] loss= 0.072\n",
      "epoch:[738 / 1000] batch:[60 / 134] loss= 0.093\n",
      "epoch:[738 / 1000] batch:[90 / 134] loss= 0.131\n",
      "epoch:[738 / 1000] batch:[120 / 134] loss= 0.143\n",
      "100 cycles trn_loss: 0.069, val_loss: 0.112, lr=9.054634e-05\n",
      "training set RMSE 1 cycle: 44.017, 10 cycle: 40.173, 100 cycle: 35.832\n",
      "testing set RMSE 1 cycle: 50.091, 10 cycle: 48.625, 100 cycle: 44.061\n",
      "epoch:[739 / 1000] batch:[30 / 134] loss= 0.093\n",
      "epoch:[739 / 1000] batch:[60 / 134] loss= 0.040\n",
      "epoch:[739 / 1000] batch:[90 / 134] loss= 0.067\n",
      "epoch:[739 / 1000] batch:[120 / 134] loss= 0.122\n",
      "100 cycles trn_loss: 0.052, val_loss: 0.122, lr=9.757730e-05\n",
      "training set RMSE 1 cycle: 43.612, 10 cycle: 37.091, 100 cycle: 29.951\n",
      "testing set RMSE 1 cycle: 51.708, 10 cycle: 53.703, 100 cycle: 45.866\n",
      "epoch:[740 / 1000] batch:[30 / 134] loss= 0.156\n",
      "epoch:[740 / 1000] batch:[60 / 134] loss= 0.154\n",
      "epoch:[740 / 1000] batch:[90 / 134] loss= 0.300\n",
      "epoch:[740 / 1000] batch:[120 / 134] loss= 0.118\n",
      "100 cycles trn_loss: 0.077, val_loss: 0.134, lr=1.000000e-04\n",
      "training set RMSE 1 cycle: 41.561, 10 cycle: 41.482, 100 cycle: 39.466\n",
      "testing set RMSE 1 cycle: 45.003, 10 cycle: 50.009, 100 cycle: 48.452\n",
      "epoch:[741 / 1000] batch:[30 / 134] loss= 0.270\n",
      "epoch:[741 / 1000] batch:[60 / 134] loss= 0.077\n",
      "epoch:[741 / 1000] batch:[90 / 134] loss= 0.076\n",
      "epoch:[741 / 1000] batch:[120 / 134] loss= 0.076\n",
      "100 cycles trn_loss: 0.094, val_loss: 0.131, lr=9.757730e-05\n",
      "training set RMSE 1 cycle: 41.420, 10 cycle: 41.582, 100 cycle: 42.062\n",
      "testing set RMSE 1 cycle: 52.973, 10 cycle: 48.605, 100 cycle: 47.563\n",
      "epoch:[742 / 1000] batch:[30 / 134] loss= 0.168\n",
      "epoch:[742 / 1000] batch:[60 / 134] loss= 0.094\n",
      "epoch:[742 / 1000] batch:[90 / 134] loss= 0.068\n",
      "epoch:[742 / 1000] batch:[120 / 134] loss= 0.074\n",
      "100 cycles trn_loss: 0.091, val_loss: 0.196, lr=9.054634e-05\n",
      "training set RMSE 1 cycle: 51.946, 10 cycle: 50.272, 100 cycle: 41.891\n",
      "testing set RMSE 1 cycle: 66.985, 10 cycle: 62.979, 100 cycle: 59.509\n",
      "epoch:[743 / 1000] batch:[30 / 134] loss= 0.120\n",
      "epoch:[743 / 1000] batch:[60 / 134] loss= 0.100\n",
      "epoch:[743 / 1000] batch:[90 / 134] loss= 0.054\n",
      "epoch:[743 / 1000] batch:[120 / 134] loss= 0.098\n",
      "100 cycles trn_loss: 0.059, val_loss: 0.157, lr=7.959537e-05\n",
      "training set RMSE 1 cycle: 40.661, 10 cycle: 35.867, 100 cycle: 32.322\n",
      "testing set RMSE 1 cycle: 51.850, 10 cycle: 56.526, 100 cycle: 52.208\n",
      "epoch:[744 / 1000] batch:[30 / 134] loss= 0.132\n",
      "epoch:[744 / 1000] batch:[60 / 134] loss= 0.072\n",
      "epoch:[744 / 1000] batch:[90 / 134] loss= 0.140\n",
      "epoch:[744 / 1000] batch:[120 / 134] loss= 0.033\n",
      "100 cycles trn_loss: 0.048, val_loss: 0.160, lr=6.579634e-05\n",
      "training set RMSE 1 cycle: 48.474, 10 cycle: 39.156, 100 cycle: 28.879\n",
      "testing set RMSE 1 cycle: 56.181, 10 cycle: 59.957, 100 cycle: 53.154\n",
      "epoch:[745 / 1000] batch:[30 / 134] loss= 0.083\n",
      "epoch:[745 / 1000] batch:[60 / 134] loss= 0.058\n",
      "epoch:[745 / 1000] batch:[90 / 134] loss= 0.046\n",
      "epoch:[745 / 1000] batch:[120 / 134] loss= 0.044\n",
      "100 cycles trn_loss: 0.050, val_loss: 0.093, lr=5.050000e-05\n",
      "training set RMSE 1 cycle: 33.705, 10 cycle: 30.399, 100 cycle: 30.297\n",
      "testing set RMSE 1 cycle: 43.295, 10 cycle: 42.762, 100 cycle: 40.065\n",
      "epoch:[746 / 1000] batch:[30 / 134] loss= 0.082\n",
      "epoch:[746 / 1000] batch:[60 / 134] loss= 0.041\n",
      "epoch:[746 / 1000] batch:[90 / 134] loss= 0.041\n",
      "epoch:[746 / 1000] batch:[120 / 134] loss= 0.031\n",
      "100 cycles trn_loss: 0.037, val_loss: 0.163, lr=3.520366e-05\n",
      "training set RMSE 1 cycle: 30.591, 10 cycle: 26.797, 100 cycle: 25.212\n",
      "testing set RMSE 1 cycle: 55.314, 10 cycle: 59.874, 100 cycle: 53.205\n",
      "epoch:[747 / 1000] batch:[30 / 134] loss= 0.050\n",
      "epoch:[747 / 1000] batch:[60 / 134] loss= 0.085\n",
      "epoch:[747 / 1000] batch:[90 / 134] loss= 0.028\n",
      "epoch:[747 / 1000] batch:[120 / 134] loss= 0.034\n",
      "100 cycles trn_loss: 0.024, val_loss: 0.151, lr=2.140463e-05\n",
      "training set RMSE 1 cycle: 28.898, 10 cycle: 23.073, 100 cycle: 20.288\n",
      "testing set RMSE 1 cycle: 55.030, 10 cycle: 57.472, 100 cycle: 51.187\n",
      "epoch:[748 / 1000] batch:[30 / 134] loss= 0.029\n",
      "epoch:[748 / 1000] batch:[60 / 134] loss= 0.014\n",
      "epoch:[748 / 1000] batch:[90 / 134] loss= 0.018\n",
      "epoch:[748 / 1000] batch:[120 / 134] loss= 0.042\n",
      "100 cycles trn_loss: 0.019, val_loss: 0.139, lr=1.045366e-05\n",
      "training set RMSE 1 cycle: 31.636, 10 cycle: 23.334, 100 cycle: 18.249\n",
      "testing set RMSE 1 cycle: 56.478, 10 cycle: 55.735, 100 cycle: 49.144\n",
      "epoch:[749 / 1000] batch:[30 / 134] loss= 0.024\n",
      "epoch:[749 / 1000] batch:[60 / 134] loss= 0.063\n",
      "epoch:[749 / 1000] batch:[90 / 134] loss= 0.014\n",
      "epoch:[749 / 1000] batch:[120 / 134] loss= 0.060\n",
      "100 cycles trn_loss: 0.020, val_loss: 0.140, lr=3.422702e-06\n",
      "training set RMSE 1 cycle: 29.482, 10 cycle: 22.043, 100 cycle: 18.583\n",
      "testing set RMSE 1 cycle: 53.745, 10 cycle: 54.906, 100 cycle: 49.282\n",
      "epoch:[750 / 1000] batch:[30 / 134] loss= 0.019\n",
      "epoch:[750 / 1000] batch:[60 / 134] loss= 0.047\n",
      "epoch:[750 / 1000] batch:[90 / 134] loss= 0.041\n",
      "epoch:[750 / 1000] batch:[120 / 134] loss= 0.024\n",
      "100 cycles trn_loss: 0.020, val_loss: 0.142, lr=1.000000e-06\n",
      "training set RMSE 1 cycle: 28.504, 10 cycle: 21.265, 100 cycle: 18.741\n",
      "testing set RMSE 1 cycle: 52.892, 10 cycle: 55.470, 100 cycle: 49.791\n",
      "epoch:[751 / 1000] batch:[30 / 134] loss= 0.014\n",
      "epoch:[751 / 1000] batch:[60 / 134] loss= 0.035\n",
      "epoch:[751 / 1000] batch:[90 / 134] loss= 0.043\n",
      "epoch:[751 / 1000] batch:[120 / 134] loss= 0.015\n",
      "100 cycles trn_loss: 0.019, val_loss: 0.142, lr=3.422702e-06\n",
      "training set RMSE 1 cycle: 29.562, 10 cycle: 21.880, 100 cycle: 18.130\n",
      "testing set RMSE 1 cycle: 53.721, 10 cycle: 55.512, 100 cycle: 49.616\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:[752 / 1000] batch:[30 / 134] loss= 0.042\n",
      "epoch:[752 / 1000] batch:[60 / 134] loss= 0.029\n",
      "epoch:[752 / 1000] batch:[90 / 134] loss= 0.037\n",
      "epoch:[752 / 1000] batch:[120 / 134] loss= 0.028\n",
      "100 cycles trn_loss: 0.018, val_loss: 0.142, lr=1.045366e-05\n",
      "training set RMSE 1 cycle: 29.678, 10 cycle: 22.149, 100 cycle: 17.766\n",
      "testing set RMSE 1 cycle: 53.969, 10 cycle: 55.887, 100 cycle: 49.697\n",
      "epoch:[753 / 1000] batch:[30 / 134] loss= 0.024\n",
      "epoch:[753 / 1000] batch:[60 / 134] loss= 0.017\n",
      "epoch:[753 / 1000] batch:[90 / 134] loss= 0.019\n",
      "epoch:[753 / 1000] batch:[120 / 134] loss= 0.016\n",
      "100 cycles trn_loss: 0.018, val_loss: 0.142, lr=2.140463e-05\n",
      "training set RMSE 1 cycle: 32.700, 10 cycle: 23.738, 100 cycle: 17.404\n",
      "testing set RMSE 1 cycle: 54.934, 10 cycle: 55.619, 100 cycle: 49.847\n",
      "epoch:[754 / 1000] batch:[30 / 134] loss= 0.062\n",
      "epoch:[754 / 1000] batch:[60 / 134] loss= 0.036\n",
      "epoch:[754 / 1000] batch:[90 / 134] loss= 0.046\n",
      "epoch:[754 / 1000] batch:[120 / 134] loss= 0.017\n",
      "100 cycles trn_loss: 0.019, val_loss: 0.145, lr=3.520366e-05\n",
      "training set RMSE 1 cycle: 29.568, 10 cycle: 21.592, 100 cycle: 18.271\n",
      "testing set RMSE 1 cycle: 53.306, 10 cycle: 55.112, 100 cycle: 50.190\n",
      "epoch:[755 / 1000] batch:[30 / 134] loss= 0.079\n",
      "epoch:[755 / 1000] batch:[60 / 134] loss= 0.078\n",
      "epoch:[755 / 1000] batch:[90 / 134] loss= 0.074\n",
      "epoch:[755 / 1000] batch:[120 / 134] loss= 0.024\n",
      "100 cycles trn_loss: 0.022, val_loss: 0.129, lr=5.050000e-05\n",
      "training set RMSE 1 cycle: 26.394, 10 cycle: 20.913, 100 cycle: 19.443\n",
      "testing set RMSE 1 cycle: 52.784, 10 cycle: 53.788, 100 cycle: 47.220\n",
      "epoch:[756 / 1000] batch:[30 / 134] loss= 0.023\n",
      "epoch:[756 / 1000] batch:[60 / 134] loss= 0.059\n",
      "epoch:[756 / 1000] batch:[90 / 134] loss= 0.032\n",
      "epoch:[756 / 1000] batch:[120 / 134] loss= 0.030\n",
      "100 cycles trn_loss: 0.020, val_loss: 0.166, lr=6.579634e-05\n",
      "training set RMSE 1 cycle: 33.891, 10 cycle: 27.520, 100 cycle: 18.435\n",
      "testing set RMSE 1 cycle: 59.794, 10 cycle: 59.941, 100 cycle: 53.942\n",
      "epoch:[757 / 1000] batch:[30 / 134] loss= 0.036\n",
      "epoch:[757 / 1000] batch:[60 / 134] loss= 0.031\n",
      "epoch:[757 / 1000] batch:[90 / 134] loss= 0.179\n",
      "epoch:[757 / 1000] batch:[120 / 134] loss= 0.021\n",
      "100 cycles trn_loss: 0.024, val_loss: 0.151, lr=7.959537e-05\n",
      "training set RMSE 1 cycle: 43.069, 10 cycle: 33.084, 100 cycle: 20.398\n",
      "testing set RMSE 1 cycle: 60.163, 10 cycle: 60.043, 100 cycle: 51.614\n",
      "epoch:[758 / 1000] batch:[30 / 134] loss= 0.071\n",
      "epoch:[758 / 1000] batch:[60 / 134] loss= 0.035\n",
      "epoch:[758 / 1000] batch:[90 / 134] loss= 0.032\n",
      "epoch:[758 / 1000] batch:[120 / 134] loss= 0.086\n",
      "100 cycles trn_loss: 0.072, val_loss: 0.137, lr=9.054634e-05\n",
      "training set RMSE 1 cycle: 32.589, 10 cycle: 37.342, 100 cycle: 37.378\n",
      "testing set RMSE 1 cycle: 51.068, 10 cycle: 50.929, 100 cycle: 48.856\n",
      "epoch:[759 / 1000] batch:[30 / 134] loss= 0.226\n",
      "epoch:[759 / 1000] batch:[60 / 134] loss= 0.085\n",
      "epoch:[759 / 1000] batch:[90 / 134] loss= 0.052\n",
      "epoch:[759 / 1000] batch:[120 / 134] loss= 0.061\n",
      "100 cycles trn_loss: 0.024, val_loss: 0.162, lr=9.757730e-05\n",
      "training set RMSE 1 cycle: 28.851, 10 cycle: 24.168, 100 cycle: 20.532\n",
      "testing set RMSE 1 cycle: 57.501, 10 cycle: 59.606, 100 cycle: 53.097\n",
      "epoch:[760 / 1000] batch:[30 / 134] loss= 0.024\n",
      "epoch:[760 / 1000] batch:[60 / 134] loss= 0.035\n",
      "epoch:[760 / 1000] batch:[90 / 134] loss= 0.180\n",
      "epoch:[760 / 1000] batch:[120 / 134] loss= 0.129\n",
      "100 cycles trn_loss: 0.089, val_loss: 0.174, lr=1.000000e-04\n",
      "training set RMSE 1 cycle: 58.818, 10 cycle: 50.793, 100 cycle: 39.353\n",
      "testing set RMSE 1 cycle: 63.431, 10 cycle: 64.575, 100 cycle: 55.346\n",
      "epoch:[761 / 1000] batch:[30 / 134] loss= 0.044\n",
      "epoch:[761 / 1000] batch:[60 / 134] loss= 0.029\n",
      "epoch:[761 / 1000] batch:[90 / 134] loss= 0.021\n",
      "epoch:[761 / 1000] batch:[120 / 134] loss= 0.111\n",
      "100 cycles trn_loss: 0.051, val_loss: 0.150, lr=9.757730e-05\n",
      "training set RMSE 1 cycle: 33.763, 10 cycle: 29.698, 100 cycle: 30.091\n",
      "testing set RMSE 1 cycle: 47.825, 10 cycle: 51.291, 100 cycle: 50.986\n",
      "epoch:[762 / 1000] batch:[30 / 134] loss= 0.135\n",
      "epoch:[762 / 1000] batch:[60 / 134] loss= 0.063\n",
      "epoch:[762 / 1000] batch:[90 / 134] loss= 0.096\n",
      "epoch:[762 / 1000] batch:[120 / 134] loss= 0.063\n",
      "100 cycles trn_loss: 0.066, val_loss: 0.199, lr=9.054634e-05\n",
      "training set RMSE 1 cycle: 52.014, 10 cycle: 47.242, 100 cycle: 33.712\n",
      "testing set RMSE 1 cycle: 67.450, 10 cycle: 67.696, 100 cycle: 60.265\n",
      "epoch:[763 / 1000] batch:[30 / 134] loss= 0.101\n",
      "epoch:[763 / 1000] batch:[60 / 134] loss= 0.060\n",
      "epoch:[763 / 1000] batch:[90 / 134] loss= 0.046\n",
      "epoch:[763 / 1000] batch:[120 / 134] loss= 0.070\n",
      "100 cycles trn_loss: 0.019, val_loss: 0.127, lr=7.959537e-05\n",
      "training set RMSE 1 cycle: 28.902, 10 cycle: 20.125, 100 cycle: 18.119\n",
      "testing set RMSE 1 cycle: 54.875, 10 cycle: 50.746, 100 cycle: 46.832\n",
      "epoch:[764 / 1000] batch:[30 / 134] loss= 0.016\n",
      "epoch:[764 / 1000] batch:[60 / 134] loss= 0.037\n",
      "epoch:[764 / 1000] batch:[90 / 134] loss= 0.030\n",
      "epoch:[764 / 1000] batch:[120 / 134] loss= 0.074\n",
      "100 cycles trn_loss: 0.031, val_loss: 0.129, lr=6.579634e-05\n",
      "training set RMSE 1 cycle: 29.995, 10 cycle: 25.751, 100 cycle: 23.008\n",
      "testing set RMSE 1 cycle: 55.754, 10 cycle: 53.246, 100 cycle: 47.566\n",
      "epoch:[765 / 1000] batch:[30 / 134] loss= 0.031\n",
      "epoch:[765 / 1000] batch:[60 / 134] loss= 0.014\n",
      "epoch:[765 / 1000] batch:[90 / 134] loss= 0.034\n",
      "epoch:[765 / 1000] batch:[120 / 134] loss= 0.035\n",
      "100 cycles trn_loss: 0.046, val_loss: 0.163, lr=5.050000e-05\n",
      "training set RMSE 1 cycle: 24.928, 10 cycle: 29.163, 100 cycle: 28.379\n",
      "testing set RMSE 1 cycle: 53.445, 10 cycle: 56.385, 100 cycle: 53.212\n",
      "epoch:[766 / 1000] batch:[30 / 134] loss= 0.025\n",
      "epoch:[766 / 1000] batch:[60 / 134] loss= 0.032\n",
      "epoch:[766 / 1000] batch:[90 / 134] loss= 0.015\n",
      "epoch:[766 / 1000] batch:[120 / 134] loss= 0.015\n",
      "100 cycles trn_loss: 0.016, val_loss: 0.124, lr=3.520366e-05\n",
      "training set RMSE 1 cycle: 26.556, 10 cycle: 19.056, 100 cycle: 16.671\n",
      "testing set RMSE 1 cycle: 51.841, 10 cycle: 48.941, 100 cycle: 46.245\n",
      "epoch:[767 / 1000] batch:[30 / 134] loss= 0.027\n",
      "epoch:[767 / 1000] batch:[60 / 134] loss= 0.038\n",
      "epoch:[767 / 1000] batch:[90 / 134] loss= 0.031\n",
      "epoch:[767 / 1000] batch:[120 / 134] loss= 0.016\n",
      "100 cycles trn_loss: 0.010, val_loss: 0.154, lr=2.140463e-05\n",
      "training set RMSE 1 cycle: 23.663, 10 cycle: 16.296, 100 cycle: 13.146\n",
      "testing set RMSE 1 cycle: 52.749, 10 cycle: 55.572, 100 cycle: 51.605\n",
      "epoch:[768 / 1000] batch:[30 / 134] loss= 0.019\n",
      "epoch:[768 / 1000] batch:[60 / 134] loss= 0.019\n",
      "epoch:[768 / 1000] batch:[90 / 134] loss= 0.025\n",
      "epoch:[768 / 1000] batch:[120 / 134] loss= 0.011\n",
      "100 cycles trn_loss: 0.009, val_loss: 0.145, lr=1.045366e-05\n",
      "training set RMSE 1 cycle: 26.425, 10 cycle: 16.999, 100 cycle: 12.653\n",
      "testing set RMSE 1 cycle: 53.925, 10 cycle: 53.554, 100 cycle: 50.029\n",
      "epoch:[769 / 1000] batch:[30 / 134] loss= 0.024\n",
      "epoch:[769 / 1000] batch:[60 / 134] loss= 0.023\n",
      "epoch:[769 / 1000] batch:[90 / 134] loss= 0.019\n",
      "epoch:[769 / 1000] batch:[120 / 134] loss= 0.009\n",
      "100 cycles trn_loss: 0.011, val_loss: 0.147, lr=3.422702e-06\n",
      "training set RMSE 1 cycle: 23.605, 10 cycle: 16.292, 100 cycle: 13.833\n",
      "testing set RMSE 1 cycle: 52.150, 10 cycle: 54.274, 100 cycle: 50.531\n",
      "epoch:[770 / 1000] batch:[30 / 134] loss= 0.017\n",
      "epoch:[770 / 1000] batch:[60 / 134] loss= 0.016\n",
      "epoch:[770 / 1000] batch:[90 / 134] loss= 0.013\n",
      "epoch:[770 / 1000] batch:[120 / 134] loss= 0.024\n",
      "100 cycles trn_loss: 0.009, val_loss: 0.148, lr=1.000000e-06\n",
      "training set RMSE 1 cycle: 24.354, 10 cycle: 15.569, 100 cycle: 12.561\n",
      "testing set RMSE 1 cycle: 53.212, 10 cycle: 53.471, 100 cycle: 50.660\n",
      "epoch:[771 / 1000] batch:[30 / 134] loss= 0.015\n",
      "epoch:[771 / 1000] batch:[60 / 134] loss= 0.010\n",
      "epoch:[771 / 1000] batch:[90 / 134] loss= 0.024\n",
      "epoch:[771 / 1000] batch:[120 / 134] loss= 0.008\n",
      "100 cycles trn_loss: 0.009, val_loss: 0.150, lr=3.422702e-06\n",
      "training set RMSE 1 cycle: 23.388, 10 cycle: 15.145, 100 cycle: 12.728\n",
      "testing set RMSE 1 cycle: 52.776, 10 cycle: 54.231, 100 cycle: 50.984\n",
      "epoch:[772 / 1000] batch:[30 / 134] loss= 0.012\n",
      "epoch:[772 / 1000] batch:[60 / 134] loss= 0.014\n",
      "epoch:[772 / 1000] batch:[90 / 134] loss= 0.016\n",
      "epoch:[772 / 1000] batch:[120 / 134] loss= 0.014\n",
      "100 cycles trn_loss: 0.009, val_loss: 0.149, lr=1.045366e-05\n",
      "training set RMSE 1 cycle: 23.789, 10 cycle: 15.378, 100 cycle: 12.397\n",
      "testing set RMSE 1 cycle: 53.112, 10 cycle: 54.090, 100 cycle: 50.847\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:[773 / 1000] batch:[30 / 134] loss= 0.019\n",
      "epoch:[773 / 1000] batch:[60 / 134] loss= 0.017\n",
      "epoch:[773 / 1000] batch:[90 / 134] loss= 0.019\n",
      "epoch:[773 / 1000] batch:[120 / 134] loss= 0.028\n",
      "100 cycles trn_loss: 0.014, val_loss: 0.143, lr=2.140463e-05\n",
      "training set RMSE 1 cycle: 24.247, 10 cycle: 17.646, 100 cycle: 15.652\n",
      "testing set RMSE 1 cycle: 51.140, 10 cycle: 52.887, 100 cycle: 49.932\n",
      "epoch:[774 / 1000] batch:[30 / 134] loss= 0.017\n",
      "epoch:[774 / 1000] batch:[60 / 134] loss= 0.014\n",
      "epoch:[774 / 1000] batch:[90 / 134] loss= 0.023\n",
      "epoch:[774 / 1000] batch:[120 / 134] loss= 0.009\n",
      "100 cycles trn_loss: 0.009, val_loss: 0.136, lr=3.520366e-05\n",
      "training set RMSE 1 cycle: 25.284, 10 cycle: 16.343, 100 cycle: 12.196\n",
      "testing set RMSE 1 cycle: 52.143, 10 cycle: 52.377, 100 cycle: 48.572\n",
      "epoch:[775 / 1000] batch:[30 / 134] loss= 0.014\n",
      "epoch:[775 / 1000] batch:[60 / 134] loss= 0.010\n",
      "epoch:[775 / 1000] batch:[90 / 134] loss= 0.025\n",
      "epoch:[775 / 1000] batch:[120 / 134] loss= 0.017\n",
      "100 cycles trn_loss: 0.019, val_loss: 0.140, lr=5.050000e-05\n",
      "training set RMSE 1 cycle: 22.812, 10 cycle: 18.159, 100 cycle: 17.917\n",
      "testing set RMSE 1 cycle: 49.138, 10 cycle: 54.127, 100 cycle: 49.525\n",
      "epoch:[776 / 1000] batch:[30 / 134] loss= 0.027\n",
      "epoch:[776 / 1000] batch:[60 / 134] loss= 0.023\n",
      "epoch:[776 / 1000] batch:[90 / 134] loss= 0.022\n",
      "epoch:[776 / 1000] batch:[120 / 134] loss= 0.162\n",
      "100 cycles trn_loss: 0.017, val_loss: 0.161, lr=6.579634e-05\n",
      "training set RMSE 1 cycle: 27.683, 10 cycle: 23.100, 100 cycle: 17.164\n",
      "testing set RMSE 1 cycle: 57.311, 10 cycle: 59.855, 100 cycle: 52.836\n",
      "epoch:[777 / 1000] batch:[30 / 134] loss= 0.011\n",
      "epoch:[777 / 1000] batch:[60 / 134] loss= 0.021\n",
      "epoch:[777 / 1000] batch:[90 / 134] loss= 0.011\n",
      "epoch:[777 / 1000] batch:[120 / 134] loss= 0.079\n",
      "100 cycles trn_loss: 0.010, val_loss: 0.138, lr=7.959537e-05\n",
      "training set RMSE 1 cycle: 30.291, 10 cycle: 22.266, 100 cycle: 13.148\n",
      "testing set RMSE 1 cycle: 49.398, 10 cycle: 55.253, 100 cycle: 49.035\n",
      "epoch:[778 / 1000] batch:[30 / 134] loss= 0.042\n",
      "epoch:[778 / 1000] batch:[60 / 134] loss= 0.025\n",
      "epoch:[778 / 1000] batch:[90 / 134] loss= 0.015\n",
      "epoch:[778 / 1000] batch:[120 / 134] loss= 0.028\n",
      "100 cycles trn_loss: 0.084, val_loss: 0.175, lr=9.054634e-05\n",
      "training set RMSE 1 cycle: 53.774, 10 cycle: 51.179, 100 cycle: 38.519\n",
      "testing set RMSE 1 cycle: 67.801, 10 cycle: 62.834, 100 cycle: 56.509\n",
      "epoch:[779 / 1000] batch:[30 / 134] loss= 0.045\n",
      "epoch:[779 / 1000] batch:[60 / 134] loss= 0.023\n",
      "epoch:[779 / 1000] batch:[90 / 134] loss= 0.034\n",
      "epoch:[779 / 1000] batch:[120 / 134] loss= 0.134\n",
      "100 cycles trn_loss: 0.018, val_loss: 0.098, lr=9.757730e-05\n",
      "training set RMSE 1 cycle: 36.545, 10 cycle: 21.523, 100 cycle: 17.616\n",
      "testing set RMSE 1 cycle: 43.185, 10 cycle: 41.733, 100 cycle: 41.340\n",
      "epoch:[780 / 1000] batch:[30 / 134] loss= 0.140\n",
      "epoch:[780 / 1000] batch:[60 / 134] loss= 0.068\n",
      "epoch:[780 / 1000] batch:[90 / 134] loss= 0.066\n",
      "epoch:[780 / 1000] batch:[120 / 134] loss= 0.064\n",
      "100 cycles trn_loss: 0.043, val_loss: 0.136, lr=1.000000e-04\n",
      "training set RMSE 1 cycle: 40.504, 10 cycle: 37.816, 100 cycle: 27.307\n",
      "testing set RMSE 1 cycle: 61.749, 10 cycle: 55.924, 100 cycle: 49.033\n",
      "epoch:[781 / 1000] batch:[30 / 134] loss= 0.038\n",
      "epoch:[781 / 1000] batch:[60 / 134] loss= 0.095\n",
      "epoch:[781 / 1000] batch:[90 / 134] loss= 0.068\n",
      "epoch:[781 / 1000] batch:[120 / 134] loss= 0.115\n",
      "100 cycles trn_loss: 0.133, val_loss: 0.219, lr=9.757730e-05\n",
      "training set RMSE 1 cycle: 48.580, 10 cycle: 50.680, 100 cycle: 51.792\n",
      "testing set RMSE 1 cycle: 54.681, 10 cycle: 61.258, 100 cycle: 62.383\n",
      "epoch:[782 / 1000] batch:[30 / 134] loss= 0.039\n",
      "epoch:[782 / 1000] batch:[60 / 134] loss= 0.087\n",
      "epoch:[782 / 1000] batch:[90 / 134] loss= 0.057\n",
      "epoch:[782 / 1000] batch:[120 / 134] loss= 0.045\n",
      "100 cycles trn_loss: 0.048, val_loss: 0.124, lr=9.054634e-05\n",
      "training set RMSE 1 cycle: 35.334, 10 cycle: 31.535, 100 cycle: 29.574\n",
      "testing set RMSE 1 cycle: 50.156, 10 cycle: 46.749, 100 cycle: 46.341\n",
      "epoch:[783 / 1000] batch:[30 / 134] loss= 0.037\n",
      "epoch:[783 / 1000] batch:[60 / 134] loss= 0.060\n",
      "epoch:[783 / 1000] batch:[90 / 134] loss= 0.023\n",
      "epoch:[783 / 1000] batch:[120 / 134] loss= 0.066\n",
      "100 cycles trn_loss: 0.013, val_loss: 0.139, lr=7.959537e-05\n",
      "training set RMSE 1 cycle: 37.115, 10 cycle: 24.369, 100 cycle: 14.882\n",
      "testing set RMSE 1 cycle: 55.845, 10 cycle: 51.569, 100 cycle: 49.213\n",
      "epoch:[784 / 1000] batch:[30 / 134] loss= 0.079\n",
      "epoch:[784 / 1000] batch:[60 / 134] loss= 0.068\n",
      "epoch:[784 / 1000] batch:[90 / 134] loss= 0.037\n",
      "epoch:[784 / 1000] batch:[120 / 134] loss= 0.024\n",
      "100 cycles trn_loss: 0.053, val_loss: 0.164, lr=6.579634e-05\n",
      "training set RMSE 1 cycle: 58.022, 10 cycle: 48.874, 100 cycle: 30.193\n",
      "testing set RMSE 1 cycle: 69.189, 10 cycle: 62.122, 100 cycle: 55.152\n",
      "epoch:[785 / 1000] batch:[30 / 134] loss= 0.089\n",
      "epoch:[785 / 1000] batch:[60 / 134] loss= 0.064\n",
      "epoch:[785 / 1000] batch:[90 / 134] loss= 0.027\n",
      "epoch:[785 / 1000] batch:[120 / 134] loss= 0.066\n",
      "100 cycles trn_loss: 0.046, val_loss: 0.121, lr=5.050000e-05\n",
      "training set RMSE 1 cycle: 27.058, 10 cycle: 28.166, 100 cycle: 29.337\n",
      "testing set RMSE 1 cycle: 45.144, 10 cycle: 46.124, 100 cycle: 45.760\n",
      "epoch:[786 / 1000] batch:[30 / 134] loss= 0.025\n",
      "epoch:[786 / 1000] batch:[60 / 134] loss= 0.033\n",
      "epoch:[786 / 1000] batch:[90 / 134] loss= 0.009\n",
      "epoch:[786 / 1000] batch:[120 / 134] loss= 0.029\n",
      "100 cycles trn_loss: 0.017, val_loss: 0.123, lr=3.520366e-05\n",
      "training set RMSE 1 cycle: 21.552, 10 cycle: 15.633, 100 cycle: 17.342\n",
      "testing set RMSE 1 cycle: 47.882, 10 cycle: 47.983, 100 cycle: 46.116\n",
      "epoch:[787 / 1000] batch:[30 / 134] loss= 0.014\n",
      "epoch:[787 / 1000] batch:[60 / 134] loss= 0.011\n",
      "epoch:[787 / 1000] batch:[90 / 134] loss= 0.015\n",
      "epoch:[787 / 1000] batch:[120 / 134] loss= 0.017\n",
      "100 cycles trn_loss: 0.008, val_loss: 0.146, lr=2.140463e-05\n",
      "training set RMSE 1 cycle: 23.261, 10 cycle: 14.906, 100 cycle: 11.415\n",
      "testing set RMSE 1 cycle: 53.013, 10 cycle: 53.564, 100 cycle: 50.295\n",
      "epoch:[788 / 1000] batch:[30 / 134] loss= 0.007\n",
      "epoch:[788 / 1000] batch:[60 / 134] loss= 0.021\n",
      "epoch:[788 / 1000] batch:[90 / 134] loss= 0.022\n",
      "epoch:[788 / 1000] batch:[120 / 134] loss= 0.009\n",
      "100 cycles trn_loss: 0.008, val_loss: 0.158, lr=1.045366e-05\n",
      "training set RMSE 1 cycle: 27.627, 10 cycle: 17.652, 100 cycle: 11.612\n",
      "testing set RMSE 1 cycle: 55.699, 10 cycle: 56.177, 100 cycle: 52.626\n",
      "epoch:[789 / 1000] batch:[30 / 134] loss= 0.018\n",
      "epoch:[789 / 1000] batch:[60 / 134] loss= 0.011\n",
      "epoch:[789 / 1000] batch:[90 / 134] loss= 0.011\n",
      "epoch:[789 / 1000] batch:[120 / 134] loss= 0.012\n",
      "100 cycles trn_loss: 0.008, val_loss: 0.140, lr=3.422702e-06\n",
      "training set RMSE 1 cycle: 21.448, 10 cycle: 14.129, 100 cycle: 11.960\n",
      "testing set RMSE 1 cycle: 51.932, 10 cycle: 52.667, 100 cycle: 49.304\n",
      "epoch:[790 / 1000] batch:[30 / 134] loss= 0.022\n",
      "epoch:[790 / 1000] batch:[60 / 134] loss= 0.011\n",
      "epoch:[790 / 1000] batch:[90 / 134] loss= 0.008\n",
      "epoch:[790 / 1000] batch:[120 / 134] loss= 0.015\n",
      "100 cycles trn_loss: 0.007, val_loss: 0.141, lr=1.000000e-06\n",
      "training set RMSE 1 cycle: 22.623, 10 cycle: 14.110, 100 cycle: 11.299\n",
      "testing set RMSE 1 cycle: 52.278, 10 cycle: 52.477, 100 cycle: 49.450\n",
      "epoch:[791 / 1000] batch:[30 / 134] loss= 0.016\n",
      "epoch:[791 / 1000] batch:[60 / 134] loss= 0.022\n",
      "epoch:[791 / 1000] batch:[90 / 134] loss= 0.013\n",
      "epoch:[791 / 1000] batch:[120 / 134] loss= 0.021\n",
      "100 cycles trn_loss: 0.007, val_loss: 0.139, lr=3.422702e-06\n",
      "training set RMSE 1 cycle: 22.196, 10 cycle: 13.921, 100 cycle: 11.368\n",
      "testing set RMSE 1 cycle: 51.778, 10 cycle: 51.933, 100 cycle: 48.996\n",
      "epoch:[792 / 1000] batch:[30 / 134] loss= 0.015\n",
      "epoch:[792 / 1000] batch:[60 / 134] loss= 0.013\n",
      "epoch:[792 / 1000] batch:[90 / 134] loss= 0.017\n",
      "epoch:[792 / 1000] batch:[120 / 134] loss= 0.014\n",
      "100 cycles trn_loss: 0.008, val_loss: 0.137, lr=1.045366e-05\n",
      "training set RMSE 1 cycle: 22.042, 10 cycle: 13.769, 100 cycle: 11.423\n",
      "testing set RMSE 1 cycle: 51.489, 10 cycle: 51.542, 100 cycle: 48.773\n",
      "epoch:[793 / 1000] batch:[30 / 134] loss= 0.017\n",
      "epoch:[793 / 1000] batch:[60 / 134] loss= 0.013\n",
      "epoch:[793 / 1000] batch:[90 / 134] loss= 0.006\n",
      "epoch:[793 / 1000] batch:[120 / 134] loss= 0.017\n",
      "100 cycles trn_loss: 0.006, val_loss: 0.141, lr=2.140463e-05\n",
      "training set RMSE 1 cycle: 24.231, 10 cycle: 14.471, 100 cycle: 10.562\n",
      "testing set RMSE 1 cycle: 52.150, 10 cycle: 53.038, 100 cycle: 49.507\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:[794 / 1000] batch:[30 / 134] loss= 0.012\n",
      "epoch:[794 / 1000] batch:[60 / 134] loss= 0.014\n",
      "epoch:[794 / 1000] batch:[90 / 134] loss= 0.015\n",
      "epoch:[794 / 1000] batch:[120 / 134] loss= 0.037\n",
      "100 cycles trn_loss: 0.008, val_loss: 0.155, lr=3.520366e-05\n",
      "training set RMSE 1 cycle: 30.826, 10 cycle: 19.659, 100 cycle: 11.840\n",
      "testing set RMSE 1 cycle: 56.436, 10 cycle: 56.068, 100 cycle: 52.433\n",
      "epoch:[795 / 1000] batch:[30 / 134] loss= 0.015\n",
      "epoch:[795 / 1000] batch:[60 / 134] loss= 0.039\n",
      "epoch:[795 / 1000] batch:[90 / 134] loss= 0.021\n",
      "epoch:[795 / 1000] batch:[120 / 134] loss= 0.010\n",
      "100 cycles trn_loss: 0.010, val_loss: 0.137, lr=5.050000e-05\n",
      "training set RMSE 1 cycle: 19.550, 10 cycle: 13.711, 100 cycle: 13.112\n",
      "testing set RMSE 1 cycle: 51.450, 10 cycle: 51.876, 100 cycle: 48.623\n",
      "epoch:[796 / 1000] batch:[30 / 134] loss= 0.012\n",
      "epoch:[796 / 1000] batch:[60 / 134] loss= 0.056\n",
      "epoch:[796 / 1000] batch:[90 / 134] loss= 0.040\n",
      "epoch:[796 / 1000] batch:[120 / 134] loss= 0.024\n",
      "100 cycles trn_loss: 0.012, val_loss: 0.133, lr=6.579634e-05\n",
      "training set RMSE 1 cycle: 24.310, 10 cycle: 15.839, 100 cycle: 14.328\n",
      "testing set RMSE 1 cycle: 49.188, 10 cycle: 50.024, 100 cycle: 47.955\n",
      "epoch:[797 / 1000] batch:[30 / 134] loss= 0.009\n",
      "epoch:[797 / 1000] batch:[60 / 134] loss= 0.056\n",
      "epoch:[797 / 1000] batch:[90 / 134] loss= 0.061\n",
      "epoch:[797 / 1000] batch:[120 / 134] loss= 0.011\n",
      "100 cycles trn_loss: 0.007, val_loss: 0.155, lr=7.959537e-05\n",
      "training set RMSE 1 cycle: 23.637, 10 cycle: 15.360, 100 cycle: 10.849\n",
      "testing set RMSE 1 cycle: 54.758, 10 cycle: 55.136, 100 cycle: 51.773\n",
      "epoch:[798 / 1000] batch:[30 / 134] loss= 0.056\n",
      "epoch:[798 / 1000] batch:[60 / 134] loss= 0.030\n",
      "epoch:[798 / 1000] batch:[90 / 134] loss= 0.020\n",
      "epoch:[798 / 1000] batch:[120 / 134] loss= 0.136\n",
      "100 cycles trn_loss: 0.041, val_loss: 0.134, lr=9.054634e-05\n",
      "training set RMSE 1 cycle: 37.498, 10 cycle: 31.075, 100 cycle: 26.785\n",
      "testing set RMSE 1 cycle: 51.330, 10 cycle: 51.565, 100 cycle: 48.252\n",
      "epoch:[799 / 1000] batch:[30 / 134] loss= 0.039\n",
      "epoch:[799 / 1000] batch:[60 / 134] loss= 0.045\n",
      "epoch:[799 / 1000] batch:[90 / 134] loss= 0.069\n",
      "epoch:[799 / 1000] batch:[120 / 134] loss= 0.173\n",
      "100 cycles trn_loss: 0.157, val_loss: 0.224, lr=9.757730e-05\n",
      "training set RMSE 1 cycle: 58.127, 10 cycle: 57.111, 100 cycle: 57.676\n",
      "testing set RMSE 1 cycle: 61.676, 10 cycle: 61.220, 100 cycle: 63.106\n",
      "epoch:[800 / 1000] batch:[30 / 134] loss= 0.052\n",
      "epoch:[800 / 1000] batch:[60 / 134] loss= 0.113\n",
      "epoch:[800 / 1000] batch:[90 / 134] loss= 0.018\n",
      "epoch:[800 / 1000] batch:[120 / 134] loss= 0.085\n",
      "100 cycles trn_loss: 0.167, val_loss: 0.211, lr=1.000000e-04\n",
      "training set RMSE 1 cycle: 53.967, 10 cycle: 59.290, 100 cycle: 58.756\n",
      "testing set RMSE 1 cycle: 67.218, 10 cycle: 59.046, 100 cycle: 61.452\n",
      "epoch:[801 / 1000] batch:[30 / 134] loss= 0.152\n",
      "epoch:[801 / 1000] batch:[60 / 134] loss= 0.137\n",
      "epoch:[801 / 1000] batch:[90 / 134] loss= 0.036\n",
      "epoch:[801 / 1000] batch:[120 / 134] loss= 0.062\n",
      "100 cycles trn_loss: 0.081, val_loss: 0.153, lr=9.757730e-05\n",
      "training set RMSE 1 cycle: 53.195, 10 cycle: 48.271, 100 cycle: 39.095\n",
      "testing set RMSE 1 cycle: 56.281, 10 cycle: 56.660, 100 cycle: 51.508\n",
      "epoch:[802 / 1000] batch:[30 / 134] loss= 0.074\n",
      "epoch:[802 / 1000] batch:[60 / 134] loss= 0.047\n",
      "epoch:[802 / 1000] batch:[90 / 134] loss= 0.035\n",
      "epoch:[802 / 1000] batch:[120 / 134] loss= 0.028\n",
      "100 cycles trn_loss: 0.062, val_loss: 0.117, lr=9.054634e-05\n",
      "training set RMSE 1 cycle: 74.693, 10 cycle: 34.746, 100 cycle: 33.135\n",
      "testing set RMSE 1 cycle: 91.780, 10 cycle: 46.838, 100 cycle: 44.951\n",
      "epoch:[803 / 1000] batch:[30 / 134] loss= 0.055\n",
      "epoch:[803 / 1000] batch:[60 / 134] loss= 0.059\n",
      "epoch:[803 / 1000] batch:[90 / 134] loss= 0.082\n",
      "epoch:[803 / 1000] batch:[120 / 134] loss= 0.024\n",
      "100 cycles trn_loss: 0.045, val_loss: 0.121, lr=7.959537e-05\n",
      "training set RMSE 1 cycle: 41.928, 10 cycle: 35.613, 100 cycle: 27.945\n",
      "testing set RMSE 1 cycle: 61.252, 10 cycle: 55.825, 100 cycle: 45.892\n",
      "epoch:[804 / 1000] batch:[30 / 134] loss= 0.090\n",
      "epoch:[804 / 1000] batch:[60 / 134] loss= 0.033\n",
      "epoch:[804 / 1000] batch:[90 / 134] loss= 0.050\n",
      "epoch:[804 / 1000] batch:[120 / 134] loss= 0.052\n",
      "100 cycles trn_loss: 0.067, val_loss: 0.122, lr=6.579634e-05\n",
      "training set RMSE 1 cycle: 35.603, 10 cycle: 36.489, 100 cycle: 35.406\n",
      "testing set RMSE 1 cycle: 50.027, 10 cycle: 47.777, 100 cycle: 46.167\n",
      "epoch:[805 / 1000] batch:[30 / 134] loss= 0.200\n",
      "epoch:[805 / 1000] batch:[60 / 134] loss= 0.061\n",
      "epoch:[805 / 1000] batch:[90 / 134] loss= 0.061\n",
      "epoch:[805 / 1000] batch:[120 / 134] loss= 0.032\n",
      "100 cycles trn_loss: 0.037, val_loss: 0.173, lr=5.050000e-05\n",
      "training set RMSE 1 cycle: 37.134, 10 cycle: 30.707, 100 cycle: 25.320\n",
      "testing set RMSE 1 cycle: 67.596, 10 cycle: 59.705, 100 cycle: 54.732\n",
      "epoch:[806 / 1000] batch:[30 / 134] loss= 0.045\n",
      "epoch:[806 / 1000] batch:[60 / 134] loss= 0.025\n",
      "epoch:[806 / 1000] batch:[90 / 134] loss= 0.025\n",
      "epoch:[806 / 1000] batch:[120 / 134] loss= 0.031\n",
      "100 cycles trn_loss: 0.015, val_loss: 0.102, lr=3.520366e-05\n",
      "training set RMSE 1 cycle: 35.870, 10 cycle: 23.098, 100 cycle: 16.254\n",
      "testing set RMSE 1 cycle: 56.380, 10 cycle: 44.595, 100 cycle: 41.906\n",
      "epoch:[807 / 1000] batch:[30 / 134] loss= 0.025\n",
      "epoch:[807 / 1000] batch:[60 / 134] loss= 0.036\n",
      "epoch:[807 / 1000] batch:[90 / 134] loss= 0.022\n",
      "epoch:[807 / 1000] batch:[120 / 134] loss= 0.031\n",
      "100 cycles trn_loss: 0.013, val_loss: 0.108, lr=2.140463e-05\n",
      "training set RMSE 1 cycle: 28.689, 10 cycle: 17.992, 100 cycle: 14.761\n",
      "testing set RMSE 1 cycle: 56.081, 10 cycle: 44.392, 100 cycle: 43.247\n",
      "epoch:[808 / 1000] batch:[30 / 134] loss= 0.016\n",
      "epoch:[808 / 1000] batch:[60 / 134] loss= 0.046\n",
      "epoch:[808 / 1000] batch:[90 / 134] loss= 0.026\n",
      "epoch:[808 / 1000] batch:[120 / 134] loss= 0.035\n",
      "100 cycles trn_loss: 0.013, val_loss: 0.129, lr=1.045366e-05\n",
      "training set RMSE 1 cycle: 26.506, 10 cycle: 16.802, 100 cycle: 14.896\n",
      "testing set RMSE 1 cycle: 55.645, 10 cycle: 49.011, 100 cycle: 47.353\n",
      "epoch:[809 / 1000] batch:[30 / 134] loss= 0.021\n",
      "epoch:[809 / 1000] batch:[60 / 134] loss= 0.027\n",
      "epoch:[809 / 1000] batch:[90 / 134] loss= 0.024\n",
      "epoch:[809 / 1000] batch:[120 / 134] loss= 0.017\n",
      "100 cycles trn_loss: 0.009, val_loss: 0.120, lr=3.422702e-06\n",
      "training set RMSE 1 cycle: 26.625, 10 cycle: 16.764, 100 cycle: 12.780\n",
      "testing set RMSE 1 cycle: 55.996, 10 cycle: 46.418, 100 cycle: 45.601\n",
      "epoch:[810 / 1000] batch:[30 / 134] loss= 0.023\n",
      "epoch:[810 / 1000] batch:[60 / 134] loss= 0.015\n",
      "epoch:[810 / 1000] batch:[90 / 134] loss= 0.016\n",
      "epoch:[810 / 1000] batch:[120 / 134] loss= 0.023\n",
      "100 cycles trn_loss: 0.009, val_loss: 0.122, lr=1.000000e-06\n",
      "training set RMSE 1 cycle: 26.157, 10 cycle: 16.516, 100 cycle: 12.672\n",
      "testing set RMSE 1 cycle: 55.957, 10 cycle: 46.732, 100 cycle: 45.878\n",
      "epoch:[811 / 1000] batch:[30 / 134] loss= 0.018\n",
      "epoch:[811 / 1000] batch:[60 / 134] loss= 0.030\n",
      "epoch:[811 / 1000] batch:[90 / 134] loss= 0.016\n",
      "epoch:[811 / 1000] batch:[120 / 134] loss= 0.019\n",
      "100 cycles trn_loss: 0.009, val_loss: 0.126, lr=3.422702e-06\n",
      "training set RMSE 1 cycle: 26.843, 10 cycle: 16.644, 100 cycle: 12.261\n",
      "testing set RMSE 1 cycle: 56.339, 10 cycle: 48.134, 100 cycle: 46.766\n",
      "epoch:[812 / 1000] batch:[30 / 134] loss= 0.028\n",
      "epoch:[812 / 1000] batch:[60 / 134] loss= 0.009\n",
      "epoch:[812 / 1000] batch:[90 / 134] loss= 0.017\n",
      "epoch:[812 / 1000] batch:[120 / 134] loss= 0.024\n",
      "100 cycles trn_loss: 0.009, val_loss: 0.124, lr=1.045366e-05\n",
      "training set RMSE 1 cycle: 25.655, 10 cycle: 16.212, 100 cycle: 12.610\n",
      "testing set RMSE 1 cycle: 55.884, 10 cycle: 47.480, 100 cycle: 46.397\n",
      "epoch:[813 / 1000] batch:[30 / 134] loss= 0.017\n",
      "epoch:[813 / 1000] batch:[60 / 134] loss= 0.014\n",
      "epoch:[813 / 1000] batch:[90 / 134] loss= 0.011\n",
      "epoch:[813 / 1000] batch:[120 / 134] loss= 0.014\n",
      "100 cycles trn_loss: 0.009, val_loss: 0.132, lr=2.140463e-05\n",
      "training set RMSE 1 cycle: 27.653, 10 cycle: 16.717, 100 cycle: 12.393\n",
      "testing set RMSE 1 cycle: 55.657, 10 cycle: 50.510, 100 cycle: 47.989\n",
      "epoch:[814 / 1000] batch:[30 / 134] loss= 0.012\n",
      "epoch:[814 / 1000] batch:[60 / 134] loss= 0.014\n",
      "epoch:[814 / 1000] batch:[90 / 134] loss= 0.022\n",
      "epoch:[814 / 1000] batch:[120 / 134] loss= 0.022\n",
      "100 cycles trn_loss: 0.009, val_loss: 0.144, lr=3.520366e-05\n",
      "training set RMSE 1 cycle: 34.427, 10 cycle: 21.722, 100 cycle: 12.215\n",
      "testing set RMSE 1 cycle: 58.937, 10 cycle: 53.696, 100 cycle: 50.154\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:[815 / 1000] batch:[30 / 134] loss= 0.058\n",
      "epoch:[815 / 1000] batch:[60 / 134] loss= 0.013\n",
      "epoch:[815 / 1000] batch:[90 / 134] loss= 0.026\n",
      "epoch:[815 / 1000] batch:[120 / 134] loss= 0.013\n",
      "100 cycles trn_loss: 0.007, val_loss: 0.138, lr=5.050000e-05\n",
      "training set RMSE 1 cycle: 30.027, 10 cycle: 18.465, 100 cycle: 11.374\n",
      "testing set RMSE 1 cycle: 58.659, 10 cycle: 51.353, 100 cycle: 48.919\n",
      "epoch:[816 / 1000] batch:[30 / 134] loss= 0.012\n",
      "epoch:[816 / 1000] batch:[60 / 134] loss= 0.075\n",
      "epoch:[816 / 1000] batch:[90 / 134] loss= 0.042\n",
      "epoch:[816 / 1000] batch:[120 / 134] loss= 0.032\n",
      "100 cycles trn_loss: 0.019, val_loss: 0.112, lr=6.579634e-05\n",
      "training set RMSE 1 cycle: 27.491, 10 cycle: 19.256, 100 cycle: 18.171\n",
      "testing set RMSE 1 cycle: 51.356, 10 cycle: 43.919, 100 cycle: 44.036\n",
      "epoch:[817 / 1000] batch:[30 / 134] loss= 0.031\n",
      "epoch:[817 / 1000] batch:[60 / 134] loss= 0.022\n",
      "epoch:[817 / 1000] batch:[90 / 134] loss= 0.034\n",
      "epoch:[817 / 1000] batch:[120 / 134] loss= 0.016\n",
      "100 cycles trn_loss: 0.026, val_loss: 0.168, lr=7.959537e-05\n",
      "training set RMSE 1 cycle: 29.338, 10 cycle: 24.760, 100 cycle: 21.308\n",
      "testing set RMSE 1 cycle: 56.482, 10 cycle: 57.166, 100 cycle: 54.247\n",
      "epoch:[818 / 1000] batch:[30 / 134] loss= 0.043\n",
      "epoch:[818 / 1000] batch:[60 / 134] loss= 0.054\n",
      "epoch:[818 / 1000] batch:[90 / 134] loss= 0.062\n",
      "epoch:[818 / 1000] batch:[120 / 134] loss= 0.026\n",
      "100 cycles trn_loss: 0.044, val_loss: 0.145, lr=9.054634e-05\n",
      "training set RMSE 1 cycle: 25.569, 10 cycle: 29.975, 100 cycle: 28.995\n",
      "testing set RMSE 1 cycle: 55.688, 10 cycle: 52.756, 100 cycle: 50.160\n",
      "epoch:[819 / 1000] batch:[30 / 134] loss= 0.035\n",
      "epoch:[819 / 1000] batch:[60 / 134] loss= 0.055\n",
      "epoch:[819 / 1000] batch:[90 / 134] loss= 0.054\n",
      "epoch:[819 / 1000] batch:[120 / 134] loss= 0.023\n",
      "100 cycles trn_loss: 0.037, val_loss: 0.120, lr=9.757730e-05\n",
      "training set RMSE 1 cycle: 52.023, 10 cycle: 42.351, 100 cycle: 25.260\n",
      "testing set RMSE 1 cycle: 58.146, 10 cycle: 52.191, 100 cycle: 46.716\n",
      "epoch:[820 / 1000] batch:[30 / 134] loss= 0.134\n",
      "epoch:[820 / 1000] batch:[60 / 134] loss= 0.194\n",
      "epoch:[820 / 1000] batch:[90 / 134] loss= 0.123\n",
      "epoch:[820 / 1000] batch:[120 / 134] loss= 0.090\n",
      "100 cycles trn_loss: 0.099, val_loss: 0.165, lr=1.000000e-04\n",
      "training set RMSE 1 cycle: 50.678, 10 cycle: 44.985, 100 cycle: 44.955\n",
      "testing set RMSE 1 cycle: 51.915, 10 cycle: 52.091, 100 cycle: 53.789\n",
      "epoch:[821 / 1000] batch:[30 / 134] loss= 0.071\n",
      "epoch:[821 / 1000] batch:[60 / 134] loss= 0.060\n",
      "epoch:[821 / 1000] batch:[90 / 134] loss= 0.139\n",
      "epoch:[821 / 1000] batch:[120 / 134] loss= 0.132\n",
      "100 cycles trn_loss: 0.078, val_loss: 0.135, lr=9.757730e-05\n",
      "training set RMSE 1 cycle: 49.804, 10 cycle: 43.170, 100 cycle: 38.308\n",
      "testing set RMSE 1 cycle: 55.097, 10 cycle: 53.965, 100 cycle: 48.463\n",
      "epoch:[822 / 1000] batch:[30 / 134] loss= 0.105\n",
      "epoch:[822 / 1000] batch:[60 / 134] loss= 0.118\n",
      "epoch:[822 / 1000] batch:[90 / 134] loss= 0.082\n",
      "epoch:[822 / 1000] batch:[120 / 134] loss= 0.123\n",
      "100 cycles trn_loss: 0.086, val_loss: 0.136, lr=9.054634e-05\n",
      "training set RMSE 1 cycle: 48.749, 10 cycle: 43.192, 100 cycle: 41.750\n",
      "testing set RMSE 1 cycle: 46.033, 10 cycle: 47.762, 100 cycle: 49.164\n",
      "epoch:[823 / 1000] batch:[30 / 134] loss= 0.100\n",
      "epoch:[823 / 1000] batch:[60 / 134] loss= 0.100\n",
      "epoch:[823 / 1000] batch:[90 / 134] loss= 0.047\n",
      "epoch:[823 / 1000] batch:[120 / 134] loss= 0.107\n",
      "100 cycles trn_loss: 0.108, val_loss: 0.232, lr=7.959537e-05\n",
      "training set RMSE 1 cycle: 50.567, 10 cycle: 45.817, 100 cycle: 46.321\n",
      "testing set RMSE 1 cycle: 71.720, 10 cycle: 70.903, 100 cycle: 65.278\n",
      "epoch:[824 / 1000] batch:[30 / 134] loss= 0.116\n",
      "epoch:[824 / 1000] batch:[60 / 134] loss= 0.079\n",
      "epoch:[824 / 1000] batch:[90 / 134] loss= 0.052\n",
      "epoch:[824 / 1000] batch:[120 / 134] loss= 0.178\n",
      "100 cycles trn_loss: 0.069, val_loss: 0.156, lr=6.579634e-05\n",
      "training set RMSE 1 cycle: 43.282, 10 cycle: 38.477, 100 cycle: 36.012\n",
      "testing set RMSE 1 cycle: 57.027, 10 cycle: 56.625, 100 cycle: 52.643\n",
      "epoch:[825 / 1000] batch:[30 / 134] loss= 0.077\n",
      "epoch:[825 / 1000] batch:[60 / 134] loss= 0.043\n",
      "epoch:[825 / 1000] batch:[90 / 134] loss= 0.175\n",
      "epoch:[825 / 1000] batch:[120 / 134] loss= 0.111\n",
      "100 cycles trn_loss: 0.066, val_loss: 0.152, lr=5.050000e-05\n",
      "training set RMSE 1 cycle: 49.365, 10 cycle: 37.480, 100 cycle: 34.501\n",
      "testing set RMSE 1 cycle: 57.392, 10 cycle: 56.330, 100 cycle: 51.285\n",
      "epoch:[826 / 1000] batch:[30 / 134] loss= 0.058\n",
      "epoch:[826 / 1000] batch:[60 / 134] loss= 0.051\n",
      "epoch:[826 / 1000] batch:[90 / 134] loss= 0.160\n",
      "epoch:[826 / 1000] batch:[120 / 134] loss= 0.062\n",
      "100 cycles trn_loss: 0.060, val_loss: 0.174, lr=3.520366e-05\n",
      "training set RMSE 1 cycle: 44.300, 10 cycle: 35.412, 100 cycle: 32.276\n",
      "testing set RMSE 1 cycle: 62.783, 10 cycle: 62.936, 100 cycle: 56.047\n",
      "epoch:[827 / 1000] batch:[30 / 134] loss= 0.141\n",
      "epoch:[827 / 1000] batch:[60 / 134] loss= 0.080\n",
      "epoch:[827 / 1000] batch:[90 / 134] loss= 0.056\n",
      "epoch:[827 / 1000] batch:[120 / 134] loss= 0.072\n",
      "100 cycles trn_loss: 0.045, val_loss: 0.143, lr=2.140463e-05\n",
      "training set RMSE 1 cycle: 41.798, 10 cycle: 31.263, 100 cycle: 28.322\n",
      "testing set RMSE 1 cycle: 58.719, 10 cycle: 56.588, 100 cycle: 50.871\n",
      "epoch:[828 / 1000] batch:[30 / 134] loss= 0.073\n",
      "epoch:[828 / 1000] batch:[60 / 134] loss= 0.061\n",
      "epoch:[828 / 1000] batch:[90 / 134] loss= 0.053\n",
      "epoch:[828 / 1000] batch:[120 / 134] loss= 0.048\n",
      "100 cycles trn_loss: 0.074, val_loss: 0.190, lr=1.045366e-05\n",
      "training set RMSE 1 cycle: 41.530, 10 cycle: 37.192, 100 cycle: 37.318\n",
      "testing set RMSE 1 cycle: 60.900, 10 cycle: 64.539, 100 cycle: 59.458\n",
      "epoch:[829 / 1000] batch:[30 / 134] loss= 0.035\n",
      "epoch:[829 / 1000] batch:[60 / 134] loss= 0.039\n",
      "epoch:[829 / 1000] batch:[90 / 134] loss= 0.030\n",
      "epoch:[829 / 1000] batch:[120 / 134] loss= 0.063\n",
      "100 cycles trn_loss: 0.042, val_loss: 0.176, lr=3.422702e-06\n",
      "training set RMSE 1 cycle: 41.476, 10 cycle: 30.470, 100 cycle: 27.297\n",
      "testing set RMSE 1 cycle: 65.041, 10 cycle: 63.951, 100 cycle: 58.956\n",
      "epoch:[830 / 1000] batch:[30 / 134] loss= 0.115\n",
      "epoch:[830 / 1000] batch:[60 / 134] loss= 0.044\n",
      "epoch:[830 / 1000] batch:[90 / 134] loss= 0.045\n",
      "epoch:[830 / 1000] batch:[120 / 134] loss= 0.045\n",
      "100 cycles trn_loss: 0.040, val_loss: 0.149, lr=1.000000e-06\n",
      "training set RMSE 1 cycle: 43.950, 10 cycle: 31.126, 100 cycle: 26.496\n",
      "testing set RMSE 1 cycle: 62.972, 10 cycle: 60.003, 100 cycle: 53.261\n",
      "epoch:[831 / 1000] batch:[30 / 134] loss= 0.062\n",
      "epoch:[831 / 1000] batch:[60 / 134] loss= 0.042\n",
      "epoch:[831 / 1000] batch:[90 / 134] loss= 0.020\n",
      "epoch:[831 / 1000] batch:[120 / 134] loss= 0.032\n",
      "100 cycles trn_loss: 0.041, val_loss: 0.168, lr=3.422702e-06\n",
      "training set RMSE 1 cycle: 42.278, 10 cycle: 30.759, 100 cycle: 26.827\n",
      "testing set RMSE 1 cycle: 64.990, 10 cycle: 63.211, 100 cycle: 57.634\n",
      "epoch:[832 / 1000] batch:[30 / 134] loss= 0.070\n",
      "epoch:[832 / 1000] batch:[60 / 134] loss= 0.049\n",
      "epoch:[832 / 1000] batch:[90 / 134] loss= 0.021\n",
      "epoch:[832 / 1000] batch:[120 / 134] loss= 0.071\n",
      "100 cycles trn_loss: 0.040, val_loss: 0.169, lr=1.045366e-05\n",
      "training set RMSE 1 cycle: 43.524, 10 cycle: 31.124, 100 cycle: 26.697\n",
      "testing set RMSE 1 cycle: 65.389, 10 cycle: 63.803, 100 cycle: 58.270\n",
      "epoch:[833 / 1000] batch:[30 / 134] loss= 0.063\n",
      "epoch:[833 / 1000] batch:[60 / 134] loss= 0.048\n",
      "epoch:[833 / 1000] batch:[90 / 134] loss= 0.122\n",
      "epoch:[833 / 1000] batch:[120 / 134] loss= 0.060\n",
      "100 cycles trn_loss: 0.039, val_loss: 0.157, lr=2.140463e-05\n",
      "training set RMSE 1 cycle: 45.482, 10 cycle: 31.561, 100 cycle: 26.245\n",
      "testing set RMSE 1 cycle: 64.407, 10 cycle: 62.210, 100 cycle: 55.577\n",
      "epoch:[834 / 1000] batch:[30 / 134] loss= 0.029\n",
      "epoch:[834 / 1000] batch:[60 / 134] loss= 0.057\n",
      "epoch:[834 / 1000] batch:[90 / 134] loss= 0.044\n",
      "epoch:[834 / 1000] batch:[120 / 134] loss= 0.040\n",
      "100 cycles trn_loss: 0.040, val_loss: 0.165, lr=3.520366e-05\n",
      "training set RMSE 1 cycle: 47.011, 10 cycle: 32.117, 100 cycle: 26.495\n",
      "testing set RMSE 1 cycle: 65.287, 10 cycle: 63.556, 100 cycle: 58.039\n",
      "epoch:[835 / 1000] batch:[30 / 134] loss= 0.107\n",
      "epoch:[835 / 1000] batch:[60 / 134] loss= 0.047\n",
      "epoch:[835 / 1000] batch:[90 / 134] loss= 0.105\n",
      "epoch:[835 / 1000] batch:[120 / 134] loss= 0.078\n",
      "100 cycles trn_loss: 0.047, val_loss: 0.174, lr=5.050000e-05\n",
      "training set RMSE 1 cycle: 44.651, 10 cycle: 30.866, 100 cycle: 28.681\n",
      "testing set RMSE 1 cycle: 63.301, 10 cycle: 62.235, 100 cycle: 57.176\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:[836 / 1000] batch:[30 / 134] loss= 0.061\n",
      "epoch:[836 / 1000] batch:[60 / 134] loss= 0.115\n",
      "epoch:[836 / 1000] batch:[90 / 134] loss= 0.106\n",
      "epoch:[836 / 1000] batch:[120 / 134] loss= 0.065\n",
      "100 cycles trn_loss: 0.057, val_loss: 0.142, lr=6.579634e-05\n",
      "training set RMSE 1 cycle: 36.720, 10 cycle: 31.596, 100 cycle: 32.223\n",
      "testing set RMSE 1 cycle: 55.154, 10 cycle: 55.683, 100 cycle: 49.711\n",
      "epoch:[837 / 1000] batch:[30 / 134] loss= 0.041\n",
      "epoch:[837 / 1000] batch:[60 / 134] loss= 0.060\n",
      "epoch:[837 / 1000] batch:[90 / 134] loss= 0.029\n",
      "epoch:[837 / 1000] batch:[120 / 134] loss= 0.054\n",
      "100 cycles trn_loss: 0.116, val_loss: 0.201, lr=7.959537e-05\n",
      "training set RMSE 1 cycle: 61.996, 10 cycle: 52.339, 100 cycle: 47.402\n",
      "testing set RMSE 1 cycle: 76.547, 10 cycle: 70.742, 100 cycle: 66.060\n",
      "epoch:[838 / 1000] batch:[30 / 134] loss= 0.077\n",
      "epoch:[838 / 1000] batch:[60 / 134] loss= 0.082\n",
      "epoch:[838 / 1000] batch:[90 / 134] loss= 0.076\n",
      "epoch:[838 / 1000] batch:[120 / 134] loss= 0.131\n",
      "100 cycles trn_loss: 0.075, val_loss: 0.133, lr=9.054634e-05\n",
      "training set RMSE 1 cycle: 52.598, 10 cycle: 42.273, 100 cycle: 37.462\n",
      "testing set RMSE 1 cycle: 55.924, 10 cycle: 52.643, 100 cycle: 49.193\n",
      "epoch:[839 / 1000] batch:[30 / 134] loss= 0.099\n",
      "epoch:[839 / 1000] batch:[60 / 134] loss= 0.035\n",
      "epoch:[839 / 1000] batch:[90 / 134] loss= 0.190\n",
      "epoch:[839 / 1000] batch:[120 / 134] loss= 0.113\n",
      "100 cycles trn_loss: 0.087, val_loss: 0.133, lr=9.757730e-05\n",
      "training set RMSE 1 cycle: 46.922, 10 cycle: 40.742, 100 cycle: 41.111\n",
      "testing set RMSE 1 cycle: 51.742, 10 cycle: 48.947, 100 cycle: 48.023\n",
      "epoch:[840 / 1000] batch:[30 / 134] loss= 0.089\n",
      "epoch:[840 / 1000] batch:[60 / 134] loss= 0.146\n",
      "epoch:[840 / 1000] batch:[90 / 134] loss= 0.081\n",
      "epoch:[840 / 1000] batch:[120 / 134] loss= 0.073\n",
      "100 cycles trn_loss: 0.072, val_loss: 0.157, lr=1.000000e-04\n",
      "training set RMSE 1 cycle: 49.179, 10 cycle: 39.552, 100 cycle: 36.474\n",
      "testing set RMSE 1 cycle: 58.196, 10 cycle: 54.586, 100 cycle: 53.318\n",
      "epoch:[841 / 1000] batch:[30 / 134] loss= 0.052\n",
      "epoch:[841 / 1000] batch:[60 / 134] loss= 0.109\n",
      "epoch:[841 / 1000] batch:[90 / 134] loss= 0.050\n",
      "epoch:[841 / 1000] batch:[120 / 134] loss= 0.075\n",
      "100 cycles trn_loss: 0.065, val_loss: 0.114, lr=9.757730e-05\n",
      "training set RMSE 1 cycle: 49.456, 10 cycle: 40.073, 100 cycle: 34.412\n",
      "testing set RMSE 1 cycle: 49.581, 10 cycle: 47.310, 100 cycle: 44.506\n",
      "epoch:[842 / 1000] batch:[30 / 134] loss= 0.142\n",
      "epoch:[842 / 1000] batch:[60 / 134] loss= 0.044\n",
      "epoch:[842 / 1000] batch:[90 / 134] loss= 0.086\n",
      "epoch:[842 / 1000] batch:[120 / 134] loss= 0.070\n",
      "100 cycles trn_loss: 0.055, val_loss: 0.091, lr=9.054634e-05\n",
      "training set RMSE 1 cycle: 46.635, 10 cycle: 35.927, 100 cycle: 31.217\n",
      "testing set RMSE 1 cycle: 44.409, 10 cycle: 43.335, 100 cycle: 39.752\n",
      "epoch:[843 / 1000] batch:[30 / 134] loss= 0.065\n",
      "epoch:[843 / 1000] batch:[60 / 134] loss= 0.155\n",
      "epoch:[843 / 1000] batch:[90 / 134] loss= 0.092\n",
      "epoch:[843 / 1000] batch:[120 / 134] loss= 0.088\n",
      "100 cycles trn_loss: 0.069, val_loss: 0.098, lr=7.959537e-05\n",
      "training set RMSE 1 cycle: 54.579, 10 cycle: 44.469, 100 cycle: 34.656\n",
      "testing set RMSE 1 cycle: 52.067, 10 cycle: 48.879, 100 cycle: 41.193\n",
      "epoch:[844 / 1000] batch:[30 / 134] loss= 0.070\n",
      "epoch:[844 / 1000] batch:[60 / 134] loss= 0.032\n",
      "epoch:[844 / 1000] batch:[90 / 134] loss= 0.051\n",
      "epoch:[844 / 1000] batch:[120 / 134] loss= 0.177\n",
      "100 cycles trn_loss: 0.055, val_loss: 0.092, lr=6.579634e-05\n",
      "training set RMSE 1 cycle: 40.863, 10 cycle: 32.708, 100 cycle: 31.312\n",
      "testing set RMSE 1 cycle: 42.512, 10 cycle: 41.986, 100 cycle: 39.906\n",
      "epoch:[845 / 1000] batch:[30 / 134] loss= 0.031\n",
      "epoch:[845 / 1000] batch:[60 / 134] loss= 0.035\n",
      "epoch:[845 / 1000] batch:[90 / 134] loss= 0.067\n",
      "epoch:[845 / 1000] batch:[120 / 134] loss= 0.032\n",
      "100 cycles trn_loss: 0.053, val_loss: 0.087, lr=5.050000e-05\n",
      "training set RMSE 1 cycle: 50.434, 10 cycle: 39.795, 100 cycle: 30.259\n",
      "testing set RMSE 1 cycle: 44.410, 10 cycle: 45.672, 100 cycle: 38.714\n",
      "epoch:[846 / 1000] batch:[30 / 134] loss= 0.045\n",
      "epoch:[846 / 1000] batch:[60 / 134] loss= 0.083\n",
      "epoch:[846 / 1000] batch:[90 / 134] loss= 0.055\n",
      "epoch:[846 / 1000] batch:[120 / 134] loss= 0.099\n",
      "100 cycles trn_loss: 0.053, val_loss: 0.117, lr=3.520366e-05\n",
      "training set RMSE 1 cycle: 42.354, 10 cycle: 35.593, 100 cycle: 30.363\n",
      "testing set RMSE 1 cycle: 51.688, 10 cycle: 48.174, 100 cycle: 44.936\n",
      "epoch:[847 / 1000] batch:[30 / 134] loss= 0.041\n",
      "epoch:[847 / 1000] batch:[60 / 134] loss= 0.094\n",
      "epoch:[847 / 1000] batch:[90 / 134] loss= 0.050\n",
      "epoch:[847 / 1000] batch:[120 / 134] loss= 0.069\n",
      "100 cycles trn_loss: 0.090, val_loss: 0.145, lr=2.140463e-05\n",
      "training set RMSE 1 cycle: 40.857, 10 cycle: 38.787, 100 cycle: 41.041\n",
      "testing set RMSE 1 cycle: 49.575, 10 cycle: 48.148, 100 cycle: 50.226\n",
      "epoch:[848 / 1000] batch:[30 / 134] loss= 0.069\n",
      "epoch:[848 / 1000] batch:[60 / 134] loss= 0.059\n",
      "epoch:[848 / 1000] batch:[90 / 134] loss= 0.051\n",
      "epoch:[848 / 1000] batch:[120 / 134] loss= 0.059\n",
      "100 cycles trn_loss: 0.038, val_loss: 0.084, lr=1.045366e-05\n",
      "training set RMSE 1 cycle: 42.057, 10 cycle: 31.219, 100 cycle: 25.481\n",
      "testing set RMSE 1 cycle: 38.705, 10 cycle: 40.863, 100 cycle: 38.038\n",
      "epoch:[849 / 1000] batch:[30 / 134] loss= 0.037\n",
      "epoch:[849 / 1000] batch:[60 / 134] loss= 0.072\n",
      "epoch:[849 / 1000] batch:[90 / 134] loss= 0.043\n",
      "epoch:[849 / 1000] batch:[120 / 134] loss= 0.060\n",
      "100 cycles trn_loss: 0.036, val_loss: 0.091, lr=3.422702e-06\n",
      "training set RMSE 1 cycle: 39.430, 10 cycle: 30.003, 100 cycle: 24.985\n",
      "testing set RMSE 1 cycle: 40.119, 10 cycle: 41.200, 100 cycle: 39.639\n",
      "epoch:[850 / 1000] batch:[30 / 134] loss= 0.023\n",
      "epoch:[850 / 1000] batch:[60 / 134] loss= 0.027\n",
      "epoch:[850 / 1000] batch:[90 / 134] loss= 0.049\n",
      "epoch:[850 / 1000] batch:[120 / 134] loss= 0.029\n",
      "100 cycles trn_loss: 0.036, val_loss: 0.089, lr=1.000000e-06\n",
      "training set RMSE 1 cycle: 39.308, 10 cycle: 29.100, 100 cycle: 25.037\n",
      "testing set RMSE 1 cycle: 37.945, 10 cycle: 40.996, 100 cycle: 39.289\n",
      "epoch:[851 / 1000] batch:[30 / 134] loss= 0.069\n",
      "epoch:[851 / 1000] batch:[60 / 134] loss= 0.041\n",
      "epoch:[851 / 1000] batch:[90 / 134] loss= 0.063\n",
      "epoch:[851 / 1000] batch:[120 / 134] loss= 0.037\n",
      "100 cycles trn_loss: 0.035, val_loss: 0.088, lr=3.422702e-06\n",
      "training set RMSE 1 cycle: 39.838, 10 cycle: 29.560, 100 cycle: 24.711\n",
      "testing set RMSE 1 cycle: 38.201, 10 cycle: 40.937, 100 cycle: 38.922\n",
      "epoch:[852 / 1000] batch:[30 / 134] loss= 0.024\n",
      "epoch:[852 / 1000] batch:[60 / 134] loss= 0.038\n",
      "epoch:[852 / 1000] batch:[90 / 134] loss= 0.051\n",
      "epoch:[852 / 1000] batch:[120 / 134] loss= 0.058\n",
      "100 cycles trn_loss: 0.039, val_loss: 0.096, lr=1.045366e-05\n",
      "training set RMSE 1 cycle: 37.693, 10 cycle: 28.284, 100 cycle: 26.095\n",
      "testing set RMSE 1 cycle: 38.218, 10 cycle: 41.931, 100 cycle: 40.711\n",
      "epoch:[853 / 1000] batch:[30 / 134] loss= 0.069\n",
      "epoch:[853 / 1000] batch:[60 / 134] loss= 0.033\n",
      "epoch:[853 / 1000] batch:[90 / 134] loss= 0.037\n",
      "epoch:[853 / 1000] batch:[120 / 134] loss= 0.029\n",
      "100 cycles trn_loss: 0.039, val_loss: 0.098, lr=2.140463e-05\n",
      "training set RMSE 1 cycle: 38.318, 10 cycle: 28.895, 100 cycle: 26.020\n",
      "testing set RMSE 1 cycle: 38.154, 10 cycle: 42.212, 100 cycle: 41.152\n",
      "epoch:[854 / 1000] batch:[30 / 134] loss= 0.056\n",
      "epoch:[854 / 1000] batch:[60 / 134] loss= 0.033\n",
      "epoch:[854 / 1000] batch:[90 / 134] loss= 0.030\n",
      "epoch:[854 / 1000] batch:[120 / 134] loss= 0.037\n",
      "100 cycles trn_loss: 0.033, val_loss: 0.091, lr=3.520366e-05\n",
      "training set RMSE 1 cycle: 40.430, 10 cycle: 29.677, 100 cycle: 24.008\n",
      "testing set RMSE 1 cycle: 38.713, 10 cycle: 41.634, 100 cycle: 39.596\n",
      "epoch:[855 / 1000] batch:[30 / 134] loss= 0.055\n",
      "epoch:[855 / 1000] batch:[60 / 134] loss= 0.031\n",
      "epoch:[855 / 1000] batch:[90 / 134] loss= 0.061\n",
      "epoch:[855 / 1000] batch:[120 / 134] loss= 0.032\n",
      "100 cycles trn_loss: 0.034, val_loss: 0.092, lr=5.050000e-05\n",
      "training set RMSE 1 cycle: 39.642, 10 cycle: 31.045, 100 cycle: 24.186\n",
      "testing set RMSE 1 cycle: 38.062, 10 cycle: 40.611, 100 cycle: 39.833\n",
      "epoch:[856 / 1000] batch:[30 / 134] loss= 0.040\n",
      "epoch:[856 / 1000] batch:[60 / 134] loss= 0.100\n",
      "epoch:[856 / 1000] batch:[90 / 134] loss= 0.058\n",
      "epoch:[856 / 1000] batch:[120 / 134] loss= 0.055\n",
      "100 cycles trn_loss: 0.047, val_loss: 0.095, lr=6.579634e-05\n",
      "training set RMSE 1 cycle: 36.592, 10 cycle: 28.584, 100 cycle: 28.860\n",
      "testing set RMSE 1 cycle: 40.930, 10 cycle: 42.490, 100 cycle: 40.504\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:[857 / 1000] batch:[30 / 134] loss= 0.029\n",
      "epoch:[857 / 1000] batch:[60 / 134] loss= 0.092\n",
      "epoch:[857 / 1000] batch:[90 / 134] loss= 0.045\n",
      "epoch:[857 / 1000] batch:[120 / 134] loss= 0.029\n",
      "100 cycles trn_loss: 0.046, val_loss: 0.113, lr=7.959537e-05\n",
      "training set RMSE 1 cycle: 39.659, 10 cycle: 31.365, 100 cycle: 28.155\n",
      "testing set RMSE 1 cycle: 42.833, 10 cycle: 44.953, 100 cycle: 44.273\n",
      "epoch:[858 / 1000] batch:[30 / 134] loss= 0.180\n",
      "epoch:[858 / 1000] batch:[60 / 134] loss= 0.106\n",
      "epoch:[858 / 1000] batch:[90 / 134] loss= 0.049\n",
      "epoch:[858 / 1000] batch:[120 / 134] loss= 0.059\n",
      "100 cycles trn_loss: 0.049, val_loss: 0.106, lr=9.054634e-05\n",
      "training set RMSE 1 cycle: 40.715, 10 cycle: 32.308, 100 cycle: 29.208\n",
      "testing set RMSE 1 cycle: 49.266, 10 cycle: 45.689, 100 cycle: 42.828\n",
      "epoch:[859 / 1000] batch:[30 / 134] loss= 0.126\n",
      "epoch:[859 / 1000] batch:[60 / 134] loss= 0.026\n",
      "epoch:[859 / 1000] batch:[90 / 134] loss= 0.072\n",
      "epoch:[859 / 1000] batch:[120 / 134] loss= 0.062\n",
      "100 cycles trn_loss: 0.050, val_loss: 0.094, lr=9.757730e-05\n",
      "training set RMSE 1 cycle: 41.196, 10 cycle: 32.058, 100 cycle: 30.242\n",
      "testing set RMSE 1 cycle: 40.610, 10 cycle: 43.533, 100 cycle: 40.301\n",
      "epoch:[860 / 1000] batch:[30 / 134] loss= 0.144\n",
      "epoch:[860 / 1000] batch:[60 / 134] loss= 0.073\n",
      "epoch:[860 / 1000] batch:[90 / 134] loss= 0.126\n",
      "epoch:[860 / 1000] batch:[120 / 134] loss= 0.052\n",
      "100 cycles trn_loss: 0.169, val_loss: 0.207, lr=1.000000e-04\n",
      "training set RMSE 1 cycle: 72.166, 10 cycle: 63.048, 100 cycle: 60.096\n",
      "testing set RMSE 1 cycle: 65.720, 10 cycle: 65.982, 100 cycle: 64.476\n",
      "epoch:[861 / 1000] batch:[30 / 134] loss= 0.086\n",
      "epoch:[861 / 1000] batch:[60 / 134] loss= 0.075\n",
      "epoch:[861 / 1000] batch:[90 / 134] loss= 0.054\n",
      "epoch:[861 / 1000] batch:[120 / 134] loss= 0.066\n",
      "100 cycles trn_loss: 0.076, val_loss: 0.145, lr=9.757730e-05\n",
      "training set RMSE 1 cycle: 54.964, 10 cycle: 47.681, 100 cycle: 36.292\n",
      "testing set RMSE 1 cycle: 57.919, 10 cycle: 55.853, 100 cycle: 52.042\n",
      "epoch:[862 / 1000] batch:[30 / 134] loss= 0.104\n",
      "epoch:[862 / 1000] batch:[60 / 134] loss= 0.056\n",
      "epoch:[862 / 1000] batch:[90 / 134] loss= 0.022\n",
      "epoch:[862 / 1000] batch:[120 / 134] loss= 0.264\n",
      "100 cycles trn_loss: 0.155, val_loss: 0.173, lr=9.054634e-05\n",
      "training set RMSE 1 cycle: 70.770, 10 cycle: 63.083, 100 cycle: 54.352\n",
      "testing set RMSE 1 cycle: 59.598, 10 cycle: 58.151, 100 cycle: 54.808\n",
      "epoch:[863 / 1000] batch:[30 / 134] loss= 0.083\n",
      "epoch:[863 / 1000] batch:[60 / 134] loss= 0.089\n",
      "epoch:[863 / 1000] batch:[90 / 134] loss= 0.167\n",
      "epoch:[863 / 1000] batch:[120 / 134] loss= 0.091\n",
      "100 cycles trn_loss: 0.057, val_loss: 0.134, lr=7.959537e-05\n",
      "training set RMSE 1 cycle: 37.035, 10 cycle: 33.678, 100 cycle: 32.262\n",
      "testing set RMSE 1 cycle: 57.599, 10 cycle: 54.718, 100 cycle: 48.132\n",
      "epoch:[864 / 1000] batch:[30 / 134] loss= 0.062\n",
      "epoch:[864 / 1000] batch:[60 / 134] loss= 0.034\n",
      "epoch:[864 / 1000] batch:[90 / 134] loss= 0.036\n",
      "epoch:[864 / 1000] batch:[120 / 134] loss= 0.061\n",
      "100 cycles trn_loss: 0.048, val_loss: 0.106, lr=6.579634e-05\n",
      "training set RMSE 1 cycle: 36.397, 10 cycle: 30.628, 100 cycle: 29.512\n",
      "testing set RMSE 1 cycle: 43.428, 10 cycle: 43.716, 100 cycle: 42.783\n",
      "epoch:[865 / 1000] batch:[30 / 134] loss= 0.041\n",
      "epoch:[865 / 1000] batch:[60 / 134] loss= 0.056\n",
      "epoch:[865 / 1000] batch:[90 / 134] loss= 0.056\n",
      "epoch:[865 / 1000] batch:[120 / 134] loss= 0.129\n",
      "100 cycles trn_loss: 0.031, val_loss: 0.106, lr=5.050000e-05\n",
      "training set RMSE 1 cycle: 32.446, 10 cycle: 25.083, 100 cycle: 23.194\n",
      "testing set RMSE 1 cycle: 44.595, 10 cycle: 46.561, 100 cycle: 42.825\n",
      "epoch:[866 / 1000] batch:[30 / 134] loss= 0.036\n",
      "epoch:[866 / 1000] batch:[60 / 134] loss= 0.065\n",
      "epoch:[866 / 1000] batch:[90 / 134] loss= 0.039\n",
      "epoch:[866 / 1000] batch:[120 / 134] loss= 0.036\n",
      "100 cycles trn_loss: 0.026, val_loss: 0.107, lr=3.520366e-05\n",
      "training set RMSE 1 cycle: 39.639, 10 cycle: 28.827, 100 cycle: 21.022\n",
      "testing set RMSE 1 cycle: 47.824, 10 cycle: 50.474, 100 cycle: 42.995\n",
      "epoch:[867 / 1000] batch:[30 / 134] loss= 0.057\n",
      "epoch:[867 / 1000] batch:[60 / 134] loss= 0.061\n",
      "epoch:[867 / 1000] batch:[90 / 134] loss= 0.045\n",
      "epoch:[867 / 1000] batch:[120 / 134] loss= 0.023\n",
      "100 cycles trn_loss: 0.033, val_loss: 0.113, lr=2.140463e-05\n",
      "training set RMSE 1 cycle: 29.732, 10 cycle: 23.910, 100 cycle: 24.138\n",
      "testing set RMSE 1 cycle: 43.285, 10 cycle: 48.970, 100 cycle: 44.280\n",
      "epoch:[868 / 1000] batch:[30 / 134] loss= 0.021\n",
      "epoch:[868 / 1000] batch:[60 / 134] loss= 0.052\n",
      "epoch:[868 / 1000] batch:[90 / 134] loss= 0.046\n",
      "epoch:[868 / 1000] batch:[120 / 134] loss= 0.043\n",
      "100 cycles trn_loss: 0.026, val_loss: 0.113, lr=1.045366e-05\n",
      "training set RMSE 1 cycle: 38.908, 10 cycle: 29.333, 100 cycle: 21.037\n",
      "testing set RMSE 1 cycle: 49.739, 10 cycle: 52.244, 100 cycle: 44.279\n",
      "epoch:[869 / 1000] batch:[30 / 134] loss= 0.032\n",
      "epoch:[869 / 1000] batch:[60 / 134] loss= 0.038\n",
      "epoch:[869 / 1000] batch:[90 / 134] loss= 0.053\n",
      "epoch:[869 / 1000] batch:[120 / 134] loss= 0.040\n",
      "100 cycles trn_loss: 0.022, val_loss: 0.109, lr=3.422702e-06\n",
      "training set RMSE 1 cycle: 33.262, 10 cycle: 24.147, 100 cycle: 19.547\n",
      "testing set RMSE 1 cycle: 45.780, 10 cycle: 49.310, 100 cycle: 43.385\n",
      "epoch:[870 / 1000] batch:[30 / 134] loss= 0.018\n",
      "epoch:[870 / 1000] batch:[60 / 134] loss= 0.031\n",
      "epoch:[870 / 1000] batch:[90 / 134] loss= 0.041\n",
      "epoch:[870 / 1000] batch:[120 / 134] loss= 0.027\n",
      "100 cycles trn_loss: 0.024, val_loss: 0.111, lr=1.000000e-06\n",
      "training set RMSE 1 cycle: 30.948, 10 cycle: 23.164, 100 cycle: 20.435\n",
      "testing set RMSE 1 cycle: 44.165, 10 cycle: 48.676, 100 cycle: 43.860\n",
      "epoch:[871 / 1000] batch:[30 / 134] loss= 0.028\n",
      "epoch:[871 / 1000] batch:[60 / 134] loss= 0.061\n",
      "epoch:[871 / 1000] batch:[90 / 134] loss= 0.034\n",
      "epoch:[871 / 1000] batch:[120 / 134] loss= 0.043\n",
      "100 cycles trn_loss: 0.022, val_loss: 0.109, lr=3.422702e-06\n",
      "training set RMSE 1 cycle: 32.187, 10 cycle: 23.406, 100 cycle: 19.630\n",
      "testing set RMSE 1 cycle: 44.167, 10 cycle: 48.558, 100 cycle: 43.364\n",
      "epoch:[872 / 1000] batch:[30 / 134] loss= 0.073\n",
      "epoch:[872 / 1000] batch:[60 / 134] loss= 0.032\n",
      "epoch:[872 / 1000] batch:[90 / 134] loss= 0.037\n",
      "epoch:[872 / 1000] batch:[120 / 134] loss= 0.025\n",
      "100 cycles trn_loss: 0.021, val_loss: 0.109, lr=1.045366e-05\n",
      "training set RMSE 1 cycle: 33.321, 10 cycle: 24.027, 100 cycle: 19.275\n",
      "testing set RMSE 1 cycle: 45.446, 10 cycle: 49.239, 100 cycle: 43.376\n",
      "epoch:[873 / 1000] batch:[30 / 134] loss= 0.025\n",
      "epoch:[873 / 1000] batch:[60 / 134] loss= 0.038\n",
      "epoch:[873 / 1000] batch:[90 / 134] loss= 0.035\n",
      "epoch:[873 / 1000] batch:[120 / 134] loss= 0.052\n",
      "100 cycles trn_loss: 0.021, val_loss: 0.111, lr=2.140463e-05\n",
      "training set RMSE 1 cycle: 33.359, 10 cycle: 24.214, 100 cycle: 19.046\n",
      "testing set RMSE 1 cycle: 46.174, 10 cycle: 49.915, 100 cycle: 43.771\n",
      "epoch:[874 / 1000] batch:[30 / 134] loss= 0.042\n",
      "epoch:[874 / 1000] batch:[60 / 134] loss= 0.035\n",
      "epoch:[874 / 1000] batch:[90 / 134] loss= 0.020\n",
      "epoch:[874 / 1000] batch:[120 / 134] loss= 0.034\n",
      "100 cycles trn_loss: 0.022, val_loss: 0.107, lr=3.520366e-05\n",
      "training set RMSE 1 cycle: 32.271, 10 cycle: 24.710, 100 cycle: 19.578\n",
      "testing set RMSE 1 cycle: 43.113, 10 cycle: 47.290, 100 cycle: 42.947\n",
      "epoch:[875 / 1000] batch:[30 / 134] loss= 0.043\n",
      "epoch:[875 / 1000] batch:[60 / 134] loss= 0.031\n",
      "epoch:[875 / 1000] batch:[90 / 134] loss= 0.033\n",
      "epoch:[875 / 1000] batch:[120 / 134] loss= 0.020\n",
      "100 cycles trn_loss: 0.026, val_loss: 0.118, lr=5.050000e-05\n",
      "training set RMSE 1 cycle: 29.054, 10 cycle: 21.599, 100 cycle: 21.101\n",
      "testing set RMSE 1 cycle: 40.916, 10 cycle: 49.675, 100 cycle: 45.142\n",
      "epoch:[876 / 1000] batch:[30 / 134] loss= 0.058\n",
      "epoch:[876 / 1000] batch:[60 / 134] loss= 0.031\n",
      "epoch:[876 / 1000] batch:[90 / 134] loss= 0.053\n",
      "epoch:[876 / 1000] batch:[120 / 134] loss= 0.036\n",
      "100 cycles trn_loss: 0.047, val_loss: 0.132, lr=6.579634e-05\n",
      "training set RMSE 1 cycle: 43.805, 10 cycle: 37.844, 100 cycle: 28.898\n",
      "testing set RMSE 1 cycle: 54.118, 10 cycle: 51.513, 100 cycle: 47.823\n",
      "epoch:[877 / 1000] batch:[30 / 134] loss= 0.181\n",
      "epoch:[877 / 1000] batch:[60 / 134] loss= 0.105\n",
      "epoch:[877 / 1000] batch:[90 / 134] loss= 0.109\n",
      "epoch:[877 / 1000] batch:[120 / 134] loss= 0.021\n",
      "100 cycles trn_loss: 0.036, val_loss: 0.144, lr=7.959537e-05\n",
      "training set RMSE 1 cycle: 37.913, 10 cycle: 30.790, 100 cycle: 25.062\n",
      "testing set RMSE 1 cycle: 51.484, 10 cycle: 54.653, 100 cycle: 50.400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:[878 / 1000] batch:[30 / 134] loss= 0.037\n",
      "epoch:[878 / 1000] batch:[60 / 134] loss= 0.030\n",
      "epoch:[878 / 1000] batch:[90 / 134] loss= 0.079\n",
      "epoch:[878 / 1000] batch:[120 / 134] loss= 0.144\n",
      "100 cycles trn_loss: 0.052, val_loss: 0.169, lr=9.054634e-05\n",
      "training set RMSE 1 cycle: 44.460, 10 cycle: 38.117, 100 cycle: 30.137\n",
      "testing set RMSE 1 cycle: 62.692, 10 cycle: 64.501, 100 cycle: 57.347\n",
      "epoch:[879 / 1000] batch:[30 / 134] loss= 0.056\n",
      "epoch:[879 / 1000] batch:[60 / 134] loss= 0.113\n",
      "epoch:[879 / 1000] batch:[90 / 134] loss= 0.069\n",
      "epoch:[879 / 1000] batch:[120 / 134] loss= 0.061\n",
      "100 cycles trn_loss: 0.079, val_loss: 0.149, lr=9.757730e-05\n",
      "training set RMSE 1 cycle: 38.706, 10 cycle: 36.301, 100 cycle: 37.944\n",
      "testing set RMSE 1 cycle: 48.079, 10 cycle: 48.142, 100 cycle: 51.010\n",
      "epoch:[880 / 1000] batch:[30 / 134] loss= 0.082\n",
      "epoch:[880 / 1000] batch:[60 / 134] loss= 0.078\n",
      "epoch:[880 / 1000] batch:[90 / 134] loss= 0.129\n",
      "epoch:[880 / 1000] batch:[120 / 134] loss= 0.057\n",
      "100 cycles trn_loss: 0.095, val_loss: 0.152, lr=1.000000e-04\n",
      "training set RMSE 1 cycle: 44.076, 10 cycle: 41.950, 100 cycle: 42.892\n",
      "testing set RMSE 1 cycle: 52.535, 10 cycle: 52.184, 100 cycle: 51.376\n",
      "epoch:[881 / 1000] batch:[30 / 134] loss= 0.094\n",
      "epoch:[881 / 1000] batch:[60 / 134] loss= 0.084\n",
      "epoch:[881 / 1000] batch:[90 / 134] loss= 0.027\n",
      "epoch:[881 / 1000] batch:[120 / 134] loss= 0.079\n",
      "100 cycles trn_loss: 0.042, val_loss: 0.112, lr=9.757730e-05\n",
      "training set RMSE 1 cycle: 32.297, 10 cycle: 28.248, 100 cycle: 27.395\n",
      "testing set RMSE 1 cycle: 43.695, 10 cycle: 47.646, 100 cycle: 44.113\n",
      "epoch:[882 / 1000] batch:[30 / 134] loss= 0.049\n",
      "epoch:[882 / 1000] batch:[60 / 134] loss= 0.066\n",
      "epoch:[882 / 1000] batch:[90 / 134] loss= 0.036\n",
      "epoch:[882 / 1000] batch:[120 / 134] loss= 0.038\n",
      "100 cycles trn_loss: 0.038, val_loss: 0.139, lr=9.054634e-05\n",
      "training set RMSE 1 cycle: 42.710, 10 cycle: 32.023, 100 cycle: 25.688\n",
      "testing set RMSE 1 cycle: 52.792, 10 cycle: 53.871, 100 cycle: 49.514\n",
      "epoch:[883 / 1000] batch:[30 / 134] loss= 0.192\n",
      "epoch:[883 / 1000] batch:[60 / 134] loss= 0.081\n",
      "epoch:[883 / 1000] batch:[90 / 134] loss= 0.031\n",
      "epoch:[883 / 1000] batch:[120 / 134] loss= 0.059\n",
      "100 cycles trn_loss: 0.048, val_loss: 0.144, lr=7.959537e-05\n",
      "training set RMSE 1 cycle: 43.636, 10 cycle: 32.740, 100 cycle: 28.814\n",
      "testing set RMSE 1 cycle: 50.869, 10 cycle: 51.076, 100 cycle: 50.077\n",
      "epoch:[884 / 1000] batch:[30 / 134] loss= 0.072\n",
      "epoch:[884 / 1000] batch:[60 / 134] loss= 0.111\n",
      "epoch:[884 / 1000] batch:[90 / 134] loss= 0.036\n",
      "epoch:[884 / 1000] batch:[120 / 134] loss= 0.060\n",
      "100 cycles trn_loss: 0.034, val_loss: 0.104, lr=6.579634e-05\n",
      "training set RMSE 1 cycle: 39.886, 10 cycle: 28.140, 100 cycle: 24.450\n",
      "testing set RMSE 1 cycle: 45.856, 10 cycle: 45.214, 100 cycle: 42.465\n",
      "epoch:[885 / 1000] batch:[30 / 134] loss= 0.069\n",
      "epoch:[885 / 1000] batch:[60 / 134] loss= 0.033\n",
      "epoch:[885 / 1000] batch:[90 / 134] loss= 0.062\n",
      "epoch:[885 / 1000] batch:[120 / 134] loss= 0.051\n",
      "100 cycles trn_loss: 0.032, val_loss: 0.124, lr=5.050000e-05\n",
      "training set RMSE 1 cycle: 35.431, 10 cycle: 24.316, 100 cycle: 23.634\n",
      "testing set RMSE 1 cycle: 45.484, 10 cycle: 45.468, 100 cycle: 46.291\n",
      "epoch:[886 / 1000] batch:[30 / 134] loss= 0.101\n",
      "epoch:[886 / 1000] batch:[60 / 134] loss= 0.043\n",
      "epoch:[886 / 1000] batch:[90 / 134] loss= 0.034\n",
      "epoch:[886 / 1000] batch:[120 / 134] loss= 0.036\n",
      "100 cycles trn_loss: 0.025, val_loss: 0.099, lr=3.520366e-05\n",
      "training set RMSE 1 cycle: 38.350, 10 cycle: 27.153, 100 cycle: 20.750\n",
      "testing set RMSE 1 cycle: 47.266, 10 cycle: 45.840, 100 cycle: 41.345\n",
      "epoch:[887 / 1000] batch:[30 / 134] loss= 0.029\n",
      "epoch:[887 / 1000] batch:[60 / 134] loss= 0.024\n",
      "epoch:[887 / 1000] batch:[90 / 134] loss= 0.031\n",
      "epoch:[887 / 1000] batch:[120 / 134] loss= 0.023\n",
      "100 cycles trn_loss: 0.024, val_loss: 0.116, lr=2.140463e-05\n",
      "training set RMSE 1 cycle: 41.541, 10 cycle: 30.436, 100 cycle: 20.272\n",
      "testing set RMSE 1 cycle: 50.556, 10 cycle: 51.542, 100 cycle: 44.967\n",
      "epoch:[888 / 1000] batch:[30 / 134] loss= 0.037\n",
      "epoch:[888 / 1000] batch:[60 / 134] loss= 0.030\n",
      "epoch:[888 / 1000] batch:[90 / 134] loss= 0.023\n",
      "epoch:[888 / 1000] batch:[120 / 134] loss= 0.028\n",
      "100 cycles trn_loss: 0.019, val_loss: 0.111, lr=1.045366e-05\n",
      "training set RMSE 1 cycle: 35.398, 10 cycle: 25.090, 100 cycle: 17.938\n",
      "testing set RMSE 1 cycle: 49.005, 10 cycle: 47.224, 100 cycle: 43.824\n",
      "epoch:[889 / 1000] batch:[30 / 134] loss= 0.038\n",
      "epoch:[889 / 1000] batch:[60 / 134] loss= 0.028\n",
      "epoch:[889 / 1000] batch:[90 / 134] loss= 0.023\n",
      "epoch:[889 / 1000] batch:[120 / 134] loss= 0.024\n",
      "100 cycles trn_loss: 0.019, val_loss: 0.105, lr=3.422702e-06\n",
      "training set RMSE 1 cycle: 33.299, 10 cycle: 22.729, 100 cycle: 18.186\n",
      "testing set RMSE 1 cycle: 45.495, 10 cycle: 44.404, 100 cycle: 42.549\n",
      "epoch:[890 / 1000] batch:[30 / 134] loss= 0.054\n",
      "epoch:[890 / 1000] batch:[60 / 134] loss= 0.023\n",
      "epoch:[890 / 1000] batch:[90 / 134] loss= 0.029\n",
      "epoch:[890 / 1000] batch:[120 / 134] loss= 0.038\n",
      "100 cycles trn_loss: 0.018, val_loss: 0.101, lr=1.000000e-06\n",
      "training set RMSE 1 cycle: 34.023, 10 cycle: 23.364, 100 cycle: 17.527\n",
      "testing set RMSE 1 cycle: 45.992, 10 cycle: 44.418, 100 cycle: 41.782\n",
      "epoch:[891 / 1000] batch:[30 / 134] loss= 0.018\n",
      "epoch:[891 / 1000] batch:[60 / 134] loss= 0.036\n",
      "epoch:[891 / 1000] batch:[90 / 134] loss= 0.027\n",
      "epoch:[891 / 1000] batch:[120 / 134] loss= 0.028\n",
      "100 cycles trn_loss: 0.019, val_loss: 0.104, lr=3.422702e-06\n",
      "training set RMSE 1 cycle: 33.195, 10 cycle: 22.556, 100 cycle: 18.089\n",
      "testing set RMSE 1 cycle: 45.458, 10 cycle: 44.051, 100 cycle: 42.312\n",
      "epoch:[892 / 1000] batch:[30 / 134] loss= 0.018\n",
      "epoch:[892 / 1000] batch:[60 / 134] loss= 0.067\n",
      "epoch:[892 / 1000] batch:[90 / 134] loss= 0.048\n",
      "epoch:[892 / 1000] batch:[120 / 134] loss= 0.051\n",
      "100 cycles trn_loss: 0.019, val_loss: 0.100, lr=1.045366e-05\n",
      "training set RMSE 1 cycle: 33.518, 10 cycle: 22.485, 100 cycle: 18.100\n",
      "testing set RMSE 1 cycle: 44.867, 10 cycle: 43.052, 100 cycle: 41.570\n",
      "epoch:[893 / 1000] batch:[30 / 134] loss= 0.031\n",
      "epoch:[893 / 1000] batch:[60 / 134] loss= 0.030\n",
      "epoch:[893 / 1000] batch:[90 / 134] loss= 0.038\n",
      "epoch:[893 / 1000] batch:[120 / 134] loss= 0.087\n",
      "100 cycles trn_loss: 0.022, val_loss: 0.112, lr=2.140463e-05\n",
      "training set RMSE 1 cycle: 31.481, 10 cycle: 21.523, 100 cycle: 19.549\n",
      "testing set RMSE 1 cycle: 45.713, 10 cycle: 44.634, 100 cycle: 44.086\n",
      "epoch:[894 / 1000] batch:[30 / 134] loss= 0.024\n",
      "epoch:[894 / 1000] batch:[60 / 134] loss= 0.066\n",
      "epoch:[894 / 1000] batch:[90 / 134] loss= 0.031\n",
      "epoch:[894 / 1000] batch:[120 / 134] loss= 0.033\n",
      "100 cycles trn_loss: 0.017, val_loss: 0.100, lr=3.520366e-05\n",
      "training set RMSE 1 cycle: 34.384, 10 cycle: 23.664, 100 cycle: 17.367\n",
      "testing set RMSE 1 cycle: 48.459, 10 cycle: 45.287, 100 cycle: 41.581\n",
      "epoch:[895 / 1000] batch:[30 / 134] loss= 0.029\n",
      "epoch:[895 / 1000] batch:[60 / 134] loss= 0.025\n",
      "epoch:[895 / 1000] batch:[90 / 134] loss= 0.014\n",
      "epoch:[895 / 1000] batch:[120 / 134] loss= 0.011\n",
      "100 cycles trn_loss: 0.022, val_loss: 0.106, lr=5.050000e-05\n",
      "training set RMSE 1 cycle: 31.507, 10 cycle: 21.919, 100 cycle: 19.382\n",
      "testing set RMSE 1 cycle: 47.249, 10 cycle: 44.852, 100 cycle: 42.892\n",
      "epoch:[896 / 1000] batch:[30 / 134] loss= 0.022\n",
      "epoch:[896 / 1000] batch:[60 / 134] loss= 0.035\n",
      "epoch:[896 / 1000] batch:[90 / 134] loss= 0.037\n",
      "epoch:[896 / 1000] batch:[120 / 134] loss= 0.046\n",
      "100 cycles trn_loss: 0.029, val_loss: 0.117, lr=6.579634e-05\n",
      "training set RMSE 1 cycle: 29.392, 10 cycle: 21.514, 100 cycle: 22.330\n",
      "testing set RMSE 1 cycle: 45.416, 10 cycle: 44.757, 100 cycle: 45.047\n",
      "epoch:[897 / 1000] batch:[30 / 134] loss= 0.052\n",
      "epoch:[897 / 1000] batch:[60 / 134] loss= 0.062\n",
      "epoch:[897 / 1000] batch:[90 / 134] loss= 0.028\n",
      "epoch:[897 / 1000] batch:[120 / 134] loss= 0.029\n",
      "100 cycles trn_loss: 0.063, val_loss: 0.116, lr=7.959537e-05\n",
      "training set RMSE 1 cycle: 36.917, 10 cycle: 34.327, 100 cycle: 34.789\n",
      "testing set RMSE 1 cycle: 45.796, 10 cycle: 43.988, 100 cycle: 44.893\n",
      "epoch:[898 / 1000] batch:[30 / 134] loss= 0.031\n",
      "epoch:[898 / 1000] batch:[60 / 134] loss= 0.023\n",
      "epoch:[898 / 1000] batch:[90 / 134] loss= 0.055\n",
      "epoch:[898 / 1000] batch:[120 / 134] loss= 0.022\n",
      "100 cycles trn_loss: 0.032, val_loss: 0.121, lr=9.054634e-05\n",
      "training set RMSE 1 cycle: 27.543, 10 cycle: 22.891, 100 cycle: 23.767\n",
      "testing set RMSE 1 cycle: 49.638, 10 cycle: 47.066, 100 cycle: 45.957\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:[899 / 1000] batch:[30 / 134] loss= 0.194\n",
      "epoch:[899 / 1000] batch:[60 / 134] loss= 0.027\n",
      "epoch:[899 / 1000] batch:[90 / 134] loss= 0.031\n",
      "epoch:[899 / 1000] batch:[120 / 134] loss= 0.040\n",
      "100 cycles trn_loss: 0.099, val_loss: 0.121, lr=9.757730e-05\n",
      "training set RMSE 1 cycle: 44.403, 10 cycle: 45.188, 100 cycle: 44.548\n",
      "testing set RMSE 1 cycle: 51.356, 10 cycle: 43.592, 100 cycle: 45.746\n",
      "epoch:[900 / 1000] batch:[30 / 134] loss= 0.077\n",
      "epoch:[900 / 1000] batch:[60 / 134] loss= 0.029\n",
      "epoch:[900 / 1000] batch:[90 / 134] loss= 0.092\n",
      "epoch:[900 / 1000] batch:[120 / 134] loss= 0.022\n",
      "100 cycles trn_loss: 0.019, val_loss: 0.103, lr=1.000000e-04\n",
      "training set RMSE 1 cycle: 34.652, 10 cycle: 25.590, 100 cycle: 18.000\n",
      "testing set RMSE 1 cycle: 45.845, 10 cycle: 46.492, 100 cycle: 42.244\n",
      "epoch:[901 / 1000] batch:[30 / 134] loss= 0.031\n",
      "epoch:[901 / 1000] batch:[60 / 134] loss= 0.026\n",
      "epoch:[901 / 1000] batch:[90 / 134] loss= 0.025\n",
      "epoch:[901 / 1000] batch:[120 / 134] loss= 0.079\n",
      "100 cycles trn_loss: 0.162, val_loss: 0.216, lr=9.757730e-05\n",
      "training set RMSE 1 cycle: 64.098, 10 cycle: 60.925, 100 cycle: 59.250\n",
      "testing set RMSE 1 cycle: 62.932, 10 cycle: 62.354, 100 cycle: 63.583\n",
      "epoch:[902 / 1000] batch:[30 / 134] loss= 0.038\n",
      "epoch:[902 / 1000] batch:[60 / 134] loss= 0.037\n",
      "epoch:[902 / 1000] batch:[90 / 134] loss= 0.094\n",
      "epoch:[902 / 1000] batch:[120 / 134] loss= 0.035\n",
      "100 cycles trn_loss: 0.115, val_loss: 0.161, lr=9.054634e-05\n",
      "training set RMSE 1 cycle: 48.659, 10 cycle: 49.863, 100 cycle: 49.517\n",
      "testing set RMSE 1 cycle: 54.188, 10 cycle: 48.036, 100 cycle: 52.886\n",
      "epoch:[903 / 1000] batch:[30 / 134] loss= 0.049\n",
      "epoch:[903 / 1000] batch:[60 / 134] loss= 0.034\n",
      "epoch:[903 / 1000] batch:[90 / 134] loss= 0.064\n",
      "epoch:[903 / 1000] batch:[120 / 134] loss= 0.043\n",
      "100 cycles trn_loss: 0.060, val_loss: 0.162, lr=7.959537e-05\n",
      "training set RMSE 1 cycle: 35.105, 10 cycle: 30.792, 100 cycle: 32.899\n",
      "testing set RMSE 1 cycle: 49.659, 10 cycle: 51.107, 100 cycle: 53.221\n",
      "epoch:[904 / 1000] batch:[30 / 134] loss= 0.032\n",
      "epoch:[904 / 1000] batch:[60 / 134] loss= 0.017\n",
      "epoch:[904 / 1000] batch:[90 / 134] loss= 0.037\n",
      "epoch:[904 / 1000] batch:[120 / 134] loss= 0.085\n",
      "100 cycles trn_loss: 0.057, val_loss: 0.170, lr=6.579634e-05\n",
      "training set RMSE 1 cycle: 41.787, 10 cycle: 36.130, 100 cycle: 32.479\n",
      "testing set RMSE 1 cycle: 57.321, 10 cycle: 56.705, 100 cycle: 54.681\n",
      "epoch:[905 / 1000] batch:[30 / 134] loss= 0.040\n",
      "epoch:[905 / 1000] batch:[60 / 134] loss= 0.027\n",
      "epoch:[905 / 1000] batch:[90 / 134] loss= 0.039\n",
      "epoch:[905 / 1000] batch:[120 / 134] loss= 0.019\n",
      "100 cycles trn_loss: 0.112, val_loss: 0.194, lr=5.050000e-05\n",
      "training set RMSE 1 cycle: 44.773, 10 cycle: 44.374, 100 cycle: 45.676\n",
      "testing set RMSE 1 cycle: 58.498, 10 cycle: 60.172, 100 cycle: 58.584\n",
      "epoch:[906 / 1000] batch:[30 / 134] loss= 0.057\n",
      "epoch:[906 / 1000] batch:[60 / 134] loss= 0.040\n",
      "epoch:[906 / 1000] batch:[90 / 134] loss= 0.064\n",
      "epoch:[906 / 1000] batch:[120 / 134] loss= 0.031\n",
      "100 cycles trn_loss: 0.026, val_loss: 0.131, lr=3.520366e-05\n",
      "training set RMSE 1 cycle: 24.363, 10 cycle: 20.268, 100 cycle: 21.340\n",
      "testing set RMSE 1 cycle: 48.455, 10 cycle: 47.381, 100 cycle: 47.739\n",
      "epoch:[907 / 1000] batch:[30 / 134] loss= 0.018\n",
      "epoch:[907 / 1000] batch:[60 / 134] loss= 0.026\n",
      "epoch:[907 / 1000] batch:[90 / 134] loss= 0.027\n",
      "epoch:[907 / 1000] batch:[120 / 134] loss= 0.066\n",
      "100 cycles trn_loss: 0.040, val_loss: 0.126, lr=2.140463e-05\n",
      "training set RMSE 1 cycle: 25.600, 10 cycle: 25.356, 100 cycle: 27.484\n",
      "testing set RMSE 1 cycle: 45.701, 10 cycle: 46.059, 100 cycle: 46.888\n",
      "epoch:[908 / 1000] batch:[30 / 134] loss= 0.018\n",
      "epoch:[908 / 1000] batch:[60 / 134] loss= 0.018\n",
      "epoch:[908 / 1000] batch:[90 / 134] loss= 0.018\n",
      "epoch:[908 / 1000] batch:[120 / 134] loss= 0.013\n",
      "100 cycles trn_loss: 0.015, val_loss: 0.103, lr=1.045366e-05\n",
      "training set RMSE 1 cycle: 26.186, 10 cycle: 18.991, 100 cycle: 16.132\n",
      "testing set RMSE 1 cycle: 45.866, 10 cycle: 44.776, 100 cycle: 42.170\n",
      "epoch:[909 / 1000] batch:[30 / 134] loss= 0.031\n",
      "epoch:[909 / 1000] batch:[60 / 134] loss= 0.021\n",
      "epoch:[909 / 1000] batch:[90 / 134] loss= 0.016\n",
      "epoch:[909 / 1000] batch:[120 / 134] loss= 0.020\n",
      "100 cycles trn_loss: 0.014, val_loss: 0.112, lr=3.422702e-06\n",
      "training set RMSE 1 cycle: 24.090, 10 cycle: 18.781, 100 cycle: 15.765\n",
      "testing set RMSE 1 cycle: 46.877, 10 cycle: 47.191, 100 cycle: 44.055\n",
      "epoch:[910 / 1000] batch:[30 / 134] loss= 0.020\n",
      "epoch:[910 / 1000] batch:[60 / 134] loss= 0.012\n",
      "epoch:[910 / 1000] batch:[90 / 134] loss= 0.015\n",
      "epoch:[910 / 1000] batch:[120 / 134] loss= 0.016\n",
      "100 cycles trn_loss: 0.011, val_loss: 0.112, lr=1.000000e-06\n",
      "training set RMSE 1 cycle: 26.264, 10 cycle: 19.590, 100 cycle: 13.944\n",
      "testing set RMSE 1 cycle: 46.851, 10 cycle: 47.465, 100 cycle: 43.974\n",
      "epoch:[911 / 1000] batch:[30 / 134] loss= 0.015\n",
      "epoch:[911 / 1000] batch:[60 / 134] loss= 0.017\n",
      "epoch:[911 / 1000] batch:[90 / 134] loss= 0.014\n",
      "epoch:[911 / 1000] batch:[120 / 134] loss= 0.022\n",
      "100 cycles trn_loss: 0.012, val_loss: 0.111, lr=3.422702e-06\n",
      "training set RMSE 1 cycle: 25.081, 10 cycle: 18.965, 100 cycle: 14.552\n",
      "testing set RMSE 1 cycle: 46.809, 10 cycle: 47.168, 100 cycle: 43.889\n",
      "epoch:[912 / 1000] batch:[30 / 134] loss= 0.026\n",
      "epoch:[912 / 1000] batch:[60 / 134] loss= 0.026\n",
      "epoch:[912 / 1000] batch:[90 / 134] loss= 0.017\n",
      "epoch:[912 / 1000] batch:[120 / 134] loss= 0.016\n",
      "100 cycles trn_loss: 0.012, val_loss: 0.111, lr=1.045366e-05\n",
      "training set RMSE 1 cycle: 25.495, 10 cycle: 19.148, 100 cycle: 14.223\n",
      "testing set RMSE 1 cycle: 46.718, 10 cycle: 47.003, 100 cycle: 43.804\n",
      "epoch:[913 / 1000] batch:[30 / 134] loss= 0.026\n",
      "epoch:[913 / 1000] batch:[60 / 134] loss= 0.018\n",
      "epoch:[913 / 1000] batch:[90 / 134] loss= 0.019\n",
      "epoch:[913 / 1000] batch:[120 / 134] loss= 0.018\n",
      "100 cycles trn_loss: 0.013, val_loss: 0.119, lr=2.140463e-05\n",
      "training set RMSE 1 cycle: 24.689, 10 cycle: 19.129, 100 cycle: 14.735\n",
      "testing set RMSE 1 cycle: 47.562, 10 cycle: 48.514, 100 cycle: 45.291\n",
      "epoch:[914 / 1000] batch:[30 / 134] loss= 0.010\n",
      "epoch:[914 / 1000] batch:[60 / 134] loss= 0.041\n",
      "epoch:[914 / 1000] batch:[90 / 134] loss= 0.013\n",
      "epoch:[914 / 1000] batch:[120 / 134] loss= 0.017\n",
      "100 cycles trn_loss: 0.023, val_loss: 0.121, lr=3.520366e-05\n",
      "training set RMSE 1 cycle: 22.658, 10 cycle: 19.577, 100 cycle: 20.109\n",
      "testing set RMSE 1 cycle: 47.946, 10 cycle: 46.979, 100 cycle: 45.945\n",
      "epoch:[915 / 1000] batch:[30 / 134] loss= 0.021\n",
      "epoch:[915 / 1000] batch:[60 / 134] loss= 0.030\n",
      "epoch:[915 / 1000] batch:[90 / 134] loss= 0.027\n",
      "epoch:[915 / 1000] batch:[120 / 134] loss= 0.018\n",
      "100 cycles trn_loss: 0.017, val_loss: 0.117, lr=5.050000e-05\n",
      "training set RMSE 1 cycle: 22.882, 10 cycle: 18.692, 100 cycle: 17.058\n",
      "testing set RMSE 1 cycle: 46.900, 10 cycle: 47.360, 100 cycle: 44.947\n",
      "epoch:[916 / 1000] batch:[30 / 134] loss= 0.034\n",
      "epoch:[916 / 1000] batch:[60 / 134] loss= 0.024\n",
      "epoch:[916 / 1000] batch:[90 / 134] loss= 0.028\n",
      "epoch:[916 / 1000] batch:[120 / 134] loss= 0.045\n",
      "100 cycles trn_loss: 0.034, val_loss: 0.126, lr=6.579634e-05\n",
      "training set RMSE 1 cycle: 26.290, 10 cycle: 23.248, 100 cycle: 24.814\n",
      "testing set RMSE 1 cycle: 49.953, 10 cycle: 50.109, 100 cycle: 47.061\n",
      "epoch:[917 / 1000] batch:[30 / 134] loss= 0.037\n",
      "epoch:[917 / 1000] batch:[60 / 134] loss= 0.030\n",
      "epoch:[917 / 1000] batch:[90 / 134] loss= 0.036\n",
      "epoch:[917 / 1000] batch:[120 / 134] loss= 0.028\n",
      "100 cycles trn_loss: 0.037, val_loss: 0.130, lr=7.959537e-05\n",
      "training set RMSE 1 cycle: 24.291, 10 cycle: 23.747, 100 cycle: 25.816\n",
      "testing set RMSE 1 cycle: 48.292, 10 cycle: 47.863, 100 cycle: 47.673\n",
      "epoch:[918 / 1000] batch:[30 / 134] loss= 0.224\n",
      "epoch:[918 / 1000] batch:[60 / 134] loss= 0.084\n",
      "epoch:[918 / 1000] batch:[90 / 134] loss= 0.030\n",
      "epoch:[918 / 1000] batch:[120 / 134] loss= 0.055\n",
      "100 cycles trn_loss: 0.017, val_loss: 0.146, lr=9.054634e-05\n",
      "training set RMSE 1 cycle: 23.952, 10 cycle: 19.018, 100 cycle: 16.946\n",
      "testing set RMSE 1 cycle: 52.358, 10 cycle: 51.817, 100 cycle: 50.386\n",
      "epoch:[919 / 1000] batch:[30 / 134] loss= 0.024\n",
      "epoch:[919 / 1000] batch:[60 / 134] loss= 0.104\n",
      "epoch:[919 / 1000] batch:[90 / 134] loss= 0.175\n",
      "epoch:[919 / 1000] batch:[120 / 134] loss= 0.030\n",
      "100 cycles trn_loss: 0.016, val_loss: 0.135, lr=9.757730e-05\n",
      "training set RMSE 1 cycle: 31.908, 10 cycle: 24.622, 100 cycle: 16.532\n",
      "testing set RMSE 1 cycle: 52.928, 10 cycle: 51.542, 100 cycle: 48.942\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:[920 / 1000] batch:[30 / 134] loss= 0.029\n",
      "epoch:[920 / 1000] batch:[60 / 134] loss= 0.120\n",
      "epoch:[920 / 1000] batch:[90 / 134] loss= 0.058\n",
      "epoch:[920 / 1000] batch:[120 / 134] loss= 0.104\n",
      "100 cycles trn_loss: 0.085, val_loss: 0.126, lr=1.000000e-04\n",
      "training set RMSE 1 cycle: 48.165, 10 cycle: 43.203, 100 cycle: 40.393\n",
      "testing set RMSE 1 cycle: 47.477, 10 cycle: 45.546, 100 cycle: 46.669\n",
      "epoch:[921 / 1000] batch:[30 / 134] loss= 0.094\n",
      "epoch:[921 / 1000] batch:[60 / 134] loss= 0.053\n",
      "epoch:[921 / 1000] batch:[90 / 134] loss= 0.055\n",
      "epoch:[921 / 1000] batch:[120 / 134] loss= 0.034\n",
      "100 cycles trn_loss: 0.017, val_loss: 0.106, lr=9.757730e-05\n",
      "training set RMSE 1 cycle: 32.625, 10 cycle: 24.325, 100 cycle: 16.986\n",
      "testing set RMSE 1 cycle: 47.974, 10 cycle: 48.782, 100 cycle: 42.858\n",
      "epoch:[922 / 1000] batch:[30 / 134] loss= 0.023\n",
      "epoch:[922 / 1000] batch:[60 / 134] loss= 0.055\n",
      "epoch:[922 / 1000] batch:[90 / 134] loss= 0.013\n",
      "epoch:[922 / 1000] batch:[120 / 134] loss= 0.040\n",
      "100 cycles trn_loss: 0.034, val_loss: 0.195, lr=9.054634e-05\n",
      "training set RMSE 1 cycle: 26.471, 10 cycle: 24.185, 100 cycle: 24.376\n",
      "testing set RMSE 1 cycle: 57.876, 10 cycle: 58.688, 100 cycle: 58.742\n",
      "epoch:[923 / 1000] batch:[30 / 134] loss= 0.038\n",
      "epoch:[923 / 1000] batch:[60 / 134] loss= 0.061\n",
      "epoch:[923 / 1000] batch:[90 / 134] loss= 0.143\n",
      "epoch:[923 / 1000] batch:[120 / 134] loss= 0.049\n",
      "100 cycles trn_loss: 0.043, val_loss: 0.140, lr=7.959537e-05\n",
      "training set RMSE 1 cycle: 38.275, 10 cycle: 34.628, 100 cycle: 27.399\n",
      "testing set RMSE 1 cycle: 58.436, 10 cycle: 52.965, 100 cycle: 49.363\n",
      "epoch:[924 / 1000] batch:[30 / 134] loss= 0.017\n",
      "epoch:[924 / 1000] batch:[60 / 134] loss= 0.035\n",
      "epoch:[924 / 1000] batch:[90 / 134] loss= 0.046\n",
      "epoch:[924 / 1000] batch:[120 / 134] loss= 0.078\n",
      "100 cycles trn_loss: 0.015, val_loss: 0.130, lr=6.579634e-05\n",
      "training set RMSE 1 cycle: 26.413, 10 cycle: 20.395, 100 cycle: 16.093\n",
      "testing set RMSE 1 cycle: 49.603, 10 cycle: 50.862, 100 cycle: 47.578\n",
      "epoch:[925 / 1000] batch:[30 / 134] loss= 0.020\n",
      "epoch:[925 / 1000] batch:[60 / 134] loss= 0.064\n",
      "epoch:[925 / 1000] batch:[90 / 134] loss= 0.085\n",
      "epoch:[925 / 1000] batch:[120 / 134] loss= 0.021\n",
      "100 cycles trn_loss: 0.037, val_loss: 0.111, lr=5.050000e-05\n",
      "training set RMSE 1 cycle: 32.923, 10 cycle: 26.759, 100 cycle: 26.106\n",
      "testing set RMSE 1 cycle: 44.228, 10 cycle: 42.659, 100 cycle: 43.781\n",
      "epoch:[926 / 1000] batch:[30 / 134] loss= 0.032\n",
      "epoch:[926 / 1000] batch:[60 / 134] loss= 0.016\n",
      "epoch:[926 / 1000] batch:[90 / 134] loss= 0.018\n",
      "epoch:[926 / 1000] batch:[120 / 134] loss= 0.022\n",
      "100 cycles trn_loss: 0.032, val_loss: 0.134, lr=3.520366e-05\n",
      "training set RMSE 1 cycle: 21.348, 10 cycle: 21.215, 100 cycle: 23.896\n",
      "testing set RMSE 1 cycle: 48.253, 10 cycle: 47.842, 100 cycle: 48.426\n",
      "epoch:[927 / 1000] batch:[30 / 134] loss= 0.035\n",
      "epoch:[927 / 1000] batch:[60 / 134] loss= 0.024\n",
      "epoch:[927 / 1000] batch:[90 / 134] loss= 0.019\n",
      "epoch:[927 / 1000] batch:[120 / 134] loss= 0.045\n",
      "100 cycles trn_loss: 0.010, val_loss: 0.118, lr=2.140463e-05\n",
      "training set RMSE 1 cycle: 25.362, 10 cycle: 19.611, 100 cycle: 13.325\n",
      "testing set RMSE 1 cycle: 50.264, 10 cycle: 49.049, 100 cycle: 45.177\n",
      "epoch:[928 / 1000] batch:[30 / 134] loss= 0.011\n",
      "epoch:[928 / 1000] batch:[60 / 134] loss= 0.019\n",
      "epoch:[928 / 1000] batch:[90 / 134] loss= 0.016\n",
      "epoch:[928 / 1000] batch:[120 / 134] loss= 0.012\n",
      "100 cycles trn_loss: 0.013, val_loss: 0.120, lr=1.045366e-05\n",
      "training set RMSE 1 cycle: 21.103, 10 cycle: 17.566, 100 cycle: 15.157\n",
      "testing set RMSE 1 cycle: 48.863, 10 cycle: 47.150, 100 cycle: 45.606\n",
      "epoch:[929 / 1000] batch:[30 / 134] loss= 0.011\n",
      "epoch:[929 / 1000] batch:[60 / 134] loss= 0.015\n",
      "epoch:[929 / 1000] batch:[90 / 134] loss= 0.012\n",
      "epoch:[929 / 1000] batch:[120 / 134] loss= 0.016\n",
      "100 cycles trn_loss: 0.010, val_loss: 0.114, lr=3.422702e-06\n",
      "training set RMSE 1 cycle: 22.323, 10 cycle: 17.147, 100 cycle: 13.456\n",
      "testing set RMSE 1 cycle: 48.659, 10 cycle: 46.674, 100 cycle: 44.383\n",
      "epoch:[930 / 1000] batch:[30 / 134] loss= 0.024\n",
      "epoch:[930 / 1000] batch:[60 / 134] loss= 0.014\n",
      "epoch:[930 / 1000] batch:[90 / 134] loss= 0.023\n",
      "epoch:[930 / 1000] batch:[120 / 134] loss= 0.008\n",
      "100 cycles trn_loss: 0.009, val_loss: 0.112, lr=1.000000e-06\n",
      "training set RMSE 1 cycle: 23.398, 10 cycle: 17.631, 100 cycle: 12.429\n",
      "testing set RMSE 1 cycle: 49.104, 10 cycle: 47.390, 100 cycle: 44.043\n",
      "epoch:[931 / 1000] batch:[30 / 134] loss= 0.014\n",
      "epoch:[931 / 1000] batch:[60 / 134] loss= 0.017\n",
      "epoch:[931 / 1000] batch:[90 / 134] loss= 0.015\n",
      "epoch:[931 / 1000] batch:[120 / 134] loss= 0.026\n",
      "100 cycles trn_loss: 0.010, val_loss: 0.112, lr=3.422702e-06\n",
      "training set RMSE 1 cycle: 22.306, 10 cycle: 17.095, 100 cycle: 12.976\n",
      "testing set RMSE 1 cycle: 48.836, 10 cycle: 46.479, 100 cycle: 44.103\n",
      "epoch:[932 / 1000] batch:[30 / 134] loss= 0.009\n",
      "epoch:[932 / 1000] batch:[60 / 134] loss= 0.015\n",
      "epoch:[932 / 1000] batch:[90 / 134] loss= 0.018\n",
      "epoch:[932 / 1000] batch:[120 / 134] loss= 0.015\n",
      "100 cycles trn_loss: 0.010, val_loss: 0.111, lr=1.045366e-05\n",
      "training set RMSE 1 cycle: 22.088, 10 cycle: 16.828, 100 cycle: 13.254\n",
      "testing set RMSE 1 cycle: 48.417, 10 cycle: 45.676, 100 cycle: 43.760\n",
      "epoch:[933 / 1000] batch:[30 / 134] loss= 0.021\n",
      "epoch:[933 / 1000] batch:[60 / 134] loss= 0.027\n",
      "epoch:[933 / 1000] batch:[90 / 134] loss= 0.021\n",
      "epoch:[933 / 1000] batch:[120 / 134] loss= 0.019\n",
      "100 cycles trn_loss: 0.008, val_loss: 0.109, lr=2.140463e-05\n",
      "training set RMSE 1 cycle: 25.061, 10 cycle: 18.482, 100 cycle: 11.667\n",
      "testing set RMSE 1 cycle: 49.284, 10 cycle: 47.783, 100 cycle: 43.366\n",
      "epoch:[934 / 1000] batch:[30 / 134] loss= 0.013\n",
      "epoch:[934 / 1000] batch:[60 / 134] loss= 0.018\n",
      "epoch:[934 / 1000] batch:[90 / 134] loss= 0.018\n",
      "epoch:[934 / 1000] batch:[120 / 134] loss= 0.033\n",
      "100 cycles trn_loss: 0.011, val_loss: 0.116, lr=3.520366e-05\n",
      "training set RMSE 1 cycle: 20.764, 10 cycle: 16.475, 100 cycle: 13.916\n",
      "testing set RMSE 1 cycle: 49.517, 10 cycle: 46.753, 100 cycle: 44.802\n",
      "epoch:[935 / 1000] batch:[30 / 134] loss= 0.016\n",
      "epoch:[935 / 1000] batch:[60 / 134] loss= 0.019\n",
      "epoch:[935 / 1000] batch:[90 / 134] loss= 0.034\n",
      "epoch:[935 / 1000] batch:[120 / 134] loss= 0.016\n",
      "100 cycles trn_loss: 0.008, val_loss: 0.129, lr=5.050000e-05\n",
      "training set RMSE 1 cycle: 29.341, 10 cycle: 22.153, 100 cycle: 11.656\n",
      "testing set RMSE 1 cycle: 52.888, 10 cycle: 52.077, 100 cycle: 47.819\n",
      "epoch:[936 / 1000] batch:[30 / 134] loss= 0.025\n",
      "epoch:[936 / 1000] batch:[60 / 134] loss= 0.010\n",
      "epoch:[936 / 1000] batch:[90 / 134] loss= 0.020\n",
      "epoch:[936 / 1000] batch:[120 / 134] loss= 0.015\n",
      "100 cycles trn_loss: 0.010, val_loss: 0.115, lr=6.579634e-05\n",
      "training set RMSE 1 cycle: 22.920, 10 cycle: 17.031, 100 cycle: 13.017\n",
      "testing set RMSE 1 cycle: 48.582, 10 cycle: 48.770, 100 cycle: 44.513\n",
      "epoch:[937 / 1000] batch:[30 / 134] loss= 0.037\n",
      "epoch:[937 / 1000] batch:[60 / 134] loss= 0.024\n",
      "epoch:[937 / 1000] batch:[90 / 134] loss= 0.066\n",
      "epoch:[937 / 1000] batch:[120 / 134] loss= 0.012\n",
      "100 cycles trn_loss: 0.021, val_loss: 0.143, lr=7.959537e-05\n",
      "training set RMSE 1 cycle: 20.311, 10 cycle: 19.358, 100 cycle: 19.256\n",
      "testing set RMSE 1 cycle: 52.522, 10 cycle: 51.958, 100 cycle: 49.847\n",
      "epoch:[938 / 1000] batch:[30 / 134] loss= 0.048\n",
      "epoch:[938 / 1000] batch:[60 / 134] loss= 0.021\n",
      "epoch:[938 / 1000] batch:[90 / 134] loss= 0.086\n",
      "epoch:[938 / 1000] batch:[120 / 134] loss= 0.085\n",
      "100 cycles trn_loss: 0.023, val_loss: 0.120, lr=9.054634e-05\n",
      "training set RMSE 1 cycle: 25.823, 10 cycle: 19.696, 100 cycle: 19.788\n",
      "testing set RMSE 1 cycle: 43.653, 10 cycle: 44.475, 100 cycle: 45.652\n",
      "epoch:[939 / 1000] batch:[30 / 134] loss= 0.016\n",
      "epoch:[939 / 1000] batch:[60 / 134] loss= 0.239\n",
      "epoch:[939 / 1000] batch:[90 / 134] loss= 0.075\n",
      "epoch:[939 / 1000] batch:[120 / 134] loss= 0.050\n",
      "100 cycles trn_loss: 0.043, val_loss: 0.143, lr=9.757730e-05\n",
      "training set RMSE 1 cycle: 39.917, 10 cycle: 34.957, 100 cycle: 27.515\n",
      "testing set RMSE 1 cycle: 60.195, 10 cycle: 59.993, 100 cycle: 50.239\n",
      "epoch:[940 / 1000] batch:[30 / 134] loss= 0.028\n",
      "epoch:[940 / 1000] batch:[60 / 134] loss= 0.008\n",
      "epoch:[940 / 1000] batch:[90 / 134] loss= 0.021\n",
      "epoch:[940 / 1000] batch:[120 / 134] loss= 0.014\n",
      "100 cycles trn_loss: 0.011, val_loss: 0.124, lr=1.000000e-04\n",
      "training set RMSE 1 cycle: 33.274, 10 cycle: 24.360, 100 cycle: 13.577\n",
      "testing set RMSE 1 cycle: 52.423, 10 cycle: 51.338, 100 cycle: 46.752\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:[941 / 1000] batch:[30 / 134] loss= 0.237\n",
      "epoch:[941 / 1000] batch:[60 / 134] loss= 0.091\n",
      "epoch:[941 / 1000] batch:[90 / 134] loss= 0.126\n",
      "epoch:[941 / 1000] batch:[120 / 134] loss= 0.127\n",
      "100 cycles trn_loss: 0.098, val_loss: 0.157, lr=9.757730e-05\n",
      "training set RMSE 1 cycle: 45.492, 10 cycle: 45.693, 100 cycle: 44.560\n",
      "testing set RMSE 1 cycle: 54.370, 10 cycle: 52.416, 100 cycle: 52.068\n",
      "epoch:[942 / 1000] batch:[30 / 134] loss= 0.089\n",
      "epoch:[942 / 1000] batch:[60 / 134] loss= 0.081\n",
      "epoch:[942 / 1000] batch:[90 / 134] loss= 0.153\n",
      "epoch:[942 / 1000] batch:[120 / 134] loss= 0.063\n",
      "100 cycles trn_loss: 0.077, val_loss: 0.115, lr=9.054634e-05\n",
      "training set RMSE 1 cycle: 44.489, 10 cycle: 42.881, 100 cycle: 38.966\n",
      "testing set RMSE 1 cycle: 47.779, 10 cycle: 46.110, 100 cycle: 44.592\n",
      "epoch:[943 / 1000] batch:[30 / 134] loss= 0.075\n",
      "epoch:[943 / 1000] batch:[60 / 134] loss= 0.063\n",
      "epoch:[943 / 1000] batch:[90 / 134] loss= 0.027\n",
      "epoch:[943 / 1000] batch:[120 / 134] loss= 0.104\n",
      "100 cycles trn_loss: 0.078, val_loss: 0.139, lr=7.959537e-05\n",
      "training set RMSE 1 cycle: 42.078, 10 cycle: 41.455, 100 cycle: 39.527\n",
      "testing set RMSE 1 cycle: 52.291, 10 cycle: 49.893, 100 cycle: 49.191\n",
      "epoch:[944 / 1000] batch:[30 / 134] loss= 0.125\n",
      "epoch:[944 / 1000] batch:[60 / 134] loss= 0.097\n",
      "epoch:[944 / 1000] batch:[90 / 134] loss= 0.039\n",
      "epoch:[944 / 1000] batch:[120 / 134] loss= 0.086\n",
      "100 cycles trn_loss: 0.071, val_loss: 0.106, lr=6.579634e-05\n",
      "training set RMSE 1 cycle: 50.025, 10 cycle: 45.795, 100 cycle: 36.150\n",
      "testing set RMSE 1 cycle: 52.193, 10 cycle: 51.416, 100 cycle: 43.021\n",
      "epoch:[945 / 1000] batch:[30 / 134] loss= 0.043\n",
      "epoch:[945 / 1000] batch:[60 / 134] loss= 0.054\n",
      "epoch:[945 / 1000] batch:[90 / 134] loss= 0.082\n",
      "epoch:[945 / 1000] batch:[120 / 134] loss= 0.103\n",
      "100 cycles trn_loss: 0.061, val_loss: 0.124, lr=5.050000e-05\n",
      "training set RMSE 1 cycle: 41.701, 10 cycle: 39.595, 100 cycle: 34.164\n",
      "testing set RMSE 1 cycle: 50.640, 10 cycle: 50.326, 100 cycle: 46.324\n",
      "epoch:[946 / 1000] batch:[30 / 134] loss= 0.066\n",
      "epoch:[946 / 1000] batch:[60 / 134] loss= 0.074\n",
      "epoch:[946 / 1000] batch:[90 / 134] loss= 0.091\n",
      "epoch:[946 / 1000] batch:[120 / 134] loss= 0.196\n",
      "100 cycles trn_loss: 0.060, val_loss: 0.110, lr=3.520366e-05\n",
      "training set RMSE 1 cycle: 40.995, 10 cycle: 38.226, 100 cycle: 34.157\n",
      "testing set RMSE 1 cycle: 47.444, 10 cycle: 46.162, 100 cycle: 43.699\n",
      "epoch:[947 / 1000] batch:[30 / 134] loss= 0.091\n",
      "epoch:[947 / 1000] batch:[60 / 134] loss= 0.058\n",
      "epoch:[947 / 1000] batch:[90 / 134] loss= 0.045\n",
      "epoch:[947 / 1000] batch:[120 / 134] loss= 0.026\n",
      "100 cycles trn_loss: 0.061, val_loss: 0.120, lr=2.140463e-05\n",
      "training set RMSE 1 cycle: 39.183, 10 cycle: 37.600, 100 cycle: 34.323\n",
      "testing set RMSE 1 cycle: 47.476, 10 cycle: 46.570, 100 cycle: 45.493\n",
      "epoch:[948 / 1000] batch:[30 / 134] loss= 0.107\n",
      "epoch:[948 / 1000] batch:[60 / 134] loss= 0.066\n",
      "epoch:[948 / 1000] batch:[90 / 134] loss= 0.083\n",
      "epoch:[948 / 1000] batch:[120 / 134] loss= 0.054\n",
      "100 cycles trn_loss: 0.060, val_loss: 0.100, lr=1.045366e-05\n",
      "training set RMSE 1 cycle: 46.355, 10 cycle: 41.590, 100 cycle: 33.134\n",
      "testing set RMSE 1 cycle: 48.717, 10 cycle: 47.770, 100 cycle: 41.552\n",
      "epoch:[949 / 1000] batch:[30 / 134] loss= 0.089\n",
      "epoch:[949 / 1000] batch:[60 / 134] loss= 0.037\n",
      "epoch:[949 / 1000] batch:[90 / 134] loss= 0.111\n",
      "epoch:[949 / 1000] batch:[120 / 134] loss= 0.102\n",
      "100 cycles trn_loss: 0.055, val_loss: 0.112, lr=3.422702e-06\n",
      "training set RMSE 1 cycle: 40.452, 10 cycle: 37.616, 100 cycle: 32.147\n",
      "testing set RMSE 1 cycle: 48.564, 10 cycle: 47.679, 100 cycle: 43.973\n",
      "epoch:[950 / 1000] batch:[30 / 134] loss= 0.111\n",
      "epoch:[950 / 1000] batch:[60 / 134] loss= 0.107\n",
      "epoch:[950 / 1000] batch:[90 / 134] loss= 0.091\n",
      "epoch:[950 / 1000] batch:[120 / 134] loss= 0.043\n",
      "100 cycles trn_loss: 0.054, val_loss: 0.110, lr=1.000000e-06\n",
      "training set RMSE 1 cycle: 40.830, 10 cycle: 37.776, 100 cycle: 32.006\n",
      "testing set RMSE 1 cycle: 48.539, 10 cycle: 47.451, 100 cycle: 43.673\n",
      "epoch:[951 / 1000] batch:[30 / 134] loss= 0.144\n",
      "epoch:[951 / 1000] batch:[60 / 134] loss= 0.036\n",
      "epoch:[951 / 1000] batch:[90 / 134] loss= 0.080\n",
      "epoch:[951 / 1000] batch:[120 / 134] loss= 0.107\n",
      "100 cycles trn_loss: 0.055, val_loss: 0.116, lr=3.422702e-06\n",
      "training set RMSE 1 cycle: 40.105, 10 cycle: 37.535, 100 cycle: 32.269\n",
      "testing set RMSE 1 cycle: 49.015, 10 cycle: 48.117, 100 cycle: 44.755\n",
      "epoch:[952 / 1000] batch:[30 / 134] loss= 0.040\n",
      "epoch:[952 / 1000] batch:[60 / 134] loss= 0.085\n",
      "epoch:[952 / 1000] batch:[90 / 134] loss= 0.122\n",
      "epoch:[952 / 1000] batch:[120 / 134] loss= 0.105\n",
      "100 cycles trn_loss: 0.055, val_loss: 0.114, lr=1.045366e-05\n",
      "training set RMSE 1 cycle: 40.212, 10 cycle: 37.568, 100 cycle: 32.083\n",
      "testing set RMSE 1 cycle: 48.890, 10 cycle: 47.974, 100 cycle: 44.489\n",
      "epoch:[953 / 1000] batch:[30 / 134] loss= 0.035\n",
      "epoch:[953 / 1000] batch:[60 / 134] loss= 0.060\n",
      "epoch:[953 / 1000] batch:[90 / 134] loss= 0.039\n",
      "epoch:[953 / 1000] batch:[120 / 134] loss= 0.095\n",
      "100 cycles trn_loss: 0.053, val_loss: 0.111, lr=2.140463e-05\n",
      "training set RMSE 1 cycle: 40.586, 10 cycle: 37.604, 100 cycle: 31.590\n",
      "testing set RMSE 1 cycle: 48.695, 10 cycle: 47.920, 100 cycle: 43.826\n",
      "epoch:[954 / 1000] batch:[30 / 134] loss= 0.061\n",
      "epoch:[954 / 1000] batch:[60 / 134] loss= 0.030\n",
      "epoch:[954 / 1000] batch:[90 / 134] loss= 0.083\n",
      "epoch:[954 / 1000] batch:[120 / 134] loss= 0.053\n",
      "100 cycles trn_loss: 0.057, val_loss: 0.105, lr=3.520366e-05\n",
      "training set RMSE 1 cycle: 39.835, 10 cycle: 37.079, 100 cycle: 32.887\n",
      "testing set RMSE 1 cycle: 46.336, 10 cycle: 44.364, 100 cycle: 42.718\n",
      "epoch:[955 / 1000] batch:[30 / 134] loss= 0.065\n",
      "epoch:[955 / 1000] batch:[60 / 134] loss= 0.083\n",
      "epoch:[955 / 1000] batch:[90 / 134] loss= 0.070\n",
      "epoch:[955 / 1000] batch:[120 / 134] loss= 0.103\n",
      "100 cycles trn_loss: 0.054, val_loss: 0.105, lr=5.050000e-05\n",
      "training set RMSE 1 cycle: 39.806, 10 cycle: 36.781, 100 cycle: 32.010\n",
      "testing set RMSE 1 cycle: 46.233, 10 cycle: 44.765, 100 cycle: 42.721\n",
      "epoch:[956 / 1000] batch:[30 / 134] loss= 0.048\n",
      "epoch:[956 / 1000] batch:[60 / 134] loss= 0.088\n",
      "epoch:[956 / 1000] batch:[90 / 134] loss= 0.057\n",
      "epoch:[956 / 1000] batch:[120 / 134] loss= 0.106\n",
      "100 cycles trn_loss: 0.056, val_loss: 0.104, lr=6.579634e-05\n",
      "training set RMSE 1 cycle: 42.678, 10 cycle: 38.315, 100 cycle: 32.397\n",
      "testing set RMSE 1 cycle: 46.768, 10 cycle: 44.814, 100 cycle: 42.444\n",
      "epoch:[957 / 1000] batch:[30 / 134] loss= 0.062\n",
      "epoch:[957 / 1000] batch:[60 / 134] loss= 0.049\n",
      "epoch:[957 / 1000] batch:[90 / 134] loss= 0.092\n",
      "epoch:[957 / 1000] batch:[120 / 134] loss= 0.096\n",
      "100 cycles trn_loss: 0.068, val_loss: 0.110, lr=7.959537e-05\n",
      "training set RMSE 1 cycle: 38.901, 10 cycle: 38.039, 100 cycle: 36.414\n",
      "testing set RMSE 1 cycle: 45.431, 10 cycle: 43.469, 100 cycle: 43.608\n",
      "epoch:[958 / 1000] batch:[30 / 134] loss= 0.096\n",
      "epoch:[958 / 1000] batch:[60 / 134] loss= 0.042\n",
      "epoch:[958 / 1000] batch:[90 / 134] loss= 0.055\n",
      "epoch:[958 / 1000] batch:[120 / 134] loss= 0.074\n",
      "100 cycles trn_loss: 0.057, val_loss: 0.123, lr=9.054634e-05\n",
      "training set RMSE 1 cycle: 44.522, 10 cycle: 39.144, 100 cycle: 32.338\n",
      "testing set RMSE 1 cycle: 49.765, 10 cycle: 50.292, 100 cycle: 46.095\n",
      "epoch:[959 / 1000] batch:[30 / 134] loss= 0.088\n",
      "epoch:[959 / 1000] batch:[60 / 134] loss= 0.080\n",
      "epoch:[959 / 1000] batch:[90 / 134] loss= 0.036\n",
      "epoch:[959 / 1000] batch:[120 / 134] loss= 0.070\n",
      "100 cycles trn_loss: 0.061, val_loss: 0.116, lr=9.757730e-05\n",
      "training set RMSE 1 cycle: 47.786, 10 cycle: 42.463, 100 cycle: 33.040\n",
      "testing set RMSE 1 cycle: 52.909, 10 cycle: 53.328, 100 cycle: 45.244\n",
      "epoch:[960 / 1000] batch:[30 / 134] loss= 0.053\n",
      "epoch:[960 / 1000] batch:[60 / 134] loss= 0.091\n",
      "epoch:[960 / 1000] batch:[90 / 134] loss= 0.062\n",
      "epoch:[960 / 1000] batch:[120 / 134] loss= 0.139\n",
      "100 cycles trn_loss: 0.055, val_loss: 0.123, lr=1.000000e-04\n",
      "training set RMSE 1 cycle: 37.628, 10 cycle: 35.307, 100 cycle: 31.822\n",
      "testing set RMSE 1 cycle: 48.932, 10 cycle: 47.692, 100 cycle: 46.261\n",
      "epoch:[961 / 1000] batch:[30 / 134] loss= 0.089\n",
      "epoch:[961 / 1000] batch:[60 / 134] loss= 0.058\n",
      "epoch:[961 / 1000] batch:[90 / 134] loss= 0.067\n",
      "epoch:[961 / 1000] batch:[120 / 134] loss= 0.069\n",
      "100 cycles trn_loss: 0.049, val_loss: 0.112, lr=9.757730e-05\n",
      "training set RMSE 1 cycle: 45.412, 10 cycle: 41.230, 100 cycle: 29.459\n",
      "testing set RMSE 1 cycle: 49.228, 10 cycle: 50.302, 100 cycle: 44.151\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:[962 / 1000] batch:[30 / 134] loss= 0.065\n",
      "epoch:[962 / 1000] batch:[60 / 134] loss= 0.049\n",
      "epoch:[962 / 1000] batch:[90 / 134] loss= 0.083\n",
      "epoch:[962 / 1000] batch:[120 / 134] loss= 0.040\n",
      "100 cycles trn_loss: 0.044, val_loss: 0.115, lr=9.054634e-05\n",
      "training set RMSE 1 cycle: 38.800, 10 cycle: 34.992, 100 cycle: 28.258\n",
      "testing set RMSE 1 cycle: 48.305, 10 cycle: 49.229, 100 cycle: 44.559\n",
      "epoch:[963 / 1000] batch:[30 / 134] loss= 0.097\n",
      "epoch:[963 / 1000] batch:[60 / 134] loss= 0.033\n",
      "epoch:[963 / 1000] batch:[90 / 134] loss= 0.051\n",
      "epoch:[963 / 1000] batch:[120 / 134] loss= 0.108\n",
      "100 cycles trn_loss: 0.095, val_loss: 0.157, lr=7.959537e-05\n",
      "training set RMSE 1 cycle: 44.168, 10 cycle: 44.154, 100 cycle: 43.828\n",
      "testing set RMSE 1 cycle: 50.446, 10 cycle: 49.692, 100 cycle: 52.451\n",
      "epoch:[964 / 1000] batch:[30 / 134] loss= 0.015\n",
      "epoch:[964 / 1000] batch:[60 / 134] loss= 0.065\n",
      "epoch:[964 / 1000] batch:[90 / 134] loss= 0.025\n",
      "epoch:[964 / 1000] batch:[120 / 134] loss= 0.055\n",
      "100 cycles trn_loss: 0.054, val_loss: 0.118, lr=6.579634e-05\n",
      "training set RMSE 1 cycle: 37.833, 10 cycle: 34.510, 100 cycle: 31.095\n",
      "testing set RMSE 1 cycle: 48.339, 10 cycle: 48.672, 100 cycle: 45.274\n",
      "epoch:[965 / 1000] batch:[30 / 134] loss= 0.043\n",
      "epoch:[965 / 1000] batch:[60 / 134] loss= 0.038\n",
      "epoch:[965 / 1000] batch:[90 / 134] loss= 0.071\n",
      "epoch:[965 / 1000] batch:[120 / 134] loss= 0.046\n",
      "100 cycles trn_loss: 0.043, val_loss: 0.106, lr=5.050000e-05\n",
      "training set RMSE 1 cycle: 47.318, 10 cycle: 41.386, 100 cycle: 27.255\n",
      "testing set RMSE 1 cycle: 50.926, 10 cycle: 52.927, 100 cycle: 43.081\n",
      "epoch:[966 / 1000] batch:[30 / 134] loss= 0.051\n",
      "epoch:[966 / 1000] batch:[60 / 134] loss= 0.023\n",
      "epoch:[966 / 1000] batch:[90 / 134] loss= 0.061\n",
      "epoch:[966 / 1000] batch:[120 / 134] loss= 0.052\n",
      "100 cycles trn_loss: 0.033, val_loss: 0.109, lr=3.520366e-05\n",
      "training set RMSE 1 cycle: 38.148, 10 cycle: 33.525, 100 cycle: 23.929\n",
      "testing set RMSE 1 cycle: 48.296, 10 cycle: 49.209, 100 cycle: 43.414\n",
      "epoch:[967 / 1000] batch:[30 / 134] loss= 0.076\n",
      "epoch:[967 / 1000] batch:[60 / 134] loss= 0.045\n",
      "epoch:[967 / 1000] batch:[90 / 134] loss= 0.055\n",
      "epoch:[967 / 1000] batch:[120 / 134] loss= 0.028\n",
      "100 cycles trn_loss: 0.029, val_loss: 0.096, lr=2.140463e-05\n",
      "training set RMSE 1 cycle: 40.515, 10 cycle: 34.368, 100 cycle: 22.488\n",
      "testing set RMSE 1 cycle: 46.135, 10 cycle: 48.102, 100 cycle: 40.665\n",
      "epoch:[968 / 1000] batch:[30 / 134] loss= 0.084\n",
      "epoch:[968 / 1000] batch:[60 / 134] loss= 0.041\n",
      "epoch:[968 / 1000] batch:[90 / 134] loss= 0.078\n",
      "epoch:[968 / 1000] batch:[120 / 134] loss= 0.020\n",
      "100 cycles trn_loss: 0.034, val_loss: 0.112, lr=1.045366e-05\n",
      "training set RMSE 1 cycle: 42.283, 10 cycle: 37.716, 100 cycle: 24.100\n",
      "testing set RMSE 1 cycle: 49.315, 10 cycle: 52.612, 100 cycle: 44.092\n",
      "epoch:[969 / 1000] batch:[30 / 134] loss= 0.034\n",
      "epoch:[969 / 1000] batch:[60 / 134] loss= 0.057\n",
      "epoch:[969 / 1000] batch:[90 / 134] loss= 0.050\n",
      "epoch:[969 / 1000] batch:[120 / 134] loss= 0.040\n",
      "100 cycles trn_loss: 0.028, val_loss: 0.098, lr=3.422702e-06\n",
      "training set RMSE 1 cycle: 35.854, 10 cycle: 30.322, 100 cycle: 21.918\n",
      "testing set RMSE 1 cycle: 45.784, 10 cycle: 46.074, 100 cycle: 41.073\n",
      "epoch:[970 / 1000] batch:[30 / 134] loss= 0.038\n",
      "epoch:[970 / 1000] batch:[60 / 134] loss= 0.093\n",
      "epoch:[970 / 1000] batch:[90 / 134] loss= 0.059\n",
      "epoch:[970 / 1000] batch:[120 / 134] loss= 0.058\n",
      "100 cycles trn_loss: 0.028, val_loss: 0.099, lr=1.000000e-06\n",
      "training set RMSE 1 cycle: 34.318, 10 cycle: 29.228, 100 cycle: 21.937\n",
      "testing set RMSE 1 cycle: 45.297, 10 cycle: 45.526, 100 cycle: 41.365\n",
      "epoch:[971 / 1000] batch:[30 / 134] loss= 0.056\n",
      "epoch:[971 / 1000] batch:[60 / 134] loss= 0.059\n",
      "epoch:[971 / 1000] batch:[90 / 134] loss= 0.034\n",
      "epoch:[971 / 1000] batch:[120 / 134] loss= 0.021\n",
      "100 cycles trn_loss: 0.027, val_loss: 0.098, lr=3.422702e-06\n",
      "training set RMSE 1 cycle: 35.108, 10 cycle: 29.774, 100 cycle: 21.542\n",
      "testing set RMSE 1 cycle: 45.505, 10 cycle: 46.116, 100 cycle: 41.263\n",
      "epoch:[972 / 1000] batch:[30 / 134] loss= 0.043\n",
      "epoch:[972 / 1000] batch:[60 / 134] loss= 0.049\n",
      "epoch:[972 / 1000] batch:[90 / 134] loss= 0.035\n",
      "epoch:[972 / 1000] batch:[120 / 134] loss= 0.032\n",
      "100 cycles trn_loss: 0.026, val_loss: 0.100, lr=1.045366e-05\n",
      "training set RMSE 1 cycle: 36.053, 10 cycle: 30.742, 100 cycle: 21.307\n",
      "testing set RMSE 1 cycle: 45.706, 10 cycle: 47.411, 100 cycle: 41.677\n",
      "epoch:[973 / 1000] batch:[30 / 134] loss= 0.057\n",
      "epoch:[973 / 1000] batch:[60 / 134] loss= 0.047\n",
      "epoch:[973 / 1000] batch:[90 / 134] loss= 0.031\n",
      "epoch:[973 / 1000] batch:[120 / 134] loss= 0.071\n",
      "100 cycles trn_loss: 0.027, val_loss: 0.097, lr=2.140463e-05\n",
      "training set RMSE 1 cycle: 34.000, 10 cycle: 29.108, 100 cycle: 21.656\n",
      "testing set RMSE 1 cycle: 44.024, 10 cycle: 44.892, 100 cycle: 40.938\n",
      "epoch:[974 / 1000] batch:[30 / 134] loss= 0.049\n",
      "epoch:[974 / 1000] batch:[60 / 134] loss= 0.031\n",
      "epoch:[974 / 1000] batch:[90 / 134] loss= 0.048\n",
      "epoch:[974 / 1000] batch:[120 / 134] loss= 0.031\n",
      "100 cycles trn_loss: 0.027, val_loss: 0.092, lr=3.520366e-05\n",
      "training set RMSE 1 cycle: 41.434, 10 cycle: 35.186, 100 cycle: 21.611\n",
      "testing set RMSE 1 cycle: 45.941, 10 cycle: 48.623, 100 cycle: 39.843\n",
      "epoch:[975 / 1000] batch:[30 / 134] loss= 0.018\n",
      "epoch:[975 / 1000] batch:[60 / 134] loss= 0.061\n",
      "epoch:[975 / 1000] batch:[90 / 134] loss= 0.066\n",
      "epoch:[975 / 1000] batch:[120 / 134] loss= 0.076\n",
      "100 cycles trn_loss: 0.030, val_loss: 0.116, lr=5.050000e-05\n",
      "training set RMSE 1 cycle: 36.159, 10 cycle: 31.954, 100 cycle: 22.722\n",
      "testing set RMSE 1 cycle: 46.788, 10 cycle: 50.795, 100 cycle: 44.876\n",
      "epoch:[976 / 1000] batch:[30 / 134] loss= 0.044\n",
      "epoch:[976 / 1000] batch:[60 / 134] loss= 0.087\n",
      "epoch:[976 / 1000] batch:[90 / 134] loss= 0.027\n",
      "epoch:[976 / 1000] batch:[120 / 134] loss= 0.044\n",
      "100 cycles trn_loss: 0.024, val_loss: 0.115, lr=6.579634e-05\n",
      "training set RMSE 1 cycle: 36.616, 10 cycle: 31.567, 100 cycle: 20.543\n",
      "testing set RMSE 1 cycle: 47.590, 10 cycle: 51.223, 100 cycle: 44.670\n",
      "epoch:[977 / 1000] batch:[30 / 134] loss= 0.061\n",
      "epoch:[977 / 1000] batch:[60 / 134] loss= 0.092\n",
      "epoch:[977 / 1000] batch:[90 / 134] loss= 0.069\n",
      "epoch:[977 / 1000] batch:[120 / 134] loss= 0.084\n",
      "100 cycles trn_loss: 0.026, val_loss: 0.104, lr=7.959537e-05\n",
      "training set RMSE 1 cycle: 43.264, 10 cycle: 36.659, 100 cycle: 21.105\n",
      "testing set RMSE 1 cycle: 47.115, 10 cycle: 50.367, 100 cycle: 42.393\n",
      "epoch:[978 / 1000] batch:[30 / 134] loss= 0.065\n",
      "epoch:[978 / 1000] batch:[60 / 134] loss= 0.085\n",
      "epoch:[978 / 1000] batch:[90 / 134] loss= 0.078\n",
      "epoch:[978 / 1000] batch:[120 / 134] loss= 0.030\n",
      "100 cycles trn_loss: 0.048, val_loss: 0.103, lr=9.054634e-05\n",
      "training set RMSE 1 cycle: 53.817, 10 cycle: 43.364, 100 cycle: 28.942\n",
      "testing set RMSE 1 cycle: 51.712, 10 cycle: 52.303, 100 cycle: 42.301\n",
      "epoch:[979 / 1000] batch:[30 / 134] loss= 0.031\n",
      "epoch:[979 / 1000] batch:[60 / 134] loss= 0.063\n",
      "epoch:[979 / 1000] batch:[90 / 134] loss= 0.109\n",
      "epoch:[979 / 1000] batch:[120 / 134] loss= 0.084\n",
      "100 cycles trn_loss: 0.025, val_loss: 0.128, lr=9.757730e-05\n",
      "training set RMSE 1 cycle: 33.804, 10 cycle: 28.325, 100 cycle: 20.600\n",
      "testing set RMSE 1 cycle: 50.322, 10 cycle: 50.930, 100 cycle: 47.206\n",
      "epoch:[980 / 1000] batch:[30 / 134] loss= 0.132\n",
      "epoch:[980 / 1000] batch:[60 / 134] loss= 0.087\n",
      "epoch:[980 / 1000] batch:[90 / 134] loss= 0.059\n",
      "epoch:[980 / 1000] batch:[120 / 134] loss= 0.075\n",
      "100 cycles trn_loss: 0.042, val_loss: 0.118, lr=1.000000e-04\n",
      "training set RMSE 1 cycle: 35.423, 10 cycle: 31.804, 100 cycle: 27.425\n",
      "testing set RMSE 1 cycle: 46.580, 10 cycle: 46.413, 100 cycle: 45.142\n",
      "epoch:[981 / 1000] batch:[30 / 134] loss= 0.046\n",
      "epoch:[981 / 1000] batch:[60 / 134] loss= 0.034\n",
      "epoch:[981 / 1000] batch:[90 / 134] loss= 0.046\n",
      "epoch:[981 / 1000] batch:[120 / 134] loss= 0.141\n",
      "100 cycles trn_loss: 0.025, val_loss: 0.131, lr=9.757730e-05\n",
      "training set RMSE 1 cycle: 33.338, 10 cycle: 27.326, 100 cycle: 20.885\n",
      "testing set RMSE 1 cycle: 51.073, 10 cycle: 50.721, 100 cycle: 47.574\n",
      "epoch:[982 / 1000] batch:[30 / 134] loss= 0.044\n",
      "epoch:[982 / 1000] batch:[60 / 134] loss= 0.119\n",
      "epoch:[982 / 1000] batch:[90 / 134] loss= 0.051\n",
      "epoch:[982 / 1000] batch:[120 / 134] loss= 0.124\n",
      "100 cycles trn_loss: 0.117, val_loss: 0.175, lr=9.054634e-05\n",
      "training set RMSE 1 cycle: 49.367, 10 cycle: 49.998, 100 cycle: 49.858\n",
      "testing set RMSE 1 cycle: 54.332, 10 cycle: 51.117, 100 cycle: 55.334\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:[983 / 1000] batch:[30 / 134] loss= 0.087\n",
      "epoch:[983 / 1000] batch:[60 / 134] loss= 0.026\n",
      "epoch:[983 / 1000] batch:[90 / 134] loss= 0.022\n",
      "epoch:[983 / 1000] batch:[120 / 134] loss= 0.043\n",
      "100 cycles trn_loss: 0.045, val_loss: 0.162, lr=7.959537e-05\n",
      "training set RMSE 1 cycle: 38.190, 10 cycle: 34.825, 100 cycle: 27.891\n",
      "testing set RMSE 1 cycle: 52.580, 10 cycle: 57.485, 100 cycle: 53.100\n",
      "epoch:[984 / 1000] batch:[30 / 134] loss= 0.039\n",
      "epoch:[984 / 1000] batch:[60 / 134] loss= 0.024\n",
      "epoch:[984 / 1000] batch:[90 / 134] loss= 0.074\n",
      "epoch:[984 / 1000] batch:[120 / 134] loss= 0.036\n",
      "100 cycles trn_loss: 0.042, val_loss: 0.128, lr=6.579634e-05\n",
      "training set RMSE 1 cycle: 34.739, 10 cycle: 31.526, 100 cycle: 27.349\n",
      "testing set RMSE 1 cycle: 48.077, 10 cycle: 48.640, 100 cycle: 47.145\n",
      "epoch:[985 / 1000] batch:[30 / 134] loss= 0.043\n",
      "epoch:[985 / 1000] batch:[60 / 134] loss= 0.027\n",
      "epoch:[985 / 1000] batch:[90 / 134] loss= 0.047\n",
      "epoch:[985 / 1000] batch:[120 / 134] loss= 0.030\n",
      "100 cycles trn_loss: 0.019, val_loss: 0.112, lr=5.050000e-05\n",
      "training set RMSE 1 cycle: 27.608, 10 cycle: 23.777, 100 cycle: 18.067\n",
      "testing set RMSE 1 cycle: 45.634, 10 cycle: 45.611, 100 cycle: 43.962\n",
      "epoch:[986 / 1000] batch:[30 / 134] loss= 0.035\n",
      "epoch:[986 / 1000] batch:[60 / 134] loss= 0.037\n",
      "epoch:[986 / 1000] batch:[90 / 134] loss= 0.035\n",
      "epoch:[986 / 1000] batch:[120 / 134] loss= 0.049\n",
      "100 cycles trn_loss: 0.020, val_loss: 0.131, lr=3.520366e-05\n",
      "training set RMSE 1 cycle: 35.370, 10 cycle: 28.947, 100 cycle: 18.808\n",
      "testing set RMSE 1 cycle: 49.826, 10 cycle: 52.946, 100 cycle: 47.767\n",
      "epoch:[987 / 1000] batch:[30 / 134] loss= 0.028\n",
      "epoch:[987 / 1000] batch:[60 / 134] loss= 0.030\n",
      "epoch:[987 / 1000] batch:[90 / 134] loss= 0.044\n",
      "epoch:[987 / 1000] batch:[120 / 134] loss= 0.023\n",
      "100 cycles trn_loss: 0.020, val_loss: 0.129, lr=2.140463e-05\n",
      "training set RMSE 1 cycle: 29.397, 10 cycle: 24.317, 100 cycle: 18.701\n",
      "testing set RMSE 1 cycle: 46.736, 10 cycle: 48.651, 100 cycle: 47.282\n",
      "epoch:[988 / 1000] batch:[30 / 134] loss= 0.016\n",
      "epoch:[988 / 1000] batch:[60 / 134] loss= 0.029\n",
      "epoch:[988 / 1000] batch:[90 / 134] loss= 0.009\n",
      "epoch:[988 / 1000] batch:[120 / 134] loss= 0.033\n",
      "100 cycles trn_loss: 0.015, val_loss: 0.097, lr=1.045366e-05\n",
      "training set RMSE 1 cycle: 28.229, 10 cycle: 22.135, 100 cycle: 16.241\n",
      "testing set RMSE 1 cycle: 45.319, 10 cycle: 42.098, 100 cycle: 41.052\n",
      "epoch:[989 / 1000] batch:[30 / 134] loss= 0.014\n",
      "epoch:[989 / 1000] batch:[60 / 134] loss= 0.023\n",
      "epoch:[989 / 1000] batch:[90 / 134] loss= 0.026\n",
      "epoch:[989 / 1000] batch:[120 / 134] loss= 0.032\n",
      "100 cycles trn_loss: 0.013, val_loss: 0.098, lr=3.422702e-06\n",
      "training set RMSE 1 cycle: 29.243, 10 cycle: 22.181, 100 cycle: 14.867\n",
      "testing set RMSE 1 cycle: 44.674, 10 cycle: 42.588, 100 cycle: 41.156\n",
      "epoch:[990 / 1000] batch:[30 / 134] loss= 0.015\n",
      "epoch:[990 / 1000] batch:[60 / 134] loss= 0.034\n",
      "epoch:[990 / 1000] batch:[90 / 134] loss= 0.028\n",
      "epoch:[990 / 1000] batch:[120 / 134] loss= 0.023\n",
      "100 cycles trn_loss: 0.014, val_loss: 0.108, lr=1.000000e-06\n",
      "training set RMSE 1 cycle: 27.506, 10 cycle: 21.772, 100 cycle: 15.351\n",
      "testing set RMSE 1 cycle: 44.893, 10 cycle: 43.840, 100 cycle: 43.138\n",
      "epoch:[991 / 1000] batch:[30 / 134] loss= 0.015\n",
      "epoch:[991 / 1000] batch:[60 / 134] loss= 0.016\n",
      "epoch:[991 / 1000] batch:[90 / 134] loss= 0.041\n",
      "epoch:[991 / 1000] batch:[120 / 134] loss= 0.022\n",
      "100 cycles trn_loss: 0.013, val_loss: 0.108, lr=3.422702e-06\n",
      "training set RMSE 1 cycle: 28.907, 10 cycle: 22.334, 100 cycle: 14.839\n",
      "testing set RMSE 1 cycle: 45.152, 10 cycle: 44.431, 100 cycle: 43.171\n",
      "epoch:[992 / 1000] batch:[30 / 134] loss= 0.025\n",
      "epoch:[992 / 1000] batch:[60 / 134] loss= 0.020\n",
      "epoch:[992 / 1000] batch:[90 / 134] loss= 0.026\n",
      "epoch:[992 / 1000] batch:[120 / 134] loss= 0.024\n",
      "100 cycles trn_loss: 0.012, val_loss: 0.107, lr=1.045366e-05\n",
      "training set RMSE 1 cycle: 30.393, 10 cycle: 23.033, 100 cycle: 14.298\n",
      "testing set RMSE 1 cycle: 45.343, 10 cycle: 44.914, 100 cycle: 42.991\n",
      "epoch:[993 / 1000] batch:[30 / 134] loss= 0.050\n",
      "epoch:[993 / 1000] batch:[60 / 134] loss= 0.036\n",
      "epoch:[993 / 1000] batch:[90 / 134] loss= 0.035\n",
      "epoch:[993 / 1000] batch:[120 / 134] loss= 0.013\n",
      "100 cycles trn_loss: 0.013, val_loss: 0.116, lr=2.140463e-05\n",
      "training set RMSE 1 cycle: 31.998, 10 cycle: 23.731, 100 cycle: 15.178\n",
      "testing set RMSE 1 cycle: 46.423, 10 cycle: 46.766, 100 cycle: 44.817\n",
      "epoch:[994 / 1000] batch:[30 / 134] loss= 0.030\n",
      "epoch:[994 / 1000] batch:[60 / 134] loss= 0.019\n",
      "epoch:[994 / 1000] batch:[90 / 134] loss= 0.041\n",
      "epoch:[994 / 1000] batch:[120 / 134] loss= 0.031\n",
      "100 cycles trn_loss: 0.013, val_loss: 0.107, lr=3.520366e-05\n",
      "training set RMSE 1 cycle: 35.127, 10 cycle: 25.409, 100 cycle: 15.226\n",
      "testing set RMSE 1 cycle: 45.993, 10 cycle: 46.189, 100 cycle: 43.053\n",
      "epoch:[995 / 1000] batch:[30 / 134] loss= 0.026\n",
      "epoch:[995 / 1000] batch:[60 / 134] loss= 0.031\n",
      "epoch:[995 / 1000] batch:[90 / 134] loss= 0.044\n",
      "epoch:[995 / 1000] batch:[120 / 134] loss= 0.034\n",
      "100 cycles trn_loss: 0.014, val_loss: 0.118, lr=5.050000e-05\n",
      "training set RMSE 1 cycle: 27.750, 10 cycle: 22.208, 100 cycle: 15.670\n",
      "testing set RMSE 1 cycle: 44.696, 10 cycle: 45.566, 100 cycle: 45.152\n",
      "epoch:[996 / 1000] batch:[30 / 134] loss= 0.045\n",
      "epoch:[996 / 1000] batch:[60 / 134] loss= 0.044\n",
      "epoch:[996 / 1000] batch:[90 / 134] loss= 0.031\n",
      "epoch:[996 / 1000] batch:[120 / 134] loss= 0.033\n",
      "100 cycles trn_loss: 0.012, val_loss: 0.109, lr=6.579634e-05\n",
      "training set RMSE 1 cycle: 30.312, 10 cycle: 22.996, 100 cycle: 14.561\n",
      "testing set RMSE 1 cycle: 46.621, 10 cycle: 45.403, 100 cycle: 43.435\n",
      "epoch:[997 / 1000] batch:[30 / 134] loss= 0.019\n",
      "epoch:[997 / 1000] batch:[60 / 134] loss= 0.027\n",
      "epoch:[997 / 1000] batch:[90 / 134] loss= 0.011\n",
      "epoch:[997 / 1000] batch:[120 / 134] loss= 0.044\n",
      "100 cycles trn_loss: 0.021, val_loss: 0.119, lr=7.959537e-05\n",
      "training set RMSE 1 cycle: 39.201, 10 cycle: 32.678, 100 cycle: 19.164\n",
      "testing set RMSE 1 cycle: 47.904, 10 cycle: 51.602, 100 cycle: 45.638\n",
      "epoch:[998 / 1000] batch:[30 / 134] loss= 0.038\n",
      "epoch:[998 / 1000] batch:[60 / 134] loss= 0.021\n",
      "epoch:[998 / 1000] batch:[90 / 134] loss= 0.106\n",
      "epoch:[998 / 1000] batch:[120 / 134] loss= 0.012\n",
      "100 cycles trn_loss: 0.039, val_loss: 0.137, lr=9.054634e-05\n",
      "training set RMSE 1 cycle: 50.823, 10 cycle: 42.253, 100 cycle: 25.896\n",
      "testing set RMSE 1 cycle: 54.159, 10 cycle: 58.003, 100 cycle: 49.359\n",
      "epoch:[999 / 1000] batch:[30 / 134] loss= 0.121\n",
      "epoch:[999 / 1000] batch:[60 / 134] loss= 0.041\n",
      "epoch:[999 / 1000] batch:[90 / 134] loss= 0.051\n",
      "epoch:[999 / 1000] batch:[120 / 134] loss= 0.016\n",
      "100 cycles trn_loss: 0.023, val_loss: 0.144, lr=9.757730e-05\n",
      "training set RMSE 1 cycle: 35.962, 10 cycle: 32.485, 100 cycle: 20.066\n",
      "testing set RMSE 1 cycle: 51.623, 10 cycle: 53.907, 100 cycle: 50.336\n",
      "epoch:[1000 / 1000] batch:[30 / 134] loss= 0.014\n",
      "epoch:[1000 / 1000] batch:[60 / 134] loss= 0.025\n",
      "epoch:[1000 / 1000] batch:[90 / 134] loss= 0.059\n",
      "epoch:[1000 / 1000] batch:[120 / 134] loss= 0.057\n",
      "100 cycles trn_loss: 0.124, val_loss: 0.142, lr=1.000000e-04\n",
      "training set RMSE 1 cycle: 55.908, 10 cycle: 48.836, 100 cycle: 48.802\n",
      "testing set RMSE 1 cycle: 52.213, 10 cycle: 48.755, 100 cycle: 49.674\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "parser = get_args_parser()\n",
    "args = parser.parse_args(args=[])\n",
    "if torch.cuda.is_available():\n",
    "    print(\" -- GPU is available -- \")\n",
    "\n",
    "# split the training data into 86:22 for training and validation respectively\n",
    "trn_set = Battery_Dataset(train=True, last_padding=False)\n",
    "val_set = Battery_Dataset(train=False, last_padding=False)\n",
    "trn_loader = DataLoader(trn_set, batch_size=86, num_workers=1, drop_last=False, shuffle=False)\n",
    "val_loader = DataLoader(val_set, batch_size=22, num_workers=1, drop_last=False, shuffle=False)\n",
    "\n",
    "\"\"\"\n",
    "real training strategy: we trained and save several models with CosineAnnealingLR\n",
    "-> load the best model in the previous stage as pretrain weight and decrease the lr for fine-tuning\n",
    "the best validation RUL error in this example can achieve ~35 cycles(RMSE)\n",
    "\"\"\"\n",
    "if args.finetune: # load pretrained weight, but in this example, we trained from scratch\n",
    "    model = torch.load(args.pretrained_model)\n",
    "else:\n",
    "    model = Predictor(args.qv_ch, 1, drop=args.drop)\n",
    "model.cuda()\n",
    "summary(model, (args.qv_ch, 50))\n",
    "\n",
    "optimizer = optim.AdamW(model.parameters(), lr=args.lr, amsgrad=True, weight_decay=args.weight_decay)\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=args.lr_period, eta_min=args.min_lr)\n",
    "criterion = nn.HuberLoss(delta=1)\n",
    "\n",
    "best_rmse = 50\n",
    "trn_loss_record, val_loss_record = [], []\n",
    "for epoch in range(args.epochs):\n",
    "    epoch += 1\n",
    "    # in the training process, we use \"last padding\" for augmentation\n",
    "    trn_random_set = Battery_Dataset(train=True, last_padding=True)\n",
    "    trn_random_loader = DataLoader(trn_random_set, batch_size=args.batch_size, num_workers=1, drop_last=False, shuffle=True)\n",
    "    model.train()\n",
    "    batch = 0\n",
    "    n_minibatch = (len(trn_random_set)//args.batch_size)\n",
    "    for inputs, targets in trn_random_loader:\n",
    "        batch += 1\n",
    "        optimizer.zero_grad()\n",
    "        output = model(inputs.cuda().float())\n",
    "        loss = criterion(output , targets.reshape(-1, 1).cuda().float())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch%30==0:\n",
    "            print('epoch:[%d / %d] batch:[%d / %d] loss= %.3f' % \n",
    "                (epoch, args.epochs, batch, n_minibatch, loss.mean()))\n",
    "\n",
    "    if args.lr_schedule:\n",
    "        scheduler.step()\n",
    "\n",
    "    # model evaluation per epoch\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        trn_loss, val_loss = 0, 0\n",
    "        for inputs, targets in trn_loader:\n",
    "            output = model(inputs.cuda().float())\n",
    "            loss = criterion(output , targets.reshape(-1, 1).cuda().float())\n",
    "            trn_loss += loss.mean()\n",
    "        for inputs, targets in val_loader:\n",
    "            output = model(inputs.cuda().float())\n",
    "            loss = criterion(output , targets.reshape(-1, 1).cuda().float())\n",
    "            val_loss += loss.mean()\n",
    "        trn_loss_record.append(trn_loss.cpu())\n",
    "        val_loss_record.append(val_loss.cpu())\n",
    "        if epoch%args.detail_epoch==0:\n",
    "            for g in optimizer.param_groups:\n",
    "                current_lr = g['lr']\n",
    "            print('100 cycles trn_loss: %.3f, val_loss: %.3f, lr=%e' % (trn_loss, val_loss, current_lr))\n",
    "\n",
    "    # we can evaluate the RUL RMSE with different input cycle length\n",
    "    trn_rmse, test_rmse = model_evaluation(model, eval_length=[0, 9, 49])\n",
    "    if epoch%args.detail_epoch==0:\n",
    "        print('training set RMSE 1 cycle: %.3f, 10 cycle: %.3f, 100 cycle: %.3f' %\n",
    "            (trn_rmse[0], trn_rmse[1], trn_rmse[2]))\n",
    "        print('testing set RMSE 1 cycle: %.3f, 10 cycle: %.3f, 100 cycle: %.3f' %\n",
    "            (test_rmse[0], test_rmse[1], test_rmse[2]))\n",
    "\n",
    "    # save the model with lowest validation RMSE\n",
    "    if test_rmse[2]<best_rmse:\n",
    "        best_rmse = test_rmse[2]\n",
    "        torch.save(model, 'checkpoint/checkpoint'+str(test_rmse[2])+'.pth')\n",
    "\n",
    "# training finished \n",
    "loss_profile(trn_loss_record, val_loss_record)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
